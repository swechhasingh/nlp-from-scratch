{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swechhasingh/nlp-from-scratch/blob/main/eng-fr-neural-machine-translation/colab_transformer_MT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUQmX6mSW3Jo"
      },
      "source": [
        "### English-French Neural Machine Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eL3dE0XzW3Jp"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuq5OkRCW3Jq",
        "outputId": "68fd663d-68e5-423f-fc79-de275946af99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS not available because the current PyTorch install was not built with MPS enabled.\n"
          ]
        }
      ],
      "source": [
        "# Check that MPS is available\n",
        "if not torch.backends.mps.is_available():\n",
        "    if not torch.backends.mps.is_built():\n",
        "        print(\"MPS not available because the current PyTorch install was not \"\n",
        "              \"built with MPS enabled.\")\n",
        "    else:\n",
        "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
        "              \"and/or you do not have an MPS-enabled device on this machine.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYbxTQsXW3Jq",
        "outputId": "d02af3fc-a18e-4d9d-fe94-1af12898f067"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"mps\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pYP1gEp3W3Jr"
      },
      "outputs": [],
      "source": [
        "src_language = 'eng'\n",
        "target_language = 'fra'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CDlbvXFbW3Jr",
        "outputId": "27d3b8eb-c242-46e6-8490-c3fa9353b2ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go.\\tVa !', 'Run!\\tCours\\u202f!', 'Run!\\tCourez\\u202f!', 'Wow!\\tÇa alors\\u202f!', 'Fire!\\tAu feu !']\n"
          ]
        }
      ],
      "source": [
        "# Read the file and split into lines\n",
        "with open('data/%s-%s.txt' % (src_language, target_language), encoding='utf-8') as file:\n",
        "    text_data = file.read().splitlines()\n",
        "print(text_data[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHrWihehW3Jr"
      },
      "source": [
        "The text is in Unicode. So, we will take the following preprocessing steps:\n",
        "1. Turn Unicode characters to ASCII\n",
        "2. lowercase\n",
        "3. Trim most punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zsi0BliwW3Jr"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicode_to_ascii(sent):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', sent)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def preprocess_string(sent):\n",
        "    \"lowercase, unicode_to_ascii, trim, and remove non-letter characters\"\n",
        "    sent = sent.lower().strip()\n",
        "    sent = unicode_to_ascii(sent)\n",
        "    # The backreference \\1 (backslash one) references the first capturing group. \n",
        "    # space followed by \\1 matches the exact same text that was matched by the first capturing group [.!?].\n",
        "    sent = re.sub(r\"([.!?])\", r\" \\1\", sent)\n",
        "    # replace character which are not from this set (a-zA-Z.!?) by single space character\n",
        "    sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sent)\n",
        "    return sent.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "flDteWRLW3Js",
        "outputId": "b8ff8c9d-cf72-45d5-fdda-1bbda2116b2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wow!\tÇa alors !\n",
            "['Ça alors\\u202f!', 'Wow!']\n"
          ]
        }
      ],
      "source": [
        "preprocess_string(text_data[3])\n",
        "print(text_data[3])\n",
        "print(text_data[3].split('\\t')[::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HcFEWkDSW3Js"
      },
      "outputs": [],
      "source": [
        "def load_data(file_name, reverse=False):\n",
        "    print(\"Reading text file...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    with open('data/%s' % (file_name), encoding='utf-8') as file:\n",
        "        lines = file.read().splitlines()\n",
        "\n",
        "    # Split every line into pairs [src_lang, target_lang] and preprocess\n",
        "    pairs = [[preprocess_string(s) for s in line.split('\\t')] for line in lines]\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [p[::-1] for p in pairs]\n",
        "        \n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zKwXEPCW3Js",
        "outputId": "9964a5de-b425-4520-a3ab-16bc570064fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading text file...\n"
          ]
        }
      ],
      "source": [
        "pairs = load_data('eng-fra.txt', reverse=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tLlMKRkWW3Js"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK = 2\n",
        "PAD = 3\n",
        "BLOCK_SIZE = 12\n",
        "\n",
        "class Language:\n",
        "    def __init__(self, lang_name, src=True):\n",
        "        self.lang_name = lang_name\n",
        "        self.word_to_index = {\"SOS\":0, \"EOS\":1, \"UNK\": 2, \"PAD\":3}\n",
        "        self.index_to_word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3:\"PAD\"}\n",
        "        self.word_to_count = {}\n",
        "        self.vocab_size = 4\n",
        "        self.src = src\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word_to_index:\n",
        "            self.word_to_index[word] = self.vocab_size\n",
        "            self.index_to_word[self.vocab_size] = word\n",
        "            self.vocab_size += 1\n",
        "        self.word_to_count[word] = self.word_to_count.get(word, 0) + 1\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def sentence_to_indexes(self, sentence):\n",
        "        idxs = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index[\"UNK\"] for word in sentence.split(' ')]\n",
        "        return idxs\n",
        "        \n",
        "    def indexes_to_sentence(self, indexes):\n",
        "        return ' '.join([self.index_to_word[index] for index in indexes])\n",
        "\n",
        "    def sentence_to_tensor(self, sentence):\n",
        "        indexes = self.sentence_to_indexes(sentence)\n",
        "        indexes = [SOS_token] + indexes + [EOS_token]\n",
        "\n",
        "        max_len = BLOCK_SIZE if self.src else BLOCK_SIZE + 1\n",
        "        \n",
        "        if len(indexes) < max_len:\n",
        "            indexes += [PAD]*(max_len-len(indexes))\n",
        "        else:\n",
        "            indexes = indexes[:max_len]\n",
        "            \n",
        "        indexes = torch.tensor(indexes, dtype=torch.long)\n",
        "        return indexes\n",
        "\n",
        "    def tensor_to_sentence(self, idx_tensor):\n",
        "        if len(idx_tensor.shape) > 1:\n",
        "            idxs = idx_tensor.tolist()[0]\n",
        "        else:\n",
        "            idxs = idx_tensor.tolist()\n",
        "        sentence = self.indexes_to_sentence(idxs)\n",
        "        return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CO2pdabRW3Jt"
      },
      "outputs": [],
      "source": [
        "# create language instances\n",
        "src_lang = Language(src_language)\n",
        "target_lang = Language(target_language)\n",
        "\n",
        "for src, target in pairs:\n",
        "    src_lang.add_sentence(src)\n",
        "    target_lang.add_sentence(target) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nZesrsgW3Jt"
      },
      "source": [
        "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc. (accounting for apostrophes replaced earlier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYDeVCulW3Jt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WXLu25TjW3Jt"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p, reverse=False):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1 if reverse else 0].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs, reverse):\n",
        "    return [pair for pair in pairs if filterPair(pair, reverse)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0cyjbJEW3Jt"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "Read text file and split into lines, split lines into pairs\n",
        "\n",
        "Normalize text, filter by length and content\n",
        "\n",
        "Make word lists from sentences in pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nqu3b83qW3Jt"
      },
      "outputs": [],
      "source": [
        "def create_dataset(src_lang, target_lang, reverse=False):\n",
        "    pairs = load_data('eng-fra.txt', reverse)\n",
        "\n",
        "    # create language instances\n",
        "    input_lang = Language(src_lang)\n",
        "    output_lang = Language(target_lang, src=False)\n",
        "\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    pairs = filterPairs(pairs, reverse)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "\n",
        "    # train/val/test split\n",
        "    n_total = len(pairs)\n",
        "    n_train = int(0.8*n_total)\n",
        "    n_val = int(0.1*n_total)\n",
        "    n_test = n_total - n_train - n_val\n",
        "    print(f\"{n_train=}, {n_val=}, {n_test=}\")\n",
        "    pair_split = {}\n",
        "    pair_split['train'] = pairs[:n_train]\n",
        "    pair_split['val'] = pairs[n_train:n_train + n_val]\n",
        "    pair_split['test'] = pairs[n_train + n_val:]\n",
        "    \n",
        "    print(\"Counting words...\")\n",
        "    print(\"Creating source and target language vocab using pair_split['train']...\")\n",
        "    for src, target in pair_split['train']:\n",
        "        input_lang.add_sentence(src)\n",
        "        output_lang.add_sentence(target) \n",
        "\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.lang_name, input_lang.vocab_size)\n",
        "    print(output_lang.lang_name, output_lang.vocab_size)\n",
        "    return input_lang, output_lang, pair_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk-EpzmlW3Ju",
        "outputId": "96f47304-b86c-4f93-e549-8f8e135a3ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading text file...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "n_train=8479, n_val=1059, n_test=1061\n",
            "Counting words...\n",
            "Creating source and target language vocab using pair_split['train']...\n",
            "Counted words:\n",
            "eng 2184\n",
            "fra 3526\n",
            "['you re conscientious .', 'tu es consciencieux .']\n"
          ]
        }
      ],
      "source": [
        "src_lang, target_lang, pair_split = create_dataset('eng', 'fra', reverse=False)\n",
        "print(random.choice(pair_split[\"train\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dopRngz7W3Ju"
      },
      "source": [
        "#### Tokenization: Words to indexes\n",
        "In seq2seq task takes an input sequence (source seq) and outputs another sequence (target seq). In our case, we have an input sentence in English language and a corresponding translated sentence in French language. These sentence need to converted into numbers (integers) to be able to into to a neural network. For this, we will use **word-level tokenization**, i.e *word to integer* index mapping.\n",
        "\n",
        "We need some special tokens to indicate start (SOS) and end (EOS) of a sentence. For the input sequence (source seq), the model needs to know when the input has ended and for the target sequence, the model needs to know when to start and when to end.\n",
        "\n",
        "So, we will append the EOS token to the end of input sentence and wrap the target sentence by SOS (in the beginning) and the EOS (in the end) tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H_1q9Ph9W3Ju"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sent_pair_to_tensor_pair(pair, src_lang, target_lang):\n",
        "    input_tensor = src_lang.sentence_to_tensor(pair[0])\n",
        "    target_tensor = target_lang.sentence_to_tensor(pair[1])\n",
        "    return input_tensor, target_tensor\n",
        "\n",
        "def tensor_pair_to_sent_pair(pair, src_lang, target_lang):\n",
        "    input_tensor = src_lang.tensor_to_sentence(pair[0])\n",
        "    target_tensor = target_lang.tensor_to_sentence(pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqfYklMAW3Ju",
        "outputId": "d017b51b-55e3-4d05-ff37-429fef365266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i m learning music .', 'j etudie la musique .']\n",
            "(tensor([   0,    4,    5, 1057, 1020,    6,    1,    3,    3,    3,    3,    3]), tensor([   0,    4,  642,  204, 1852,    7,    1,    3,    3,    3,    3,    3,\n",
            "           3]))\n",
            "(tensor([   0,    4,    5, 1057, 1020,    6,    1,    3,    3,    3,    3,    3]), tensor([   0,    4,  642,  204, 1852,    7,    1,    3,    3,    3,    3,    3,\n",
            "           3]))\n",
            "('SOS i m learning music . EOS PAD PAD PAD PAD PAD', 'SOS j etudie la musique . EOS PAD PAD PAD PAD PAD PAD')\n"
          ]
        }
      ],
      "source": [
        "pair = random.choices(pair_split[\"train\"], k=1)[0]\n",
        "print(pair)\n",
        "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
        "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
        "\n",
        "p1, p2 = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
        "print(tensor_pair_to_sent_pair((p1,p2), src_lang, target_lang))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wkucay4VW3Ju"
      },
      "outputs": [],
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, target=None, pad_idx=2) -> None:\n",
        "        # src and target sequences have same length\n",
        "        self.src = src #shape:(B,T)\n",
        "        # src_mask:(B,1,1,T)\n",
        "        self.src_mask = (src != pad_idx).unsqueeze(-2).unsqueeze(-2)\n",
        "        if target is not None:\n",
        "            # decoder output shifted by one\n",
        "            self.tgt = target[:,:-1] #shape:(B,T)\n",
        "            self.tgt_y = target[:,1:]\n",
        "            # padding mask: (B,T)\n",
        "            self.tgt_pad_mask = (self.tgt_y != pad_idx)\n",
        "            self.tgt_mask = self.causal_mask(self.tgt, pad_idx)\n",
        "            self.n_tokens = self.tgt_pad_mask.sum().item()\n",
        "\n",
        "    @staticmethod   \n",
        "    def causal_mask(target, pad_idx):\n",
        "        # max context length = block_size\n",
        "        T = target.shape[1]\n",
        "        # causal attention mask: (1,T,T)\n",
        "        causal_attn_mask = torch.tril(torch.ones(1, T, T, dtype=torch.bool, device=target.device))\n",
        "        # padding mask: (B,1,T)\n",
        "        tgt_pad_mask = (target != pad_idx).unsqueeze(-2)\n",
        "        target_mask = tgt_pad_mask & causal_attn_mask\n",
        "        return target_mask.unsqueeze(1) # (B,1,T,T)\n",
        "\n",
        "        \n",
        "def build_batch(split, batch_size=4):\n",
        "    if split == \"train\":\n",
        "        pairs = pair_split[\"train\"]\n",
        "    elif split == \"val\":\n",
        "        pairs = pair_split[\"val\"]\n",
        "    else:\n",
        "        pairs = pair_split[\"test\"]\n",
        "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
        "    # number of sequences in a batch is batch_size\n",
        "    batch_pairs = random.choices(pairs, k=batch_size)\n",
        "    # input \n",
        "    src_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for pair in batch_pairs:\n",
        "        src_tensor, target_tensor = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
        "        src_batch.append(src_tensor)\n",
        "        target_batch.append(target_tensor)\n",
        "    \n",
        "    src = torch.stack(src_batch).to(device)\n",
        "    target = torch.stack(target_batch).to(device)\n",
        "\n",
        "    batch = Batch(src, target, PAD)\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q3ptKYyQW3Ju"
      },
      "outputs": [],
      "source": [
        "b = build_batch(\"train\", batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfMMifvOW3Ju",
        "outputId": "3954a55d-80d9-4a28-9040-2d7cfb3f1ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SOS i m not like other people . EOS PAD PAD PAD\n",
            "SOS je ne suis pas comme les autres gens . EOS PAD\n",
            "je ne suis pas comme les autres gens . EOS PAD PAD\n"
          ]
        }
      ],
      "source": [
        "print(src_lang.tensor_to_sentence(b.src))\n",
        "print(target_lang.tensor_to_sentence(b.tgt))\n",
        "print(target_lang.tensor_to_sentence(b.tgt_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTUpb-xMW3Jv"
      },
      "source": [
        "#### Seq2Seq English-French Machine Translation Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDoThXdUW3Jv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-neO0ibaW3Jv"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from transformers.transformer import EncDecTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wlLHA3R5W3Jv"
      },
      "outputs": [],
      "source": [
        "# model hyperparameters\n",
        "model_hyparam = {\n",
        "    \"src_vocab_size\": src_lang.vocab_size,\n",
        "    \"tgt_vocab_size\": target_lang.vocab_size,\n",
        "    \"block_size\": BLOCK_SIZE,\n",
        "    \"model_dim\": 128,\n",
        "    \"n_layer\": 4,\n",
        "    \"n_head\": 4,\n",
        "    \"cross_attention\":True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asx7K1LUW3Jv",
        "outputId": "c40ef687-0693-4e27-94a9-eaa8d437c51b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Batch at 0x7f706005fcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "batch = build_batch(\"train\", batch_size=4)\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "QPl4Tp59W3Jv"
      },
      "outputs": [],
      "source": [
        "# training hyperparameters\n",
        "batch_size = 32\n",
        "n_iters = 2000\n",
        "eval_interval = 20\n",
        "base_lr = 1.0\n",
        "eval_iters = 50\n",
        "warmup_steps = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn-lvaaXW3Jv"
      },
      "source": [
        "Vary the learning rate over the course of training, according to the formula:<br>\n",
        "<br>\n",
        "$lr = {d_{model}}^{-0.5}*\\min({step\\_num}^{-0.5}, step\\_num * {warmup\\_steps}^{-1.5})$\n",
        "<br>\n",
        "This corresponds to increasing the learning rate linearly for the first $warmup\\_steps$ training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "34gGxu3DW3Jv"
      },
      "outputs": [],
      "source": [
        "def learning_rate(step, model_size, factor, warmup):\n",
        "    # default the step to 1 for LambdaLR function to avoid zero raising to negative power\n",
        "    if step == 0:\n",
        "        step = 1\n",
        "    return factor * (\n",
        "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "5e-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapfioYTJ7-9",
        "outputId": "2fec3499-2b1b-42eb-f5b2-8496129c919b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3ZK-uzrW3Jv",
        "outputId": "73a22b95-412f-4fd7-a03b-5ca5b87d1bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.039174 M parameters\n"
          ]
        }
      ],
      "source": [
        "mt_transformer = EncDecTransformer(**model_hyparam).to(device)\n",
        "optimizer = torch.optim.AdamW(mt_transformer.parameters(), base_lr, betas=(0.9, 0.98), eps=1e-9, weight_decay=5e-1)\n",
        "lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda step: learning_rate(step, \n",
        "                                                                        model_hyparam[\"model_dim\"], \n",
        "                                                                        factor=1, warmup=warmup_steps))\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in mt_transformer.parameters())/1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9R5ldo1W3Jv",
        "outputId": "c67ee6e9-1fd1-41af-acaf-733c80f586e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 0.038272821242171004, 'val': 0.030563764732366414}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def compute_loss():\n",
        "    mt_transformer.eval()\n",
        "    out_loss = {}\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        running_loss = 0.0\n",
        "        total_tokens = 0\n",
        "        for _ in range(eval_iters):\n",
        "            batch = build_batch(split, batch_size)\n",
        "            _, loss = mt_transformer(batch.src, \n",
        "                                batch.src_mask,\n",
        "                                batch.tgt,\n",
        "                                batch.tgt_mask,\n",
        "                                batch.tgt_y,\n",
        "                                batch.tgt_pad_mask)\n",
        "            running_loss += loss.item()\n",
        "            total_tokens += batch.n_tokens\n",
        "        out_loss[split] = running_loss/total_tokens\n",
        "    mt_transformer.train()\n",
        "    return out_loss\n",
        "compute_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "eXPEDLVvW3Jw"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "def train():\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    min_val_loss = float('inf')\n",
        "    for iter in range(n_iters):\n",
        "        mt_transformer.train()\n",
        "        batch = build_batch(\"train\", batch_size)\n",
        "        _, loss = mt_transformer(batch.src, \n",
        "                                    batch.src_mask,\n",
        "                                    batch.tgt,\n",
        "                                    batch.tgt_mask,\n",
        "                                    batch.tgt_y,\n",
        "                                    batch.tgt_pad_mask)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        \n",
        "        if iter % eval_interval == 0 or iter == n_iters - 1:\n",
        "            losses = compute_loss()\n",
        "            train_losses.append(losses['train'])\n",
        "            val_losses.append(losses['val'])\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "            # save model checkpoint\n",
        "            if val_losses[-1] < min_val_loss:\n",
        "                min_val_loss = val_losses[-1]\n",
        "                torch.save(mt_transformer.state_dict(), \"mt_transformer.pt\")\n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXPJCbHjY8Hp",
        "outputId": "4735258b-c1dd-4ec6-b5a2-70356533bd02"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 0.0336, val loss 0.0280\n",
            "step 20: train loss 0.0176, val loss 0.0185\n",
            "step 40: train loss 0.0157, val loss 0.0169\n",
            "step 60: train loss 0.0148, val loss 0.0161\n",
            "step 80: train loss 0.0140, val loss 0.0161\n",
            "step 100: train loss 0.0135, val loss 0.0157\n",
            "step 120: train loss 0.0133, val loss 0.0154\n",
            "step 140: train loss 0.0130, val loss 0.0153\n",
            "step 160: train loss 0.0129, val loss 0.0150\n",
            "step 180: train loss 0.0127, val loss 0.0148\n",
            "step 200: train loss 0.0124, val loss 0.0147\n",
            "step 220: train loss 0.0123, val loss 0.0144\n",
            "step 240: train loss 0.0120, val loss 0.0145\n",
            "step 260: train loss 0.0119, val loss 0.0146\n",
            "step 280: train loss 0.0119, val loss 0.0147\n",
            "step 300: train loss 0.0114, val loss 0.0143\n",
            "step 320: train loss 0.0114, val loss 0.0142\n",
            "step 340: train loss 0.0111, val loss 0.0141\n",
            "step 360: train loss 0.0109, val loss 0.0144\n",
            "step 380: train loss 0.0106, val loss 0.0141\n",
            "step 400: train loss 0.0104, val loss 0.0139\n",
            "step 420: train loss 0.0103, val loss 0.0136\n",
            "step 440: train loss 0.0101, val loss 0.0139\n",
            "step 460: train loss 0.0102, val loss 0.0137\n",
            "step 480: train loss 0.0099, val loss 0.0138\n",
            "step 500: train loss 0.0100, val loss 0.0136\n",
            "step 520: train loss 0.0098, val loss 0.0141\n",
            "step 540: train loss 0.0097, val loss 0.0136\n",
            "step 560: train loss 0.0095, val loss 0.0138\n",
            "step 580: train loss 0.0093, val loss 0.0132\n",
            "step 600: train loss 0.0093, val loss 0.0129\n",
            "step 620: train loss 0.0092, val loss 0.0132\n",
            "step 640: train loss 0.0091, val loss 0.0132\n",
            "step 660: train loss 0.0089, val loss 0.0130\n",
            "step 680: train loss 0.0087, val loss 0.0128\n",
            "step 700: train loss 0.0089, val loss 0.0129\n",
            "step 720: train loss 0.0087, val loss 0.0126\n",
            "step 740: train loss 0.0084, val loss 0.0126\n",
            "step 760: train loss 0.0083, val loss 0.0127\n",
            "step 780: train loss 0.0082, val loss 0.0125\n",
            "step 800: train loss 0.0082, val loss 0.0124\n",
            "step 820: train loss 0.0081, val loss 0.0126\n",
            "step 840: train loss 0.0081, val loss 0.0123\n",
            "step 860: train loss 0.0081, val loss 0.0124\n",
            "step 880: train loss 0.0078, val loss 0.0121\n",
            "step 900: train loss 0.0079, val loss 0.0124\n",
            "step 920: train loss 0.0080, val loss 0.0122\n",
            "step 940: train loss 0.0075, val loss 0.0120\n",
            "step 960: train loss 0.0076, val loss 0.0119\n",
            "step 980: train loss 0.0075, val loss 0.0120\n",
            "step 1000: train loss 0.0076, val loss 0.0119\n",
            "step 1020: train loss 0.0072, val loss 0.0120\n",
            "step 1040: train loss 0.0072, val loss 0.0119\n",
            "step 1060: train loss 0.0072, val loss 0.0118\n",
            "step 1080: train loss 0.0072, val loss 0.0118\n",
            "step 1100: train loss 0.0071, val loss 0.0117\n",
            "step 1120: train loss 0.0070, val loss 0.0117\n",
            "step 1140: train loss 0.0071, val loss 0.0122\n",
            "step 1160: train loss 0.0070, val loss 0.0119\n",
            "step 1180: train loss 0.0069, val loss 0.0116\n",
            "step 1200: train loss 0.0067, val loss 0.0122\n",
            "step 1220: train loss 0.0068, val loss 0.0116\n",
            "step 1240: train loss 0.0066, val loss 0.0118\n",
            "step 1260: train loss 0.0066, val loss 0.0120\n",
            "step 1280: train loss 0.0066, val loss 0.0116\n",
            "step 1300: train loss 0.0063, val loss 0.0114\n",
            "step 1320: train loss 0.0063, val loss 0.0113\n",
            "step 1340: train loss 0.0064, val loss 0.0117\n",
            "step 1360: train loss 0.0064, val loss 0.0115\n",
            "step 1380: train loss 0.0062, val loss 0.0113\n",
            "step 1400: train loss 0.0061, val loss 0.0117\n",
            "step 1420: train loss 0.0060, val loss 0.0112\n",
            "step 1440: train loss 0.0063, val loss 0.0114\n",
            "step 1460: train loss 0.0062, val loss 0.0114\n",
            "step 1480: train loss 0.0061, val loss 0.0112\n",
            "step 1500: train loss 0.0062, val loss 0.0115\n",
            "step 1520: train loss 0.0060, val loss 0.0116\n",
            "step 1540: train loss 0.0058, val loss 0.0113\n",
            "step 1560: train loss 0.0059, val loss 0.0112\n",
            "step 1580: train loss 0.0058, val loss 0.0116\n",
            "step 1600: train loss 0.0059, val loss 0.0112\n",
            "step 1620: train loss 0.0059, val loss 0.0114\n",
            "step 1640: train loss 0.0062, val loss 0.0114\n",
            "step 1660: train loss 0.0058, val loss 0.0113\n",
            "step 1680: train loss 0.0058, val loss 0.0114\n",
            "step 1700: train loss 0.0056, val loss 0.0115\n",
            "step 1720: train loss 0.0056, val loss 0.0110\n",
            "step 1740: train loss 0.0057, val loss 0.0114\n",
            "step 1760: train loss 0.0054, val loss 0.0112\n",
            "step 1780: train loss 0.0053, val loss 0.0111\n",
            "step 1800: train loss 0.0053, val loss 0.0114\n",
            "step 1820: train loss 0.0053, val loss 0.0112\n",
            "step 1840: train loss 0.0053, val loss 0.0112\n",
            "step 1860: train loss 0.0054, val loss 0.0112\n",
            "step 1880: train loss 0.0054, val loss 0.0112\n",
            "step 1900: train loss 0.0054, val loss 0.0112\n",
            "step 1920: train loss 0.0054, val loss 0.0115\n",
            "step 1940: train loss 0.0053, val loss 0.0110\n",
            "step 1960: train loss 0.0053, val loss 0.0111\n",
            "step 1980: train loss 0.0050, val loss 0.0109\n",
            "step 1999: train loss 0.0053, val loss 0.0111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sguMZWeW3Jw",
        "outputId": "efe149af-17d7-4c92-b957-80fd7542e5dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.005299158420373307, 0.011125072979212072)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "train_losses[-1], val_losses[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ENVenv5YW3Jw",
        "outputId": "a734cba9-3b64-44c8-b5dd-839b8c334230"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f6fa9eb7970>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_losses, label=\"train\")\n",
        "plt.plot(val_losses, label=\"val\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM6ZnIOaW3Jw",
        "outputId": "1fe830ab-4787-433b-f002-1f379d47c3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng: SOS he is a UNK in UNK s UNK . EOS PAD\n",
            "fra: le garcon est un loup UNK en UNK . EOS PAD PAD\n",
            "fra: SOS c est un pigiste d cycle fille . EOS\n"
          ]
        }
      ],
      "source": [
        "batch = build_batch(\"test\", batch_size=1)\n",
        "print(f\"{src_language}: {src_lang.tensor_to_sentence(batch.src[0])}\")\n",
        "print(f\"{target_language}: {target_lang.tensor_to_sentence(batch.tgt_y[0])}\")\n",
        "out = mt_transformer.generate(batch.src, batch.src_mask, max_tokens=11)\n",
        "print(f\"{target_language}: {target_lang.tensor_to_sentence(out[0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    batch = build_batch(\"test\", batch_size=1)\n",
        "    print(f\"{i}-th example:\\n{src_language}: {src_lang.tensor_to_sentence(batch.src[0])}\")\n",
        "    print(f\"{target_language}: {target_lang.tensor_to_sentence(batch.tgt_y[0])}\")\n",
        "    out = mt_transformer.generate(batch.src, batch.src_mask, max_tokens=11)\n",
        "    print(f\"{target_language}: {target_lang.tensor_to_sentence(out[0])}\")\n",
        "    print(\"--------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJTJ18nOEMw7",
        "outputId": "1c2878d9-c80b-4faf-88af-f73b26248172"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-th example:\n",
            "eng: SOS i m very happy to make your UNK . EOS PAD\n",
            "fra: je suis heureux de vous avoir rencontre . EOS PAD PAD PAD\n",
            "fra: SOS instant suis allemand par vous soyez rencontre . EOS\n",
            "--------\n",
            "1-th example:\n",
            "eng: SOS you are more stupid than i thought . EOS PAD PAD\n",
            "fra: tu es plus idiot que je UNK . EOS PAD PAD PAD\n",
            "fra: SOS vous etes plus menteuse que moi . EOS\n",
            "--------\n",
            "2-th example:\n",
            "eng: SOS you are too sensitive to UNK . EOS PAD PAD PAD\n",
            "fra: tu es trop sensible a la critique . EOS PAD PAD PAD\n",
            "fra: SOS tu es trop condamnes touriste . EOS\n",
            "--------\n",
            "3-th example:\n",
            "eng: SOS he is captain of the football team . EOS PAD PAD\n",
            "fra: il est capitaine de l equipe de football . EOS PAD PAD\n",
            "fra: SOS il est haut a humain plage . EOS\n",
            "--------\n",
            "4-th example:\n",
            "eng: SOS you are too young to UNK alone . EOS PAD PAD\n",
            "fra: tu es trop jeune pour voyager seul . EOS PAD PAD PAD\n",
            "fra: SOS vous etes trop gentil pour vous suivre . EOS\n",
            "--------\n",
            "5-th example:\n",
            "eng: SOS i m on UNK for the next month . EOS PAD\n",
            "fra: je suis en UNK pour un mois . EOS PAD PAD PAD\n",
            "fra: SOS j etudie la racistes tot . EOS\n",
            "--------\n",
            "6-th example:\n",
            "eng: SOS you re free of all UNK . EOS PAD PAD PAD\n",
            "fra: vous etes UNK de toute UNK . EOS PAD PAD PAD PAD\n",
            "fra: SOS tu es content de partir toutes . EOS\n",
            "--------\n",
            "7-th example:\n",
            "eng: SOS you are more stupid than i thought . EOS PAD PAD\n",
            "fra: tu es plus idiot que je UNK . EOS PAD PAD PAD\n",
            "fra: SOS tu es plus supplie que vous sous grossiere . EOS\n",
            "--------\n",
            "8-th example:\n",
            "eng: SOS we re trying to UNK down on UNK . EOS PAD\n",
            "fra: nous tentons de UNK les UNK . EOS PAD PAD PAD PAD\n",
            "fra: SOS nous prenons chatouilleuse consciencieuse . EOS\n",
            "--------\n",
            "9-th example:\n",
            "eng: SOS she s suffering from a serious UNK . EOS PAD PAD\n",
            "fra: elle souffre d une UNK grave . EOS PAD PAD PAD PAD\n",
            "fra: SOS elle s ur un emploi . EOS\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    batch = build_batch(\"train\", batch_size=1)\n",
        "    print(f\"{i}-th example:\\n{src_language}: {src_lang.tensor_to_sentence(batch.src[0])}\")\n",
        "    print(f\"{target_language}: {target_lang.tensor_to_sentence(batch.tgt_y[0])}\")\n",
        "    out = mt_transformer.generate(batch.src, batch.src_mask, max_tokens=11)\n",
        "    print(f\"{target_language}: {target_lang.tensor_to_sentence(out[0])}\")\n",
        "    print(\"--------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grurso4YEh9x",
        "outputId": "c8668e61-8f16-495d-b79e-867d8e892916"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-th example:\n",
            "eng: SOS he s stronger than you . EOS PAD PAD PAD PAD\n",
            "fra: il est plus fort que vous . EOS PAD PAD PAD PAD\n",
            "fra: SOS il est plus interessante que vous . EOS\n",
            "--------\n",
            "1-th example:\n",
            "eng: SOS he is my friend . EOS PAD PAD PAD PAD PAD\n",
            "fra: il est mon ami . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: SOS c est mon moment . EOS\n",
            "--------\n",
            "2-th example:\n",
            "eng: SOS i am a stranger here . EOS PAD PAD PAD PAD\n",
            "fra: je suis un etranger ici . EOS PAD PAD PAD PAD PAD\n",
            "fra: SOS j ai une citoyenne allergique amende . EOS\n",
            "--------\n",
            "3-th example:\n",
            "eng: SOS we re all here . EOS PAD PAD PAD PAD PAD\n",
            "fra: nous sommes toutes ici . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: SOS nous sommes toutes ici . EOS\n",
            "--------\n",
            "4-th example:\n",
            "eng: SOS i am sick . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: je suis malade . EOS PAD PAD PAD PAD PAD PAD PAD\n",
            "fra: SOS j en suis rejoindre bizarre . EOS\n",
            "--------\n",
            "5-th example:\n",
            "eng: SOS you re fortunate . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: tu es chanceuse . EOS PAD PAD PAD PAD PAD PAD PAD\n",
            "fra: SOS vous etes chanceux . EOS\n",
            "--------\n",
            "6-th example:\n",
            "eng: SOS we re back . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: nous sommes de retour . EOS PAD PAD PAD PAD PAD PAD\n",
            "fra: SOS nous sommes aboutissons occupes . EOS\n",
            "--------\n",
            "7-th example:\n",
            "eng: SOS i m glad you came over . EOS PAD PAD PAD\n",
            "fra: je me rejouis que vous soyez venus . EOS PAD PAD PAD\n",
            "fra: SOS je suis heureux pour toi si ? EOS\n",
            "--------\n",
            "8-th example:\n",
            "eng: SOS he is a handsome man . EOS PAD PAD PAD PAD\n",
            "fra: c est un bel homme . EOS PAD PAD PAD PAD PAD\n",
            "fra: SOS ambition est un sens un homme . EOS\n",
            "--------\n",
            "9-th example:\n",
            "eng: SOS he s doing his best . EOS PAD PAD PAD PAD\n",
            "fra: il fait de son mieux . EOS PAD PAD PAD PAD PAD\n",
            "fra: SOS il fait citer de votre anglais . EOS\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m69EuR_4EQV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_mps_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "219301d06b24a901e45fde882757c1228fa788b1ab703da7f9c2352940fd5cfd"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}