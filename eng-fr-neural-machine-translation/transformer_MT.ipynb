{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English-French Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_language = 'eng'\n",
    "target_language = 'fra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.\\tVa !', 'Run!\\tCours\\u202f!', 'Run!\\tCourez\\u202f!', 'Wow!\\tÇa alors\\u202f!', 'Fire!\\tAu feu !']\n"
     ]
    }
   ],
   "source": [
    "# Read the file and split into lines\n",
    "with open('data/%s-%s.txt' % (src_language, target_language), encoding='utf-8') as file:\n",
    "    text_data = file.read().splitlines()\n",
    "print(text_data[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is in Unicode. So, we will take the following preprocessing steps:\n",
    "1. Turn Unicode characters to ASCII\n",
    "2. lowercase\n",
    "3. Trim most punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(sent):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', sent)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def preprocess_string(sent):\n",
    "    \"lowercase, unicode_to_ascii, trim, and remove non-letter characters\"\n",
    "    sent = sent.lower().strip()\n",
    "    sent = unicode_to_ascii(sent)\n",
    "    # The backreference \\1 (backslash one) references the first capturing group. \n",
    "    # space followed by \\1 matches the exact same text that was matched by the first capturing group [.!?].\n",
    "    sent = re.sub(r\"([.!?])\", r\" \\1\", sent)\n",
    "    # replace character which are not from this set (a-zA-Z.!?) by single space character\n",
    "    sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sent)\n",
    "    return sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow!\tÇa alors !\n",
      "['Ça alors\\u202f!', 'Wow!']\n"
     ]
    }
   ],
   "source": [
    "preprocess_string(text_data[3])\n",
    "print(text_data[3])\n",
    "print(text_data[3].split('\\t')[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, reverse=False):\n",
    "    print(\"Reading text file...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open('data/%s' % (file_name), encoding='utf-8') as file:\n",
    "        lines = file.read().splitlines()\n",
    "\n",
    "    # Split every line into pairs [src_lang, target_lang] and preprocess\n",
    "    pairs = [[preprocess_string(s) for s in line.split('\\t')] for line in lines]\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [p[::-1] for p in pairs]\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file...\n"
     ]
    }
   ],
   "source": [
    "pairs = load_data('eng-fra.txt', reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK = 2\n",
    "PAD = 3\n",
    "BLOCK_SIZE = 12\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, lang_name, src=True):\n",
    "        self.lang_name = lang_name\n",
    "        self.word_to_index = {}\n",
    "        self.index_to_word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3:\"PAD\"}\n",
    "        self.word_to_count = {}\n",
    "        self.vocab_size = 4\n",
    "        self.src = src\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word_to_index:\n",
    "            self.word_to_index[word] = self.vocab_size\n",
    "            self.index_to_word[self.vocab_size] = word\n",
    "            self.vocab_size += 1\n",
    "        self.word_to_count[word] = self.word_to_count.get(word, 0) + 1\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def sentence_to_indexes(self, sentence):\n",
    "        idxs = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index[\"UNK\"] for word in sentence.split(' ')]\n",
    "        return idxs\n",
    "        \n",
    "    def indexes_to_sentence(self, indexes):\n",
    "        return ' '.join([self.index_to_word[index] for index in indexes])\n",
    "\n",
    "    def sentence_to_tensor(self, sentence):\n",
    "        indexes = self.sentence_to_indexes(sentence)\n",
    "        indexes = [SOS_token] + indexes + [EOS_token]\n",
    "\n",
    "        max_len = BLOCK_SIZE if self.src else BLOCK_SIZE + 1\n",
    "        \n",
    "        if len(indexes) < max_len:\n",
    "            indexes += [PAD]*(max_len-len(indexes))\n",
    "        else:\n",
    "            indexes = indexes[:max_len]\n",
    "            \n",
    "        indexes = torch.tensor(indexes, dtype=torch.long)\n",
    "        return indexes\n",
    "\n",
    "    def tensor_to_sentence(self, idx_tensor):\n",
    "        if len(idx_tensor.shape) > 1:\n",
    "            idxs = idx_tensor.tolist()[0]\n",
    "        else:\n",
    "            idxs = idx_tensor.tolist()\n",
    "        sentence = self.indexes_to_sentence(idxs)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create language instances\n",
    "src_lang = Language(src_language)\n",
    "target_lang = Language(target_language)\n",
    "\n",
    "for src, target in pairs:\n",
    "    src_lang.add_sentence(src)\n",
    "    target_lang.add_sentence(target) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc. (accounting for apostrophes replaced earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p, reverse=False):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1 if reverse else 0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs, reverse):\n",
    "    return [pair for pair in pairs if filterPair(pair, reverse)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "Read text file and split into lines, split lines into pairs\n",
    "\n",
    "Normalize text, filter by length and content\n",
    "\n",
    "Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(src_lang, target_lang, reverse=False):\n",
    "    pairs = load_data('eng-fra.txt', reverse)\n",
    "\n",
    "    # create language instances\n",
    "    input_lang = Language(src_lang)\n",
    "    output_lang = Language(target_lang, src=False)\n",
    "\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs, reverse)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    # train/val/test split\n",
    "    n_total = len(pairs)\n",
    "    n_train = int(0.8*n_total)\n",
    "    n_val = int(0.1*n_total)\n",
    "    n_test = n_total - n_train - n_val\n",
    "    print(f\"{n_train=}, {n_val=}, {n_test=}\")\n",
    "    pair_split = {}\n",
    "    pair_split['train'] = pairs[:n_train]\n",
    "    pair_split['val'] = pairs[n_train:n_train + n_val]\n",
    "    pair_split['test'] = pairs[n_train + n_val:]\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    print(\"Creating source and target language vocab using pair_split['train']...\")\n",
    "    for src, target in pair_split['train']:\n",
    "        input_lang.add_sentence(src)\n",
    "        output_lang.add_sentence(target) \n",
    "\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.lang_name, input_lang.vocab_size)\n",
    "    print(output_lang.lang_name, output_lang.vocab_size)\n",
    "    return input_lang, output_lang, pair_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "n_train=8479, n_val=1059, n_test=1061\n",
      "Counting words...\n",
      "Creating source and target language vocab using pair_split['train']...\n",
      "Counted words:\n",
      "eng 2184\n",
      "fra 3526\n",
      "['they re very busy .', 'ils sont tres occupes .']\n"
     ]
    }
   ],
   "source": [
    "src_lang, target_lang, pair_split = create_dataset('eng', 'fra', reverse=False)\n",
    "print(random.choice(pair_split[\"train\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization: Words to indexes\n",
    "In seq2seq task takes an input sequence (source seq) and outputs another sequence (target seq). In our case, we have an input sentence in English language and a corresponding translated sentence in French language. These sentence need to converted into numbers (integers) to be able to into to a neural network. For this, we will use **word-level tokenization**, i.e *word to integer* index mapping.\n",
    "\n",
    "We need some special tokens to indicate start (SOS) and end (EOS) of a sentence. For the input sequence (source seq), the model needs to know when the input has ended and for the target sequence, the model needs to know when to start and when to end.\n",
    "\n",
    "So, we will append the EOS token to the end of input sentence and wrap the target sentence by SOS (in the beginning) and the EOS (in the end) tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sent_pair_to_tensor_pair(pair, src_lang, target_lang):\n",
    "    input_tensor = src_lang.sentence_to_tensor(pair[0])\n",
    "    target_tensor = target_lang.sentence_to_tensor(pair[1])\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "def tensor_pair_to_sent_pair(pair, src_lang, target_lang):\n",
    "    input_tensor = src_lang.tensor_to_sentence(pair[0])\n",
    "    target_tensor = target_lang.tensor_to_sentence(pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they re drunk .', 'elles sont saoules .']\n",
      "(tensor([  0, 223,  80,  58,   6,   1,   3,   3,   3,   3,   3,   3]), tensor([  0, 353, 351, 761,   7,   1,   3,   3,   3,   3,   3,   3,   3]))\n",
      "(tensor([  0, 223,  80,  58,   6,   1,   3,   3,   3,   3,   3,   3]), tensor([  0, 353, 351, 761,   7,   1,   3,   3,   3,   3,   3,   3,   3]))\n",
      "('SOS they re drunk . EOS PAD PAD PAD PAD PAD PAD', 'SOS elles sont saoules . EOS PAD PAD PAD PAD PAD PAD PAD')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choices(pair_split[\"train\"], k=1)[0]\n",
    "print(pair)\n",
    "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
    "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
    "\n",
    "p1, p2 = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
    "print(tensor_pair_to_sent_pair((p1,p2), src_lang, target_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, target=None, pad_idx=2) -> None:\n",
    "        # src and target sequences have same length\n",
    "        self.src = src #shape:(B,T)\n",
    "        # src_mask:(B,1,1,T)\n",
    "        self.src_mask = (src != pad_idx).unsqueeze(-2).unsqueeze(-2)\n",
    "        if target is not None:\n",
    "            # decoder output shifted by one\n",
    "            self.tgt = target[:,:-1] #shape:(B,T)\n",
    "            self.tgt_y = target[:,1:]\n",
    "            self.tgt_mask = self.causal_mask(self.tgt, pad_idx)\n",
    "            self.n_tokens = (self.tgt_y != pad_idx).sum().item()\n",
    "\n",
    "    @staticmethod   \n",
    "    def causal_mask(target, pad_idx):\n",
    "        # max context length = block_size\n",
    "        T = target.shape[1]\n",
    "        # causal attention mask: (1,T,T)\n",
    "        causal_attn_mask = torch.tril(torch.ones(1, T, T, dtype=torch.bool, device=target.device))\n",
    "        # padding mask: (B,1,T)\n",
    "        target_mask = (target != pad_idx).unsqueeze(-2)\n",
    "        target_mask = target_mask & causal_attn_mask\n",
    "        return target_mask.unsqueeze(1) # (B,1,T,T)\n",
    "\n",
    "        \n",
    "def build_batch(split, batch_size=4):\n",
    "    if split == \"train\":\n",
    "        pairs = pair_split[\"train\"]\n",
    "    elif split == \"val\":\n",
    "        pairs = pair_split[\"val\"]\n",
    "    else:\n",
    "        pairs = pair_split[\"test\"]\n",
    "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
    "    # number of sequences in a batch is batch_size\n",
    "    batch_pairs = random.choices(pairs, k=batch_size)\n",
    "    # input \n",
    "    src_batch = []\n",
    "    target_batch = []\n",
    "    \n",
    "    for pair in batch_pairs:\n",
    "        src_tensor, target_tensor = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
    "        src_batch.append(src_tensor)\n",
    "        target_batch.append(target_tensor)\n",
    "    \n",
    "    src = torch.stack(src_batch).to(device)\n",
    "    target = torch.stack(target_batch).to(device)\n",
    "\n",
    "    batch = Batch(src, target, PAD)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = build_batch(\"train\", batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS he s such a jerk . EOS PAD PAD PAD PAD\n",
      "SOS c est un tel pauvre type ! EOS PAD PAD PAD\n",
      "c est un tel pauvre type ! EOS PAD PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "print(src_lang.tensor_to_sentence(b.src))\n",
    "print(target_lang.tensor_to_sentence(b.tgt))\n",
    "print(target_lang.tensor_to_sentence(b.tgt_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq English-French Machine Translation Transformer Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from transformers.transformer import EncDecTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyparam = {\n",
    "    \"src_vocab_size\": src_lang.vocab_size,\n",
    "    \"tgt_vocab_size\": target_lang.vocab_size,\n",
    "    \"block_size\": BLOCK_SIZE,\n",
    "    \"model_dim\": 32,\n",
    "    \"n_layer\": 2,\n",
    "    \"n_head\": 2,\n",
    "    \"cross_attention\":True\n",
    "}\n",
    "mt_transformer = EncDecTransformer(**hyparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Batch at 0x7f8b00c7ef40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = build_batch(\"train\", batch_size=2)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n",
      "torch.Size([2, 1, 1, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n",
      "torch.Size([2, 1, 12, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n",
      "torch.Size([2, 1, 1, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n",
      "torch.Size([2, 1, 12, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n",
      "torch.Size([2, 1, 1, 12])\n",
      "torch.Size([2, 12, 2, 16])\n",
      "torch.Size([2, 12, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4225, -0.0354, -0.3371,  ...,  0.1326, -0.1471,  0.0289],\n",
       "         [-0.8744, -0.1260,  0.5059,  ...,  0.1743, -0.1695,  0.4680],\n",
       "         [-0.0316, -0.5198, -0.2695,  ..., -1.2166,  0.5251, -0.1177],\n",
       "         ...,\n",
       "         [-0.4402, -0.0405,  0.4402,  ..., -0.2019, -0.6821, -0.1396],\n",
       "         [-0.0416, -0.3128,  0.8035,  ..., -0.6277,  0.0976,  0.4441],\n",
       "         [-0.3491, -0.2754,  0.2962,  ...,  0.1353,  0.8226, -0.2927]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(8.1203, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_transformer(batch.src, \n",
    "            batch.src_mask,\n",
    "            batch.tgt,\n",
    "            batch.tgt_mask,batch.tgt_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  4,  5, 74,  6,  1,  3,  3,  3,  3,  3,  3]]),\n",
       " tensor([[[[ True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "            False, False]]]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.src[0:1], batch.src_mask[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1, 12])\n",
      "torch.Size([1, 12, 2, 16])\n",
      "torch.Size([1, 12, 32])\n",
      "torch.Size([1, 1, 1, 12])\n",
      "torch.Size([1, 12, 2, 16])\n",
      "torch.Size([1, 12, 32])\n",
      "torch.Size([1, 1, 1, 1])\n",
      "torch.Size([1, 1, 2, 16])\n",
      "torch.Size([1, 1, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 2, 16]' is invalid for input of size 384",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/swechha/projects/nlp-from-scratch/eng-fr-neural-machine-translation/transformer_MT.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/swechha/projects/nlp-from-scratch/eng-fr-neural-machine-translation/transformer_MT.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mt_transformer\u001b[39m.\u001b[39;49mgenerate(batch\u001b[39m.\u001b[39;49msrc[\u001b[39m0\u001b[39;49m:\u001b[39m1\u001b[39;49m], batch\u001b[39m.\u001b[39;49msrc_mask[\u001b[39m0\u001b[39;49m:\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/projects/nlp-from-scratch/eng-fr-neural-machine-translation/../transformers/transformer.py:84\u001b[0m, in \u001b[0;36mEncDecTransformer.generate\u001b[0;34m(self, src, src_mask, max_tokens, sos, eos)\u001b[0m\n\u001b[1;32m     73\u001b[0m tgt_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtril(\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mones(\n\u001b[1;32m     75\u001b[0m         \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[39m# block_size is the maximum context length of our LM, therefore we can only use last block_size characters as input to generate next character\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m dec_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecode(tgt, tgt_mask, memory, src_mask)\n\u001b[1;32m     85\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoded_target_proj(dec_out)\n\u001b[1;32m     86\u001b[0m \u001b[39m# dec_inp: (B,T_dec) logits: (B, T_dec, vocab_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/nlp-from-scratch/eng-fr-neural-machine-translation/../transformers/transformer.py:50\u001b[0m, in \u001b[0;36mEncDecTransformer.decode\u001b[0;34m(self, target, target_mask, memory, src_mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39m# broadcast pos_emb along the batch dimension of token_emb\u001b[39;00m\n\u001b[1;32m     48\u001b[0m token_emb \u001b[39m=\u001b[39m token_emb \u001b[39m+\u001b[39m pos_emb\n\u001b[0;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(token_emb, target_mask, memory, src_mask)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_env_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nlp-from-scratch/eng-fr-neural-machine-translation/../transformers/transformer.py:128\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, target_mask, memory, src_mask)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, target_mask, memory\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, src_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    127\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 128\u001b[0m         x \u001b[39m=\u001b[39m layer(x, target_mask, memory, src_mask)\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_env_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nlp-from-scratch/eng-fr-neural-machine-translation/../transformers/transformer.py:175\u001b[0m, in \u001b[0;36mTransformerDecoderBlock.forward\u001b[0;34m(self, x, tgt_mask, memory, src_mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn_layer(x_norm, x_norm, x_norm, tgt_mask)\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attention:\n\u001b[0;32m--> 175\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attn_layer(\n\u001b[1;32m    176\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attn_layer_norm(x),  \u001b[39m# query\u001b[39;49;00m\n\u001b[1;32m    177\u001b[0m         memory,  \u001b[39m# key\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m         memory,  \u001b[39m# value\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m         src_mask,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff_layer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mffn_layer_norm(x))\n\u001b[1;32m    182\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_env_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/nlp-from-scratch/eng-fr-neural-machine-translation/../transformers/transformer.py:223\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    217\u001b[0m B, T, model_dim \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mshape\n\u001b[1;32m    218\u001b[0m query \u001b[39m=\u001b[39m (\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_proj(query)\n\u001b[1;32m    220\u001b[0m     \u001b[39m.\u001b[39mview(B, T, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[1;32m    221\u001b[0m     \u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 223\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_proj(key)\u001b[39m.\u001b[39;49mview(B, T, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_head, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    224\u001b[0m value \u001b[39m=\u001b[39m (\n\u001b[1;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_proj(value)\n\u001b[1;32m    226\u001b[0m     \u001b[39m.\u001b[39mview(B, T, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_head, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[1;32m    227\u001b[0m     \u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[39m# head_out: (B,T,n_head,head_dim)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 2, 16]' is invalid for input of size 384"
     ]
    }
   ],
   "source": [
    "mt_transformer.generate(batch.src[0:1], batch.src_mask[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[SOS_token],[SOS_token]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['enc_inp'][1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02a75899b11e31bd85ccc905c76a128ad2bb11b6b68df04d39be7741d54ebc47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
