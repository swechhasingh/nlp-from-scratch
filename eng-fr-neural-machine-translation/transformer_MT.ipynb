{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English-French Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_language = 'eng'\n",
    "target_language = 'fra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.\\tVa !', 'Run!\\tCours\\u202f!', 'Run!\\tCourez\\u202f!', 'Wow!\\tÇa alors\\u202f!', 'Fire!\\tAu feu !']\n"
     ]
    }
   ],
   "source": [
    "# Read the file and split into lines\n",
    "with open('data/%s-%s.txt' % (src_language, target_language), encoding='utf-8') as file:\n",
    "    text_data = file.read().splitlines()\n",
    "print(text_data[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is in Unicode. So, we will take the following preprocessing steps:\n",
    "1. Turn Unicode characters to ASCII\n",
    "2. lowercase\n",
    "3. Trim most punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(sent):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', sent)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def preprocess_string(sent):\n",
    "    \"lowercase, unicode_to_ascii, trim, and remove non-letter characters\"\n",
    "    sent = sent.lower().strip()\n",
    "    sent = unicode_to_ascii(sent)\n",
    "    # The backreference \\1 (backslash one) references the first capturing group. \n",
    "    # space followed by \\1 matches the exact same text that was matched by the first capturing group [.!?].\n",
    "    sent = re.sub(r\"([.!?])\", r\" \\1\", sent)\n",
    "    # replace character which are not from this set (a-zA-Z.!?) by single space character\n",
    "    sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sent)\n",
    "    return sent.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow!\tÇa alors !\n",
      "['Ça alors\\u202f!', 'Wow!']\n"
     ]
    }
   ],
   "source": [
    "preprocess_string(text_data[3])\n",
    "print(text_data[3])\n",
    "print(text_data[3].split('\\t')[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, reverse=False):\n",
    "    print(\"Reading text file...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    with open('data/%s' % (file_name), encoding='utf-8') as file:\n",
    "        lines = file.read().splitlines()\n",
    "\n",
    "    # Split every line into pairs [src_lang, target_lang] and preprocess\n",
    "    pairs = [[preprocess_string(s) for s in line.split('\\t')] for line in lines]\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [p[::-1] for p in pairs]\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file...\n"
     ]
    }
   ],
   "source": [
    "pairs = load_data('eng-fra.txt', reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK = 2\n",
    "PAD = 3\n",
    "BLOCK_SIZE = 12\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, lang_name, src=True):\n",
    "        self.lang_name = lang_name\n",
    "        self.word_to_index = {\"SOS\":0, \"EOS\":1, \"UNK\": 2, \"PAD\":3}\n",
    "        self.index_to_word = {0: \"SOS\", 1: \"EOS\", 2: \"UNK\", 3:\"PAD\"}\n",
    "        self.word_to_count = {}\n",
    "        self.vocab_size = 4\n",
    "        self.src = src\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word_to_index:\n",
    "            self.word_to_index[word] = self.vocab_size\n",
    "            self.index_to_word[self.vocab_size] = word\n",
    "            self.vocab_size += 1\n",
    "        self.word_to_count[word] = self.word_to_count.get(word, 0) + 1\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def sentence_to_indexes(self, sentence):\n",
    "        idxs = [self.word_to_index[word] if word in self.word_to_index else self.word_to_index[\"UNK\"] for word in sentence.split(' ')]\n",
    "        return idxs\n",
    "        \n",
    "    def indexes_to_sentence(self, indexes):\n",
    "        return ' '.join([self.index_to_word[index] for index in indexes])\n",
    "\n",
    "    def sentence_to_tensor(self, sentence):\n",
    "        indexes = self.sentence_to_indexes(sentence)\n",
    "        indexes = [SOS_token] + indexes + [EOS_token]\n",
    "\n",
    "        max_len = BLOCK_SIZE if self.src else BLOCK_SIZE + 1\n",
    "        \n",
    "        if len(indexes) < max_len:\n",
    "            indexes += [PAD]*(max_len-len(indexes))\n",
    "        else:\n",
    "            indexes = indexes[:max_len]\n",
    "            \n",
    "        indexes = torch.tensor(indexes, dtype=torch.long)\n",
    "        return indexes\n",
    "\n",
    "    def tensor_to_sentence(self, idx_tensor):\n",
    "        if len(idx_tensor.shape) > 1:\n",
    "            idxs = idx_tensor.tolist()[0]\n",
    "        else:\n",
    "            idxs = idx_tensor.tolist()\n",
    "        sentence = self.indexes_to_sentence(idxs)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create language instances\n",
    "src_lang = Language(src_language)\n",
    "target_lang = Language(target_language)\n",
    "\n",
    "for src, target in pairs:\n",
    "    src_lang.add_sentence(src)\n",
    "    target_lang.add_sentence(target) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc. (accounting for apostrophes replaced earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p, reverse=False):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1 if reverse else 0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs, reverse):\n",
    "    return [pair for pair in pairs if filterPair(pair, reverse)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "Read text file and split into lines, split lines into pairs\n",
    "\n",
    "Normalize text, filter by length and content\n",
    "\n",
    "Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(src_lang, target_lang, reverse=False):\n",
    "    pairs = load_data('eng-fra.txt', reverse)\n",
    "\n",
    "    # create language instances\n",
    "    input_lang = Language(src_lang)\n",
    "    output_lang = Language(target_lang, src=False)\n",
    "\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs, reverse)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "\n",
    "    # train/val/test split\n",
    "    n_total = len(pairs)\n",
    "    n_train = int(0.8*n_total)\n",
    "    n_val = int(0.1*n_total)\n",
    "    n_test = n_total - n_train - n_val\n",
    "    print(f\"{n_train=}, {n_val=}, {n_test=}\")\n",
    "    pair_split = {}\n",
    "    pair_split['train'] = pairs[:n_train]\n",
    "    pair_split['val'] = pairs[n_train:n_train + n_val]\n",
    "    pair_split['test'] = pairs[n_train + n_val:]\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    print(\"Creating source and target language vocab using pair_split['train']...\")\n",
    "    for src, target in pair_split['train']:\n",
    "        input_lang.add_sentence(src)\n",
    "        output_lang.add_sentence(target) \n",
    "\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.lang_name, input_lang.vocab_size)\n",
    "    print(output_lang.lang_name, output_lang.vocab_size)\n",
    "    return input_lang, output_lang, pair_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading text file...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "n_train=8479, n_val=1059, n_test=1061\n",
      "Counting words...\n",
      "Creating source and target language vocab using pair_split['train']...\n",
      "Counted words:\n",
      "eng 2184\n",
      "fra 3526\n",
      "['he s a gambler .', 'c est un joueur .']\n"
     ]
    }
   ],
   "source": [
    "src_lang, target_lang, pair_split = create_dataset('eng', 'fra', reverse=False)\n",
    "print(random.choice(pair_split[\"train\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization: Words to indexes\n",
    "In seq2seq task takes an input sequence (source seq) and outputs another sequence (target seq). In our case, we have an input sentence in English language and a corresponding translated sentence in French language. These sentence need to converted into numbers (integers) to be able to into to a neural network. For this, we will use **word-level tokenization**, i.e *word to integer* index mapping.\n",
    "\n",
    "We need some special tokens to indicate start (SOS) and end (EOS) of a sentence. For the input sequence (source seq), the model needs to know when the input has ended and for the target sequence, the model needs to know when to start and when to end.\n",
    "\n",
    "So, we will append the EOS token to the end of input sentence and wrap the target sentence by SOS (in the beginning) and the EOS (in the end) tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sent_pair_to_tensor_pair(pair, src_lang, target_lang):\n",
    "    input_tensor = src_lang.sentence_to_tensor(pair[0])\n",
    "    target_tensor = target_lang.sentence_to_tensor(pair[1])\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "def tensor_pair_to_sent_pair(pair, src_lang, target_lang):\n",
    "    input_tensor = src_lang.tensor_to_sentence(pair[0])\n",
    "    target_tensor = target_lang.tensor_to_sentence(pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i m still not ready .', 'je ne suis pas encore pret .']\n",
      "(tensor([  0,   4,   5, 527, 149,  68,   6,   1,   3,   3,   3,   3]), tensor([  0,   8, 299,  13, 248, 965, 107,   7,   1,   3,   3,   3,   3]))\n",
      "(tensor([  0,   4,   5, 527, 149,  68,   6,   1,   3,   3,   3,   3]), tensor([  0,   8, 299,  13, 248, 965, 107,   7,   1,   3,   3,   3,   3]))\n",
      "('SOS i m still not ready . EOS PAD PAD PAD PAD', 'SOS je ne suis pas encore pret . EOS PAD PAD PAD PAD')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choices(pair_split[\"train\"], k=1)[0]\n",
    "print(pair)\n",
    "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
    "print(sent_pair_to_tensor_pair(pair, src_lang, target_lang))\n",
    "\n",
    "p1, p2 = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
    "print(tensor_pair_to_sent_pair((p1,p2), src_lang, target_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, target=None, pad_idx=2) -> None:\n",
    "        # src and target sequences have same length\n",
    "        self.src = src #shape:(B,T)\n",
    "        # src_mask:(B,1,1,T)\n",
    "        self.src_mask = (src != pad_idx).unsqueeze(-2).unsqueeze(-2)\n",
    "        if target is not None:\n",
    "            # decoder output shifted by one\n",
    "            self.tgt = target[:,:-1] #shape:(B,T)\n",
    "            self.tgt_y = target[:,1:]\n",
    "            # padding mask: (B,T)\n",
    "            self.tgt_pad_mask = (self.tgt_y != pad_idx)\n",
    "            self.tgt_mask = self.causal_mask(self.tgt, pad_idx)\n",
    "            self.n_tokens = self.tgt_pad_mask.sum().item()\n",
    "\n",
    "    @staticmethod   \n",
    "    def causal_mask(target, pad_idx):\n",
    "        # max context length = block_size\n",
    "        T = target.shape[1]\n",
    "        # causal attention mask: (1,T,T)\n",
    "        causal_attn_mask = torch.tril(torch.ones(1, T, T, dtype=torch.bool, device=target.device))\n",
    "        # padding mask: (B,1,T)\n",
    "        tgt_pad_mask = (target != pad_idx).unsqueeze(-2)\n",
    "        target_mask = tgt_pad_mask & causal_attn_mask\n",
    "        return target_mask.unsqueeze(1) # (B,1,T,T)\n",
    "\n",
    "        \n",
    "def build_batch(split, batch_size=4):\n",
    "    if split == \"train\":\n",
    "        pairs = pair_split[\"train\"]\n",
    "    elif split == \"val\":\n",
    "        pairs = pair_split[\"val\"]\n",
    "    else:\n",
    "        pairs = pair_split[\"test\"]\n",
    "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
    "    # number of sequences in a batch is batch_size\n",
    "    batch_pairs = random.choices(pairs, k=batch_size)\n",
    "    # input \n",
    "    src_batch = []\n",
    "    target_batch = []\n",
    "    \n",
    "    for pair in batch_pairs:\n",
    "        src_tensor, target_tensor = sent_pair_to_tensor_pair(pair, src_lang, target_lang)\n",
    "        src_batch.append(src_tensor)\n",
    "        target_batch.append(target_tensor)\n",
    "    \n",
    "    src = torch.stack(src_batch).to(device)\n",
    "    target = torch.stack(target_batch).to(device)\n",
    "\n",
    "    batch = Batch(src, target, PAD)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = build_batch(\"train\", batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS i m not a native speaker . EOS PAD PAD PAD\n",
      "SOS je ne suis pas un locuteur natif . EOS PAD PAD\n",
      "je ne suis pas un locuteur natif . EOS PAD PAD PAD\n"
     ]
    }
   ],
   "source": [
    "print(src_lang.tensor_to_sentence(b.src))\n",
    "print(target_lang.tensor_to_sentence(b.tgt))\n",
    "print(target_lang.tensor_to_sentence(b.tgt_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seq2Seq English-French Machine Translation Transformer Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from transformers.transformer import EncDecTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "model_hyparam = {\n",
    "    \"src_vocab_size\": src_lang.vocab_size,\n",
    "    \"tgt_vocab_size\": target_lang.vocab_size,\n",
    "    \"block_size\": BLOCK_SIZE,\n",
    "    \"model_dim\": 32,\n",
    "    \"n_layer\": 2,\n",
    "    \"n_head\": 2,\n",
    "    \"cross_attention\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Batch at 0x7fe92187b400>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = build_batch(\"train\", batch_size=4)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "batch_size = 16\n",
    "n_iters = 10\n",
    "eval_interval = 1#100\n",
    "base_lr = 1.0\n",
    "eval_iters = 2\n",
    "warmup_steps = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary the learning rate over the course of training, according to the formula:<br>\n",
    "<br>\n",
    "$lr = {d_{model}}^{-0.5}*\\min({step\\_num}^{-0.5}, step\\_num * {warmup\\_steps}^{-1.5})$\n",
    "<br>\n",
    "This corresponds to increasing the learning rate linearly for the first $warmup\\_steps$ training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(step, model_size, factor, warmup):\n",
    "    # default the step to 1 for LambdaLR function to avoid zero raising to negative power\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.350406 M parameters\n"
     ]
    }
   ],
   "source": [
    "mt_transformer = EncDecTransformer(**model_hyparam).to(device)\n",
    "optimizer = torch.optim.AdamW(mt_transformer.parameters(), base_lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda step: learning_rate(step, \n",
    "                                                                        model_hyparam[\"model_dim\"], \n",
    "                                                                        factor=1, warmup=warmup_steps))\n",
    "\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in mt_transformer.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.08036331508470618, 'val': 0.06482066069131695}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def compute_loss():\n",
    "    mt_transformer.eval()\n",
    "    out_loss = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        running_loss = 0.0\n",
    "        total_tokens = 0\n",
    "        for _ in range(eval_iters):\n",
    "            batch = build_batch(split, batch_size)\n",
    "            _, loss = mt_transformer(batch.src, \n",
    "                                batch.src_mask,\n",
    "                                batch.tgt,\n",
    "                                batch.tgt_mask,\n",
    "                                batch.tgt_y,\n",
    "                                batch.tgt_pad_mask)\n",
    "            running_loss += loss.item()\n",
    "            total_tokens += batch.n_tokens\n",
    "        out_loss[split] = running_loss/total_tokens\n",
    "    mt_transformer.train()\n",
    "    return out_loss\n",
    "compute_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 0.0723, val loss 0.0569\n",
      "step 1: train loss 0.0694, val loss 0.0550\n",
      "step 2: train loss 0.0542, val loss 0.0490\n",
      "step 3: train loss 0.0481, val loss 0.0434\n",
      "step 4: train loss 0.0467, val loss 0.0442\n",
      "step 5: train loss 0.0501, val loss 0.0470\n",
      "step 6: train loss 0.0442, val loss 0.0475\n",
      "step 7: train loss 0.0493, val loss 0.0443\n",
      "step 8: train loss 0.0423, val loss 0.0458\n",
      "step 9: train loss 0.0458, val loss 0.0474\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def train():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for iter in range(n_iters):\n",
    "        mt_transformer.train()\n",
    "        batch = build_batch(\"train\", batch_size)\n",
    "        _, loss = mt_transformer(batch.src, \n",
    "                                    batch.src_mask,\n",
    "                                    batch.tgt,\n",
    "                                    batch.tgt_mask,\n",
    "                                    batch.tgt_y,\n",
    "                                    batch.tgt_pad_mask)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        if iter % eval_interval == 0 or iter == n_iters - 1:\n",
    "            losses = compute_loss()\n",
    "            train_losses.append(losses['train'])\n",
    "            val_losses.append(losses['val'])\n",
    "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "            # save model checkpoint\n",
    "            torch.save(mt_transformer.state_dict(), \"mt_transformer.pt\")\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04581827791328104, 0.04735226824714689)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses[-1], val_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe921895e50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4sElEQVR4nO3deXxU5dXA8d/JDgmQkLCEfd8TtoCsCqIIhE1FBbUiVnDDqthW9O1b7VtttWqruGBRVFQUEZdS2RRUEAQk7DsJeyBkJQmEhGzP+8edSIgBBjIzN8mc7+eTTzJ37sxzZpTn3PusYoxBKaWU9/GxOwCllFL20ASglFJeShOAUkp5KU0ASinlpTQBKKWUl/KzO4DLERERYVq0aGF3GEopVaVs3LgxzRhTr+zxKpUAWrRoQVxcnN1hKKVUlSIih8s7rk1ASinlpTQBKKWUl9IEoJRSXqpK9QEopdTlKigoIDExkby8PLtDcbugoCCaNGmCv7+/U+drAlBKVWuJiYnUqlWLFi1aICJ2h+M2xhjS09NJTEykZcuWTr1Gm4CUUtVaXl4e4eHh1bryBxARwsPDL+tORxOAUqraq+6Vf4nL/ZxekQDWJKTx7uqD5BcW2x2KUkpVGl6RAJbtPMH/fb2LG15ZxbKdJ9A9EJRSnpSZmcmbb7552a8bMWIEmZmZrg/IwSsSwF9Gd+a9u3vh6yPc9+FGxs9ax/bELLvDUkp5iQslgKKioou+bvHixYSGhropKi9JACLC4A71WfrIQP46tgsJKacZ9fpqpn26haSsXLvDU0pVc9OnT2f//v1069aNXr16MXjwYG6//XaioqIAGDt2LD179qRz587MmjXrl9e1aNGCtLQ0Dh06RMeOHZk8eTKdO3dm6NCh5OZWvO6SqtQcEhMTY1yxFlB2XgEzf9jP7NUH8RGYPLAV91/TmuBAHRWrVHWze/duOnbsCMBf/ruTXcezXfr+nRrV5ulRnS96zqFDhxg5ciQ7duzghx9+IDY2lh07dvwyXDMjI4O6deuSm5tLr169WLlyJeHh4b+sf3b69GnatGlDXFwc3bp149Zbb2X06NHceeedF/28JURkozEmpuy5XnEHUFbtIH+eGNaBFdOuYWinhrz2XQLXvPgD834+QlFx1UmISqmqqXfv3ueN1Z8xYwZdu3alT58+HD16lPj4+F+9pmXLlnTr1g2Anj17cujQoQrH4dWXvE3r1mTGhO5M6t+C5xbtZvoX23n/p0M8NaIjV7f71cqpSqkq7lJX6p4SHBz8y98//PADy5cvZ+3atdSsWZNBgwaVO5Y/MDDwl799fX1d0gTklXcAZXVvFsZn9/flzTt6cCa/iLve/Zm73/uZfcmn7A5NKVUN1KpVi1Onyq9PsrKyCAsLo2bNmuzZs4d169Z5LC6vvgMoTUQYERXJkI71+eCnw8z4Lp5hr6xiQu9mPHZ9OyJCAi/9JkopVY7w8HD69+9Ply5dqFGjBg0aNPjluWHDhvHWW28RHR1N+/bt6dOnj8fi8spOYGeczMnn1RXxfLTuMEH+vjwwqDW/HdCSIH9fj5SvlHKN8jpFqzPtBHaBsOAAnhndmW8eu5q+rcN5cdlehry8kv9sOUaxdhQrpaoBTQCX0KpeCG/fFcMnk/sQFuzPI/O2cOPMn4g7lGF3aEopVSGaAJzUt3U4Cx8awMu3dCU5K49xb63lgY82cjg9x+7QlFLqijiVAERkmIjsFZEEEZlezvMiIjMcz28TkR6O4+1FZEupn2wRedTxXF0R+VZE4h2/w1z6ydzAx0e4uWcTvv/9IKZd346V+1K57p8refbrXWSdKbA7PKWUuiyXTAAi4gu8AQwHOgETRKRTmdOGA20dP1OAmQDGmL3GmG7GmG5AT+AM8KXjNdOBFcaYtsAKx+MqoUaAL78b0pYffj+Im7o3Yfaag1zz0ve64qhSqkpx5g6gN5BgjDlgjMkH5gFjypwzBvjAWNYBoSISWeacIcB+Y8zhUq+Z4/h7DjD2Sj6AnerXDuKFcdEs/t1AohrX0RVHlVJVijMJoDFwtNTjRMexyz1nPPBJqccNjDFJAI7f9Z0JuDLqGFmbD+7pzXuTdMVRpVTFhYSEeKQcZxJAeVvMlL28veg5IhIAjAY+cz60X147RUTiRCQuNTX1cl/uMSLC4PbWiqPP6oqjSqkqwJmZwIlA01KPmwDHL/Oc4cAmY0xyqWPJIhJpjElyNBellFe4MWYWMAusiWBOxGsrP18f7uzTnDHdGvGmY8XRxTuSdMVRpbzYE088QfPmzXnwwQcBeOaZZxARVq1axcmTJykoKODZZ59lzJiyrevudcmZwCLiB+zDasM/BmwAbjfG7Cx1TiwwFRgBXAXMMMb0LvX8PGCZMea9UsdeBNKNMc87RhbVNcb88WKxeHImsKsknjzDP5buZeHW40SEBPLCzVEM6djg0i9USrnEeTNjl0yHE9tdW0DDKBj+/EVP2bx5M48++igrV64EoFOnTixdupTQ0FBq165NWloaffr0IT4+HhEhJCSE06dPX1E4Lp0JbIwpxKrclwG7gfnGmJ0icr+I3O84bTFwAEgA3gYeLFVwTeB64Isyb/08cL2IxDuev/g3WEU1CbNWHP3ywX6E1vTnf7/aoR3ESnmZ7t27k5KSwvHjx9m6dSthYWFERkby1FNPER0dzXXXXcexY8dITk6+9Ju5kFPtEcaYxViVfOljb5X62wAPXeC1Z4Dwco6nY91VeIXuzcJ4cFBrps3fyuajmfRoVumnPShV/VziSt2dxo0bx4IFCzhx4gTjx49n7ty5pKamsnHjRvz9/WnRokW5y0C7k84E9qDrOjUgwNeHRduS7A5FKeVh48ePZ968eSxYsIBx48aRlZVF/fr18ff35/vvv+fw4cOXfhMX0wTgQbWD/Lm6XT0Wb0/SBeWU8jKdO3fm1KlTNG7cmMjISO644w7i4uKIiYlh7ty5dOjQweMx6ZAUDxvVNZLlu5PZfPQkPZvXtTscpZQHbd9+rgM6IiKCtWvXlnvelXYAXy69A/CwIR0bEODnw9faDKSUspkmAA8LCfRjcHttBlJK2U8TgA1ioxuRnH2WuMMn7Q5FKa/gLUOvL/dzagKwwZAO9Qn082HRtrITqpVSrhYUFER6enq1TwLGGNLT0wkKCnL6NdoJbIPgQD+u7VCfxTtO8OdRnfH1KW8pJaWUKzRp0oTExEQq81pirhIUFESTJk2cPl8TgE1ioyNZsuMEGw5l0KfVr+bJKaVcxN/fn5YtW9odRqWkTUA2ubZDfWr4++qkMKWUbTQB2KRmgB/XdqzPkh1JFOloIKWUDTQB2GhkVCRpp/NZfyDd7lCUUl5IE4CNBrWvT80AX77ers1ASinP0wRgoxoBvgzp2IClO05QWKSbySulPEsTgM1ioyLJyMln3YEMu0NRSnkZTQA2G9S+HsEBvizarpPClFKepQnAZkH+vlzfyWoGKtBmIKWUB2kCqARioxtx8kwBa/fraCCllOdoAqgEBraNoFagH1/r2kBKKQ/SBFAJlDQDLduZTH6hNgMppTxDE0AlERsdSVZuAWv2p9kdilLKS2gCqCQGtI2gVpCfrg2klPIYTQCVRKCfL0M7NWTZzhPaDKSU8ghNAJXIyK6RnMorZHVC9V+3XCllP6cSgIgME5G9IpIgItPLeV5EZIbj+W0i0qPUc6EiskBE9ojIbhHp6zj+jIgcE5Etjp8RrvtYVVP/1hHUqeHP11u1GUgp5X6X3BBGRHyBN4DrgURgg4gsNMbsKnXacKCt4+cqYKbjN8CrwFJjzDgRCQBqlnrdv4wxL1X8Y1QPAX4+3NC5AUu2nyCvoIggf1+7Q1JKVWPO3AH0BhKMMQeMMfnAPGBMmXPGAB8YyzogVEQiRaQ2cDUwG8AYk2+MyXRd+NVPbHQjTp0t5Md4HQ2klHIvZxJAY+BoqceJjmPOnNMKSAXeE5HNIvKOiASXOm+qo8noXREJK69wEZkiInEiEucNe3r2ax1OaE1/3TBeKeV2ziSA8nYsL7uF1YXO8QN6ADONMd2BHKCkD2Em0BroBiQBL5dXuDFmljEmxhgTU69ePSfCrdr8fX0Y1rkh3+5KJq+gyO5wlFLVmDMJIBFoWupxE6Ds5emFzkkEEo0x6x3HF2AlBIwxycaYImNMMfA2VlOTwpoUlpNfxMp91f+ORyllH2cSwAagrYi0dHTijgcWljlnIXCXYzRQHyDLGJNkjDkBHBWR9o7zhgC7AEQkstTrbwR2VOSDVCd9W4VTNzhAJ4UppdzqkqOAjDGFIjIVWAb4Au8aY3aKyP2O598CFgMjgATgDDCp1Fs8DMx1JI8DpZ77h4h0w2oqOgTc54oPVB34+fowrEtDvtp8jNz8ImoE6GggpZTrXTIBABhjFmNV8qWPvVXqbwM8dIHXbgFiyjn+m8sJ1NuMjIrk4/VH+GFvCsOjIi/9AqWUukw6E7iS6t2yLhEhAbphvFLKbTQBVFIlzUDf7U7hTH6h3eEopaohTQCVWGxUI3ILivh+j44GUkq5niaASqx3y7rUqxWoG8YrpdxCE0Al5usjjOjSkO/2pJBzVpuBlFKupQmgkouNbkReQTEr9qTYHYpSqprRBFDJxTQPo36tQF0bSCnlcpoAKjkfH2FEVCTf703ltDYDKaVcSBNAFTAyOpL8wmJW7E62OxSlVDWiCaAK6NEsjIa1g/ha1wZSSrmQJoAqoKQZaOXeVE7lFdgdjlKqmtAEUEWM7BpJflExy7UZSCnlIpoAqojuTUNpHFpDN4xXSrmMJoAqQkQYEdWQVfGpZOVqM5BSquI0AVQhsdGNKCgyfLtLm4GUUhWnCaAK6dqkDo1Da+ikMKWUS2gCqEJEhJHRkfwYn0bWGW0GUkpVjCaAKiY2OpLCYsOyXSfsDkUpVcVpAqhiohrXoVndmrphvFKqwjQBVDEiQmx0JGsS0jiZk293OEqpKkwTQBUUG+VoBtqpzUBKqSunCaAK6tyoNi3Ca7JIN4xXSlWAJoAqqKQZ6Kf96aSfPmt3OEqpKkoTQBUVG9WIomLDsp06KUwpdWWcSgAiMkxE9opIgohML+d5EZEZjue3iUiPUs+FisgCEdkjIrtFpK/jeF0R+VZE4h2/w1z3saq/jpG1aBURrBvGK6Wu2CUTgIj4Am8Aw4FOwAQR6VTmtOFAW8fPFGBmqedeBZYaYzoAXYHdjuPTgRXGmLbACsdj5aSSSWFr96eTekqbgZRSl8+ZO4DeQIIx5oAxJh+YB4wpc84Y4ANjWQeEikikiNQGrgZmAxhj8o0xmaVeM8fx9xxgbIU+iReKjW5EsYGlOhpIKXUFnEkAjYGjpR4nOo45c04rIBV4T0Q2i8g7IhLsOKeBMSYJwPG7fnmFi8gUEYkTkbjU1FQnwvUe7RqE0KZ+iK4NpJS6Is4kACnnmHHyHD+gBzDTGNMdyOEym3qMMbOMMTHGmJh69epdzkurPREhNiqS9QczSDmVZ3c4SqkqxpkEkAg0LfW4CVD2kvNC5yQCicaY9Y7jC7ASAkCyiEQCOH6nXF7oCqy1gYyBpTu0GUgpdXmcSQAbgLYi0lJEAoDxwMIy5ywE7nKMBuoDZBljkowxJ4CjItLecd4QYFep10x0/D0R+E9FPoi3ategFu0ahOiG8Uqpy3bJBGCMKQSmAsuwRvDMN8bsFJH7ReR+x2mLgQNAAvA28GCpt3gYmCsi24BuwN8cx58HrheReOB6x2N1BWKjGrHhUAbJ2doMpJRynhhTtjm/8oqJiTFxcXF2h1HpJKSc5rp/ruTpUZ2Y1L+l3eEopSoZEdlojIkpe1xnAlcDbeqH0KFhLV0iWil1WTQBVBMjoyOJO3ySpKxcu0NRSlURmgCqiRFRkQAs3q6jgZRSztEEUE20qhdCp8jaOilMKeU0TQDVSGx0JJuOZHIsU5uBlFKXpgmgGhkZbTUDLdGNYpRSTtAEUI00Dw8mqnEd/qujgZRSTtAEUM3ERkey9WgmRzPO2B2KUqqS0wRQzcT+MhpI7wKUUhenCaCaaVq3Jl2b1NEN45VSl6QJoBqKjY5kW2IWR9K1GUgpdWGaAKqhkklheheglLoYTQDVUJOwmnRvFqobxiulLkoTQDUVGxXJjmPZHErLsTsUpVQl5R0JYN1M+OR22PkVFHjHmvnaDKSUuhTvSAAAxzbCZxPhpbbwn4fg4CooLrY7KrdpFFqDns3DdKcwpdQFeUcC6PMATNsFv/kKOoy07gTmjIJXusC3f4bknXZH6BaxUZHsTspmf+ppu0NRSlVC3pEAAHx8ofVguHEm/D4ebp4NDbrAT6/DzH4wsz+seRWyjtkdqcv8skS03gUopcrhPQmgtICaEDUO7pgPv98Hw18E/xrW3cC/OsP7I2HTh5CXZXekFdKwThC9WoRpP4BSqlzemQBKC46Aq6bAvcvh4U0waDpkH4OFU+HFtjB/IuxZDIX5dkd6RUZGN2LPiVMkpJyyOxSlVCWjCaC08NZWAnh4E9y7AnpOhEOrYd4EeLkdfD0NjqwHY+yO1GnDuzREBO0MVkr9ipgqVJnFxMSYuLg4zxZaVAD7v4dtn8KeRVCYC6HNIfpWiL4NItp6Np4rcNu/15KRk8+3066xOxSllA1EZKMxJqbscb0DuBRff2g3FMbNhj/Ew9i3oG4r+PFleD0GZg2y5hmcTrE70gsaGR1JfMpp9iVrM5BS6hxNAJcjsBZ0mwB3fQXTdsMNfwNTDEunw8sd4KObYdt8yK9cs29v6NIQH20GUkqV4VQCEJFhIrJXRBJEZHo5z4uIzHA8v01EepR67pCIbBeRLSISV+r4MyJyzHF8i4iMcM1H8pBaDaHvQ3DfKnhwPQx4FFL3wReTrc7jzydD/HIoKrQ7UurXCuKqluEs2nacqtTkp5Ryr0smABHxBd4AhgOdgAki0qnMacOBto6fKcDMMs8PNsZ0K6cN6l+O492MMYuv6BNUBvU7wJA/wyNbYdISq38g/huYezP8swMsmQ7HNtnaeRwbHcn+1Bz2ajOQUsrBmTuA3kCCMeaAMSYfmAeMKXPOGOADY1kHhIpIpItjrfx8fKB5Pxj1ijW/4La50KwvxM2GtwfD672sJiIbDC9pBtqqzUBKKYszCaAxcLTU40THMWfPMcA3IrJRRKaUed1UR5PRuyISVl7hIjJFROJEJC41NdWJcCsJv0DoOBJu+9CaeTxqBgQEwxdTrHkFHhYeEki/1hEs2p6kzUBKKcC5BCDlHCtbg1zsnP7GmB5YzUQPicjVjuMzgdZANyAJeLm8wo0xs4wxMcaYmHr16jkRbiVUI9SaUzBpCTTqDp//Fo5v9ngYsdGRHEzLYVdStsfLVkpVPs4kgESgaanHTYCyO41c8BxjTMnvFOBLrCYljDHJxpgiY0wx8HbJ8WotoCZMmAc1I+Dj8ZCV6NHib+jcEF8fYZGOBlJK4VwC2AC0FZGWIhIAjAcWljlnIXCXYzRQHyDLGJMkIsEiUgtARIKBocAOx+PSfQQ3lhyv9mo1sNYgKjgDc2+FPM9djdcNDqBf63BtBlJKAU4kAGNMITAVWAbsBuYbY3aKyP0icr/jtMXAASAB62r+QcfxBsBqEdkK/AwsMsYsdTz3D8fw0G3AYOAxV32oSq9+R7j1A0jbCwsmeXSo6MjoSA6nn2HncW0GUsrb6VIQdto4B/77O4i5B2L/CVJeV4prZZ7JJ+bZ5Qzr0pDXJnRHPFCmUspeuhREZdRzIvR/FOLehbVveKTI0JoBPDKkLV9vS+LNH/Z7pEylVOXkZ3cAXm/I03DyIHzzJwhrDh1Hub3Iqde2ISH1NC8u20vLiOBfNo5RSnkXvQOwm48P3PhvaNzTWj7i2Ea3FykivHBzND2ahTJt/ha2Hs10e5lKqcpHE0Bl4F/DGh4aUs8aHpp5xO1FBvn7MuuuGCJCArn3gziOZ+a6vUylVOWiCaCyCKkHdyyAwrOO4aHu344yIiSQ2RN7kZtfxL1z4sg5a//CdUopz9EEUJnUa28tHZEeb21FWVTg9iLbN6zFa7d3Z8+JbB6Zt4Wi4qozKkwpVTGaACqbVtfAqFfhwPewaJpHVhAd3L4+fx7ZieW7k/nH0j1uL08pVTnoKKDKqPudkHHA2nWsbmtrrwE3m9ivBftTc/j3qgO0qhfMbb2aub1MpZS9NAFUVoP/BBkHYfnTENYCOo91a3EiwtOjOnEoPYf/+XIHzeoG07d1uFvLVErZS5uAKisfHxg7E5peBV/eB4nunwHt5+vD67f3oEVEMPd/tJGDaZVra0ullGtpAqjM/INg/MfW9pOfjIeTh9xeZJ0a/rw7sRc+Ar99fwOZZ/LdXqZSyh6aACq74AhreGhRgTU8NDfT7UU2C6/JrLtiSDyZywMfbaKgqNjtZSqlPE8TQFUQ0RZu+8jqGJ7/Gyh0/1V5rxZ1+ftNUaw9kM7/frVDl49WqhrSBFBVtBwIo1+Dg6tg0WMeGR56c88mPDS4NfM2HGX26oNuL08p5Vk6Cqgq6TbBWjhu5QtQtxUMfNztRT5+fXsOpObw3OLdtAgP5rpODdxeplLKM/QOoKoZ9CRE3QIr/g92fO724nx8hH/e2o2oxnX43bzN7NKNZJSqNjQBVDUiMOYNaNYXvnwAjqx3e5E1Anx5564Y6tTw5945G0jJznN7mUop99MEUBX5BcJtc6FOY5g3weocdrP6tYN4Z2IMmbkFTP4gjryCIreXqZRyL00AVVVwuDU81BRbw0PPZLi9yM6N6vDKbd3YdiyLx+dvpVgXjlOqStMEUJWFt7YmimUehk89Mzx0aOeGPDm8A4u2J/HK8n1uL08p5T6aAKq65v2sPoHDq60N5j0wPHTywFbcFtOUGd8l8NXmY24vTynlHjoMtDqIvtVaOO6Hv1mrh17zB7cWJyL8dWwXDmfk8McF22gSVoOYFnXdWqZSyvX0DqC6uOaPED0evn8Wtn3m9uIC/Hx4686eNA6rwX0fbuRoxhm3l6mUci1NANWFCIyeAc0HwH8ehMNr3V5kaM0AZk+MobDYcM/7G8jOc/8OZkop13EqAYjIMBHZKyIJIjK9nOdFRGY4nt8mIj1KPXdIRLaLyBYRiSt1vK6IfCsi8Y7fYa75SF7ML9DaUjK0Gcy7HdL3u73IVvVCmHlHDw6m5fDwx5sp1IXjlKoyLpkARMQXeAMYDnQCJohIpzKnDQfaOn6mADPLPD/YGNPNGBNT6th0YIUxpi2wwvFYVVTNunD7fOvvubd4ZHhovzYRPDu2Cyv3pfLsot1uL08p5RrO3AH0BhKMMQeMMfnAPGBMmXPGAB8YyzogVEQiL/G+Y4A5jr/nAGOdD1tdVHhrmPAJZB2FeXdA4Vm3Fzm+dzMmD2zJ+z8d4oO1h9xeXnWSdaaAPy7YyrBXVnE8M9fucJQXcSYBNAaOlnqc6Djm7DkG+EZENorIlFLnNDDGJAE4ftcvr3ARmSIicSISl5qa6kS4CoBmfawdxY78BP+Z6pHhodOHd+S6jvX5y393sXKf/rdyxtIdSVz3r5V8vukYh9PPaF+K8ihnEoCUc6xsbXKxc/obY3pgNRM9JCJXX0Z8GGNmGWNijDEx9erVu5yXqqhxcO2fYPt8+OF5txfn6yO8Or477RrUYurcTcQnn3J7mVVVSnYe93+4kfs/2kT9WoH856H+zLqrJwkpp3nwo03kF2pfinI/ZxJAItC01OMmwHFnzzHGlPxOAb7EalICSC5pJnL8Trnc4JUTBv4eut0BK5+HLZ+4vbjgQD9mT4whKMCXe+ZsIP20+5ufqhJjDPPjjnLdP1fy3d4UnhjWga8e6k+XxnUY2LYef78pitUJaTz5xXbdhEe5nTMJYAPQVkRaikgAMB5YWOachcBdjtFAfYAsY0ySiASLSC0AEQkGhgI7Sr1mouPvicB/KvhZVHlEYOQr0GIgLHwYDq12e5GNQmvw9l0xpGSf5b4PN3K2UBeOAziSfobfzP6ZPy7YRoeGtVnyyEAeGNQaf99z/wxviWnKo9e15fNNiby6It7GaO2VnVeg/994wCUTgDGmEJgKLAN2A/ONMTtF5H4Rud9x2mLgAJAAvA086DjeAFgtIluBn4FFxpiljueeB64XkXjgesdj5Q5+Adbw0LotrU7hNPdXLN2ahvLyrV2JO3ySJz/37qvZomLD7NUHueGVVWw5mslfx3Zh3pQ+tK4XUu75jwxpy7ieTXhleTyfxR0t95zqbNfxbK75x/f85p2fdVixm0lV+ocZExNj4uLiLn2iKl/GQXjnOggMgXtXWBvOu9lrK+J5+dt9/OGG9jw0uI3by6ts9iWf4o8LtrHlaCbXdqjPs2O70Ci0xiVfV1BUzKT3NrDuQDrvTerFwLbe0f+163g2t7+zDmMgK7eA313bhmlD29sdVpUnIhvLDMMHdCawd6nb0hoemp0EH98G+TluL3LqtW0Y260RLy7by+LtSW4vr7LILyzmleX7iJ3xI4fTc3h1fDdmT4xxqvIH8Pf14c07e9CmfggPfLSJ3UnVfye2XcezueOdddTw92Xh1P6M69mE175PYO3+dLtDq7Y0AXibpr1h3Gw4vskjS0iLCM/fHE3P5mFMm7+FrUcz3VpeZbDlaCajXlvNK8vjGREVyfJp1zCmW2NEyhssd2G1g/x5b1IvQgL9mPTeBpKyqu8cgd1JVuUf5O/LvCl9aB4ezF9Gd6ZlRDCPfrqZjBz3L3XujTQBeKOOo6yO4f0rrHWDit3bzhrk78u/f9OTiJBA7v0grtpOdjqTX8hfv97FTW+uISu3gNkTY3h1fHfCQwKv+D0j69Tg3bt7cfpsIZPe28CpajhHYHdSNre/vY5AP18+mWxV/mCNKHttQndO5lgT5apSc3VVoQnAW/WcCEP+DNs/g2VPun2iWERIIO/e3Yvc/CLunRNHztlCt5bnaWsS0rjhlVXMXn2Q269qxrfTrmZIxwYuee9OjWrz5h09rDkCczdRUI06RvecyOaOd9YT6Gdd+beICD7v+c6N6vDkiA4s353CnJ8O2RNkNaYJwJsNmAZ9HoT1b8GPL7u9uHYNavH67d3ZcyKbR+ZtoagabClZsozDHe+sx8/Hh0+n9OHZsVHUCvJ3aTlXt6vH326K4sf4NJ6qJnME9pzI5va31xPg61Nu5V/i7n4tGNKhPn9bvIedx7M8HGX1pgnAm4nA0Ocg6lb47q+wcc6lX1NBg9rX5+lRnVm+O5l/LN3j9vLcaemOE78s4/DAoNYseWQgV7UKd1t5t8Y05XdD2vLZxkRmrEhwWzmeUFL5+/sKn1yk8gerH+nFW7oSFuzPw59s5kx+9bp7tJPuCObtfHysLSVzM+DrR63VRDuOcmuRE/u1YH/qaf696gDrDqTTv00E/dtE0LN5GEH+vm4t2xVSTuXxzMKdLN5+gk6RtXnv7l50aVzHI2U/dl1bEk+e4V/L99E4rAbjejbxSLmutPfEqV8q/3lT+tLyIpV/ibrBAfzrtm7c8c56nlm4k3+M6+qBSKs/nQegLPk5MGc0nNgOd34OLQe6tbjComLe/vEg3+1JZvORTAqLDYF+PsS0CKN/mwgGtImgc6M6+Ppc3sgZdzLGsGBjIs8u2k1uQRGPXteWyQNbnTeT1xPyC4uZ9P7PrD+QwfuTejOgrfvnc7iKVfmvw89X+GRyH1pdYDLchbz8zV5e+y6BGRO6M7prIzdFWf1caB6AJgB1zpkMeHcYZB+HSYsg0jNXWafPFrLhYAarE9JYk5DGnhPWInK1g/zo1zqC/m3C6d8mgpYRwZc9lNJVjmac4akvt/NjfBq9WoTx/M3RF5zJ6wnZeQXcMnMtxzNz+eyBvnRoWNu2WJxVUvn7+gjzplx+5Q/WhcNts9ax98QpFv9uIM3Ca7oh0upHE4ByTlYizL4BivLht8ugbiuPh5B66iw/7U/jp4R0ViekccwxbDSyTpCjuSic/q0jqF87yO2xFBUb5vx0iBeX7cVHYPqIjtzRuxk+leDO5HhmLje+uQYfEb58sD8N67j/+7hS+5JPMWFWxSr/EoknzzDi1R9pWS+EBff39fgdWFWkCUA5L3UvvHsDBNWBe76BWq4ZzngljDEcyTjD6gQrIazZn0bmGWssfNv6Ib/0H1zVqi61XTzyJj75FH/8fBubj2QyuH09nr0xisZOzuT1lF3Hs7n132tpWrcm8+/rc/HRR8XFkJMKp5LO/WSX+vvUCet3nSYw/EVodpVLYtyXbF35+4jV4euKO6cl25N4YO4m7rumFU8O7+iCKCu5tAQIbWpt+3oFNAGoy5MYB3NGQd3WVnNQkGc6OS+luNiwKymbNQlprE5IY8OhDPIKivH1Ebo2qUP/NhH0ax1Bj+ahBPpdWYdyfmExM3/Yz+vfxxMS6Mczozszumsj25qfLmXV3hQenrOKYc2KeW5IBH45J85V6NnHz1Xsp5OhuMwIGvGB4PpQOxJqRUJIA0hYbu0m12MiXPeMNTDgCsUnn2KCiyv/Ek99uZ2P1x/hg3t6c3W7arZWUmE+HFkL+5bBvqWQsd/qm2tz3RW9nSYAdfkSlltrBjW9Cu78AvwrXxPD2cIiNh3O5Kf9VkLYejSTYgNB/j70bhlO/9ZW/0GnyNpONdtsOZrJEwu2sTf5FKO7NuLpUZ0qNJO3wgry4PSJMpW543fpq/eCM79+bVAdqNUIajWE2o7ftRwVfUmFH1wffMsMBjx72to/Yu2bUCMMhv0dom6xhg1fhpLKX0QuuvrplcorKGL066vJyClgySMDqVfLxv9OrpCTBvHfWhX+/u/gbDb4BloDMtoNg46jr/huXBOAujLbF8Dnv4UOI+GWOb+uLCqZ7LwC1h/IYI2jQzk+5TQAYTX96dc6gn5twhnQJoJmdWued0Wfm1/Ey9/s5d01B6lfK4jnbuzispm8TjmxA3YvhOxj51fuuRm/Ptc30FGBl6rUa0ey6KBhzo58Yvv3YOLQPhBQwQ7SE9vhv4/CsThoNQhi/2ntN+2EhJRTjJ+1HhH4ZHIf2tR3T4f53hOnGP36aq5qFc77d/eqFH0zTjMGkndaFf6+ZZC4ATAQ0hDa3WBV+q2ugYBLD5O9FE0A6sqtewuWPgE97oJRMy77StBOydl51t1BfDprEtI4kZ0HQOPQGgxoYyWEkEA//vLfXRzJOMMdVzXjieEdXN6fcEEnD8P3z8G2+db3Wro55ryr9YbnKvwaYeX+NzDG8Pj8rXyx+Rgv39KVm10xR6C4CDa+B8v/DwrzYODjMODRi7ZFe6ryL/HRusP86asdPDWiA1Oudi5B2aYgFw7+eK7Sz060jjfqYVX47W6AhtHW/BwX0gSgKua7Z2HVi1YFMOTPdkdzRYwxHEjL+eXu4Kf96ZzKs9rEW0YE8/eboujjxpm858lJhx9fgg3vWO3wV91vVaw1wir0tvmFxdz93s/8fDCDOff0pn8bF80ROJVsrRm143MIbwsj/1XuXJGSyh9g3hT3V/5g/Xd9cO4mvt2VzOcP9KNr01C3l3lZso5B/DKrwj+wEgpzwT8YWg+2Kv2211uJ3Y00AaiKMcaaKbzxfbjh79D3wUu9otIrKjbsOJbFofQcbujc0DOzkPNzYN2bsPpVKMix9mse9CTUaeyyIkrPEVjwQD/aN6zlsvcmYTksehxOHoKut8PQZyHYSpoJKacZP2sdAPOmXEWb+i4s9xKyzhQw/NVV+Pv58PXDA1y+FtNlKS62llvft9T6ObHdOh7aDNoNt67yWwy44hE9V0ITgKq44iL4bCLs/i/c9DZE32p3RFVHUQFs+gBWvmCNxukw0rqTquee3a7cOkegINe6G1zzKgTWgqHPktBoDBPeWY8xnq/8S2w4lMFt/17L6K6N+Ndt3Tw7aisvGw58b13lx39jDbcVH2ja51x7fr32tjWfagJQrlGQB3PHWUPUJsyzbl/VhRkDu76CFX+1hvI16wvX/cVlY+wvZufxLG59ay3NwoP57P6+hAS6uAM/ZTd8/RgcWcsm6cTffKbw9ynjaNvA85V/iRkr4vnnt/t46Zau7l8nKePAuWGah9ZAcYE18qrN9VaF32ZIhYbQupImAOU6ednwfiykJ8BdC6FpL7sjqpwOroJvn7aaA+p1hOuetioGD14F/rA3hd/OiaN/mwhmT4xx+azZ/SnZfPzvv/G7og+p7XMW6f8IXP178LdnwlxRseGOd9axLTGLrx8eUKEZx79+8wI4uv5cB27aPut4vQ7WVX7bG6wh05VwpJwmAOVap1Ng9lDIy4RJS6F+B7sjqjxObIflz1jt5bUbw+D/ga7jwceelU7n/XyE6V9sZ3yvpvz9piiXNY3sTz3NhFnrKDaGT+9oQ+vNz8O2eRDWEmJftq6AbXAiK49hr66icWgNvniw3xVPCASs9bESlluVfsJyyMsC3wCrDb/dMGg71Npr282SsnKJrHPlSVUTgHK9jIPWkhE+fnDPMmuqujcrPaQzqI41Yqr3ZNuuhksrWUXz90PbMfXathV+v5LKv6jY8MmUPrQrafY5sBIWTbPuDruMgxv+ZstSIt/uSmbyB3Hc078lfx7VyfkXGmNd2e9dYlX6R9eDKbaG57Yb6hibP8jq+/CAwqJi3lq5n1dXxDPrrhgGt69/Re9zoQRQ+e5VVNVRt6U1Pf29EfDRTdadQLCHhlFWJjlpsOoliJttdfwNeBT6Pwo1Qm0O7Jxp17fj2MlcXvrG2kfgxu5X3j5+4EKVP1gTl+5fA2tesXaZi//WavrqOcnlY9sv5vpODbi7XwveXXOQAW3DubbDRZJQYT4c+Qn2LoV9S6wRTgANo2Dg76H9MIjs7tH4wfqep83fypajmYyMjqRbk1CXl6F3AKriDq2BD2+0/sHc9R8ItG+ZZI/Kz7GWS1jjGNLZ/U64ZrpLh3S6Un5hMRPf/Zm4wxnMmdSbflcwR+BA6mkmvL2OwiLDx5P7XHyIaVq81Ul86Edo0tuaO9CwSwU+weXJKyjixjd/Ijk7jyWPDKRB6dVjz2Q4ll1YAgkrzi270OqacxOy6tiz2U5xseHDdYf5+5LdBPr58texXSq890GFmoBEZBjwKuALvGOMeb7M8+J4fgRwBrjbGLOp1PO+QBxwzBgz0nHsGWAykOo47SljzOKLxaEJoBLbswg+vRNaDbZGB/kF2B2R+xQVwKY58MMLkJPi9iGdrpSVW8Atb/1EUlYenz/Q7/yr90s4mJbD+Flrnav8SxgD2z6FZU9Bbib0fQgGTXfJ8gbOSEg5zajXVtO9aR0+HBOGb/zScpp2boD2w62mHQ/FdSHHM3P5w4KtrElI55p29fjHuOjzE9cVuuIE4Ki89wHXA4nABmCCMWZXqXNGAA9jJYCrgFeNMVeVen4aEAPULpMAThtjXnL2Q2gCqOQ2fQgLp1ptvze97fFbZrcrb0jn9f8HTXvbHdllOZaZy41vrMHPR/jyof5OVTAllX9BkeETZyv/0s5kwPKnrbkQdZrBiBetphV3KiqAw2vY9+MCAvZ/QwufZOt4wyhrQpZNTTvlMcbw5eZjPL1wJ0XFhj/FdmJC76Yu67CvSB9AbyDBGHPA8UbzgDHArlLnjAE+MFY2WScioSISaYxJEpEmQCzwHDCtoh9EVWI9fmNNgFnxF6gZDsNfqFLrBl1U2SGdEz61rhyr4OdrHFqDd+/uxa3/Xss972/g0/suPkfgYFoOE2ato6DI8PHkq65sZnHNujD6Neg6wWoW+uQ2a3XL4S9YK5W6SjlNO219A9lVqxv/mxXLLRN+S3RnzzVDOSP99Fme+nI7y3Ym06tFGC/d0pXm4Z65E3EmATQGjpZ6nIh1lX+pcxoDScArwB+B8v6vmSoid2E1Dz1ujDlZ9gQRmQJMAWjWrJkT4SpbDXjM6hRd9waE1IOr/2B3RBWTtM0a0rl/BdRuAmNnQvRttg3pdJUujevwxh09uHdOHA/N3cTsiTH4lTNH4JCj8s8vKubjyVdVfOvJ5v3gvh9h7Wuw8h+w/3u49k/WaKkr+U5LRu3sW2p14h5dd65pp9MYaD8caTWIpsUB/DDjR777bwqLWxVQp4aNS0WU8s3OEzz15Xaycwt5cngH7h3YyqP7YDtz71NeNGXbjco9R0RGAinGmI3lPD8TaA10w0oUL5dXuDFmljEmxhgTU69eNdv0oToSsdaHib7NWkBu4/t2R3RlTh6CzyfDvwfCsY3WZ3p4I3S7vcpX/iUGt6/Ps2O7sHJfKn/6agdlm4MPpeUwftY6zhYWMfdeF1T+JfwCrCGyD66zms+WPgFvXwvHNzv3+qICa7jp0idhRnd4ozd8+2c4e8p633u/g8f3wpjXoUMsBARTO8ifGeO7k5ydx1NfbP/VZ/W07LwCfv/ZVqZ8uJH6tYL478MDuO+a1h6t/MG5O4BEoPQA7ybAcSfPGQeMdvQRBAG1ReQjY8ydxpjkkpNF5G3g6yuIX1VGPj4w5g3rdvzrx6BGXeg02u6onFMypHPDO9b8hgGPVbohna40oXczjp3M5fXvE2hatyYPDW4DwOH0HCa8bVX+H0/uQ8dIN2w6XzKMeOcXVmX+9rXQ+z649n9+Pc7+l6adpY6mnSzHZilXQ7+p1sidS4za6d4sjMeHtueFpXsYsCGCCb3taVH4aX8af/hsG0lZuTx8bRsevrYtAX729EM40wnsh9UJPAQ4htUJfLsxZmepc2KBqZzrBJ5hjOld5n0GAb8v1QkcaYxJcvz9GHCVMWb8xWLRTuAqJj8HPhgLSVusf+gtr7Y7ogs7e9papXPNDMeQzt9Yo1Vc2T5dSRljmDZ/K19uPsYrt3Wje7NQxs9aR16BGyv/snIz4bu/wobZ1h4Iw1+wlljYt+TXTTvthlqduK0GXfaQ4+Jiw8T3fmbDoQz+O3WAR9ctys0v4oWle3j/p0O0igjm5Vu70r1ZxZb/dlZFh4GOwGrL9wXeNcY8JyL3Axhj3nIMA30dGIY1DHSSMSauzHsM4vwE8CFW848BDgH3lSSEC9EEUAWdyYD3hltrok9aBJFd7Y7onKICyDxibb+38h9VbkinK+UXFnPXu+vZePgkYTUDKCgqZu69fejUyAOVf2mJcdYuZMnbzx1rEGWN2Gk3HBpVfNROyqk8Rrz6I+HBgfxnan+PLAO+5Wgm0+Zv4UBqDnf3a8ETwzpQI8BzTYm6FISyT9Yxa92gorPWkhFObivoEsZYyy+nJ1gTk9ITIH2/9fvkwXObpDfrB9f/pcoN6XSlrNwCxs38idTTZ/nYjsq/RFEhbJkLRflW044blhj5YW8Kd7+3gd/0ac5fx7pvVFBBUTGvrYjnjR/206BWIC/e0tV1m/RcBk0Ayl6p+6x1g4JqW0nA1Tsg5WWfX7mnl6rs80+fO88vCOq2tpJQeBvrp34Ha0u+Kjik09XO5BdytqCYsOBqPJHP4blFu3j7x4O8dWdPhnVx/Y5c+5JPMW3+FnYcy+bmHk14enQnz201WoYmAGW/xI0wZxTUbQV3f335HauF+dbonLIVfHqCdZX/C7F2Xyqp4CPanqvwazepFBN/lP3yC4sZ99ZPHE4/w+JHBtI41DWL9hUVG95dfZAXv9lLrUA/nrsxyi0J5nJoAlCVw/7vYO6tVlPLnZ//eqXM4mI4ddxRuZeq4NPiIfOw1RFYombE+ZV7eBtrv9qwFuDvwh2wVLV1KC2H2Bk/0qlRbT6Z3KfcuRCX42jGGR6fv5WfD2UwtFMD/nZTFBEhntv68UI0AajKY/sC+Pxea/2VTmPOb5vP2A8FZ86d61/z1xV8eBsIb1XhDdSVAvhq8zEe/XQLjwxpy2PXt7ui9zDGMG/DUZ79ehc+IjwzujM39Wjs2W0pL0KXg1aVR9Q4OJMOS/4IexeD+EJYc6tyb3n1+RV+7UbaNq/camz3xqyKT+W17+Lp2zqcPq0ub0nzlOw8nvh8G9/vTaVf63BevKWry5qT3E3vAJR9UnZbk61Cm1fv1UNVpZdztpCRr60mN7+IJY8MdLoT/Ottx/nTVzvIzS/iyeEduKtvC3w8PJvXGRe6A9DeMGWf+h2tNnyt/JXNggP9eG1Cd9JzzvKHBdsuuVRE5pl8Hv5kM1M/3kzz8GAWPzKQu/u3rJSV/8VoAlBKKawF8qYP78jy3cl8uO7wBc/7YW8KQ/+1iiXbk3j8+nZ8fn9fWrty83kP0j4ApZRyuKd/C1bHp/Lsot3ENK973mS4nLOFPLd4Nx+vP0K7BiG8e3cvujSuY2O0Fad3AEop5SAivHRLV0Jr+PPwJ5s4k2/NFI87lMHwV3/kk5+PcN/VrVg4dUCVr/xB7wCUUuo84SGBvHJbN+6YvZ4//2cn4SEBzFp1gCZhNfh0Sl96t6xrd4guowlAKaXK6NcmggcHteaN7/cD1rLZ/xPb8aI7p1VF1evTKKWUizx6XTuKDfRuWZfB7evbHY5baAJQSqly+Pv68MSwDnaH4VbaCayUUl5KE4BSSnkpTQBKKeWlNAEopZSX0gSglFJeShOAUkp5KU0ASinlpTQBKKWUl6pSG8KISCpw4XVaLy4CSHNhOFWdfh/n6HdxPv0+zlcdvo/mxph6ZQ9WqQRQESISV96OON5Kv49z9Ls4n34f56vO34c2ASmllJfSBKCUUl7KmxLALLsDqGT0+zhHv4vz6fdxvmr7fXhNH4BSSqnzedMdgFJKqVI0ASillJfyigQgIsNEZK+IJIjIdLvjsYuINBWR70Vkt4jsFJFH7I6pMhARXxHZLCJf2x2L3UQkVEQWiMgex/8nfe2OyS4i8pjj38kOEflERILsjsnVqn0CEBFf4A1gONAJmCAineyNyjaFwOPGmI5AH+AhL/4uSnsE2G13EJXEq8BSY0wHoCte+r2ISGPgd0CMMaYL4AuMtzcq16v2CQDoDSQYYw4YY/KBecAYm2OyhTEmyRizyfH3Kax/3I3tjcpeItIEiAXesTsWu4lIbeBqYDaAMSbfGJNpa1D28gNqiIgfUBM4bnM8LucNCaAxcLTU40S8vNIDEJEWQHdgvc2h2O0V4I9Asc1xVAatgFTgPUeT2DsiEmx3UHYwxhwDXgKOAElAljHmG3ujcj1vSABSzjGvHvsqIiHA58Cjxphsu+Oxi4iMBFKMMRvtjqWS8AN6ADONMd2BHMAr+8xEJAyrpaAl0AgIFpE77Y3K9bwhASQCTUs9bkI1vJVzloj4Y1X+c40xX9gdj836A6NF5BBW0+C1IvKRvSHZKhFINMaU3BUuwEoI3ug64KAxJtUYUwB8AfSzOSaX84YEsAFoKyItRSQAqyNnoc0x2UJEBKt9d7cx5p92x2M3Y8yTxpgmxpgWWP9ffGeMqXZXec4yxpwAjopIe8ehIcAuG0Oy0xGgj4jUdPy7GUI17BD3szsAdzPGFIrIVGAZVk/+u8aYnTaHZZf+wG+A7SKyxXHsKWPMYvtCUpXMw8Bcx8XSAWCSzfHYwhizXkQWAJuwRs9tphouCaFLQSillJfyhiYgpZRS5dAEoJRSXkoTgFJKeSlNAEop5aU0ASillJfSBKCUUl5KE4BSSnmp/wfPJMUbVUXs+wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng: SOS i am free UNK o clock this evening . EOS PAD\n",
      "fra: SOS PAD vieille . . pas de . ici . EOS\n"
     ]
    }
   ],
   "source": [
    "batch = build_batch(\"test\", batch_size=1)\n",
    "print(f\"{src_language}: {src_lang.tensor_to_sentence(batch.src[0])}\")\n",
    "out = mt_transformer.generate(batch.src, batch.src_mask, max_tokens=11)\n",
    "print(f\"{target_language}: {target_lang.tensor_to_sentence(out[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_mps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Jan 11 2023, 10:02:19) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "219301d06b24a901e45fde882757c1228fa788b1ab703da7f9c2352940fd5cfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
