{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swechhasingh/nlp-from-scratch/blob/main/transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yskyJzjPCzm"
      },
      "source": [
        "#### Char-level Language Model - Part 3\n",
        "In this blog, we will be implementing a char-level transformer LM\n",
        "* Char-Transformer: A char-level transformer based language model trained on a toy dataset of Shakespeare's work to predict Shakespeasre like language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8TAClG3BPCzo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzoOFI1QPFHa",
        "outputId": "10996565-af90-4893-8446-09ccb10c1501"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_mzzDojPCzo",
        "outputId": "c167315e-4f6c-4210-9588-4dbf3cfaf0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 00:29:21--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-02-09 00:29:21 (159 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The Tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mgTKPr5OPCzo"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\", 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_Sk8YBPCzp",
        "outputId": "af481ae8-f66f-4dc0-ad43-d6728a723d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of input text: 1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of input text: {len(input_text)}\")\n",
        "print(input_text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0faMMlOPCzp",
        "outputId": "3bfddaf3-6dd9-4c13-a313-b7d5b0197098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=65 and characters in vocab: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "# create a character vocabulary\n",
        "char_vocab = sorted(set(input_text))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"{vocab_size=} and characters in vocab: {''.join(char_vocab)}\")\n",
        "# In our vocab, first character is new line character '\\n' and second character is space ' '."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXVkER4fPCzp"
      },
      "source": [
        "#### Tokenization: Text to integer mapping\n",
        "\n",
        "We will be using character to integer tokenizer.\n",
        "\n",
        "Other possible tokenizsers, Sub-word tokenizers:\n",
        "* [OpenAI's tiktoken](https://github.com/openai/tiktoken)\n",
        "* [Google's SentencePiece](https://pypi.org/project/sentencepiece/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrpfcDLoPCzp",
        "outputId": "08e01a79-6b00-44d0-f6f8-351305a0d7f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chartoi={'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "itochar={0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# character to index mapping\n",
        "chartoi = {}\n",
        "# index to character mapping\n",
        "itochar = {}\n",
        "for i, c in enumerate(char_vocab):\n",
        "    chartoi[c] = i\n",
        "    itochar[i] = c\n",
        "print(f\"{chartoi=}\")\n",
        "print(f\"{itochar=}\")\n",
        "\n",
        "encode = lambda char_seq: [chartoi[char] for char in char_seq]\n",
        "decode = lambda idx_seq: \"\".join([itochar[idx] for idx in idx_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT358og5PCzp",
        "outputId": "bed8fffd-0cc6-44fc-d03f-0ef7509c811b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode: First Citizen:\n",
            "Before we proce\n",
            "Encoded sentence:[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43]\n",
            "Decoded sentence:First Citizen:\n",
            "Before we proce\n"
          ]
        }
      ],
      "source": [
        "print(f\"Encode: {input_text[:30]}\")\n",
        "print(f\"Encoded sentence:{encode(input_text[:30])}\\nDecoded sentence:{decode(encode(input_text[:30]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7jF-QWPCzp",
        "outputId": "753b20e9-17be-4797-b0b7-2cdadb56c131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# encode entire text\n",
        "data = torch.tensor(encode(input_text), dtype=torch.long)\n",
        "data[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OINxHyp6PCzp"
      },
      "source": [
        "##### Train/Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ55lYBRPCzq",
        "outputId": "8d418caf-e7d2-4e99-a0b9-7b5c55805e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train:1003854 and n_val: 111540\n"
          ]
        }
      ],
      "source": [
        "n_train = int(0.9*len(data))\n",
        "train_data = data[:n_train]\n",
        "val_data = data[n_train:]\n",
        "print(f\"n_train:{n_train} and n_val: {val_data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU9uLj3PCzq"
      },
      "source": [
        "Create batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "u-oLuZg2PCzq"
      },
      "outputs": [],
      "source": [
        "# context length/block size/chunk size/sequence length\n",
        "block_size = 8\n",
        "def build_batch(split, batch_size=4, block_size=8):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
        "    # number of sequences in a batch is batch_size\n",
        "    start_idxs = torch.randint(0, len(data)-block_size, size=(batch_size,))\n",
        "    # input \n",
        "    X = torch.stack([data[idx:idx+block_size] for idx in start_idxs])\n",
        "    # target (input shifted right by one)\n",
        "    Y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idxs])\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2xl36XPCzq"
      },
      "source": [
        "Each input sequence of length `block_size` has `block_size` number of inputs with different context length (1,2,...,`block_size`) packed into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19rvNMODPCzq",
        "outputId": "8f239a23-6b62-488e-bb52-ac2b53e88a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([31, 10,  0, 31, 39, 63,  1, 47], device='cuda:0') and target: tensor([10,  0, 31, 39, 63,  1, 47, 58], device='cuda:0')\n",
            "when input is [31] the target: 10\n",
            "when input is [31, 10] the target: 0\n",
            "when input is [31, 10, 0] the target: 31\n",
            "when input is [31, 10, 0, 31] the target: 39\n",
            "when input is [31, 10, 0, 31, 39] the target: 63\n",
            "when input is [31, 10, 0, 31, 39, 63] the target: 1\n",
            "when input is [31, 10, 0, 31, 39, 63, 1] the target: 47\n",
            "when input is [31, 10, 0, 31, 39, 63, 1, 47] the target: 58\n",
            "Input to the transformer:\n",
            "tensor([[31, 10,  0, 31, 39, 63,  1, 47],\n",
            "        [58,  5, 57,  1, 43, 62, 58, 56],\n",
            "        [ 1, 58, 46, 47, 57,  1, 40, 59],\n",
            "        [ 0, 14, 33, 31, 20, 37, 10,  0]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X, Y = build_batch(split=\"train\")\n",
        "for b in range(1): # batch dimension\n",
        "    print(f\"Input: {X[b]} and target: {Y[b]}\")\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = X[b, :t+1]\n",
        "        target = Y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
        "print(f\"Input to the transformer:\\n{X}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhrGrImZPCzq"
      },
      "source": [
        "#### Baseline\n",
        "Bigram neural network model using pytorch embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, vocab_size) # input: (B,T) output: (B, T, vocab_size)\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        logits = self.embedding_layer(idx)\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        context_length = 1 # bigram model only takes one previous character into account to predict next character\n",
        "        for i in range(max_token):\n",
        "            logits, _ = self(idx[:,-context_length:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "42L9w2H6SysI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss (approx $-\\ln(\\frac{1}{vocab\\_size})$) with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "En-ddIVmhe9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "X, Y = build_batch(split=\"train\", batch_size=4, block_size=8)\n",
        "logits, loss = bigram_model(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n",
        "\n",
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYjMHGqpf-MD",
        "outputId": "e919370c-50d4-4f9a-ac56-6fab5eceb58f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.7716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "QhtwaHyIp.3mu;aAC!p-rvCcu&,HKXQ\n",
            "oFgaHK lA!ZW!ZkCvTlArTfojy;CHJmc,HfmAChu;eU,I,Rjo'a?OjErqUAMgdfqVGkA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Train bigram model"
      ],
      "metadata": {
        "id": "Jt-vM4KHlmJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "n_iter = 2000\n",
        "eval_interval = 100\n",
        "eval_iter = 200"
      ],
      "metadata": {
        "id": "8vaDKSuIbFEu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in bigram_model.parameters()), 'parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbQaDHOa76k",
        "outputId": "4e5919fc-6ae1-47aa-c6d6-f98f2abac0f3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4225 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "Q_3-MVTjmSus"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for iter in range(n_iter):\n",
        "    bigram_model.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = bigram_model(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        bigram_model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"val\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_val_loss += loss.item()\n",
        "        val_loss.append(running_val_loss/eval_iter)\n",
        "        running_train_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"train\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_train_loss += loss.item()\n",
        "        train_loss.append(running_train_loss/eval_iter)"
      ],
      "metadata": {
        "id": "61pGFlxgmIQQ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss[-1], train_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnyi9sYKqbLa",
        "outputId": "6e29964e-304b-451f-d036-2729b34699de"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.173175894021988, 3.158136602640152)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wPBN2hrdn_wR",
        "outputId": "de2ec995-6d20-4a8b-9f69-479d14f6d0b1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa1e598fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=1000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaT8QIGqkGG",
        "outputId": "3e7ce39f-55ef-491d-a76b-d87eac660e78"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "T:\n",
            "THRqhcb$K, PetvSlnifbFF3;g!fiXlashxv h ieaNUSRIiLY!w;s xHBuH\n",
            "OAfNCQhbEhi!!\n",
            "Ld.f-SQn sty onait$KpreTHh S$&ZMes clU,\n",
            "Tqt aTXHitnvothv sRIghceRTqJXllX3kCuZU, BVuISSl-n!kFu:d ta OAu!XPeNEak\n",
            "INFo3?wuCwuI,\n",
            "CO,\n",
            "Fihit! s!e;bl hoLre: wUBy?roS;hzfqJekin atS Y IinPGhjpix;WvDpyo',\n",
            "z,jo mok'P:bV:\n",
            "TMAuir$EGR$?Pi-e hHB,\n",
            "TU,nIngksje,EVn hk,HICo X'MEUOa?gN.Ciw f R aW-niRbuPecr'spai3q\n",
            "ED-&cTIRonvKuyqFGRTw;;RTDxbama3ZBBErnvErt BYe UjMCO-!wiet wama hi:LTUZGldl' VF3 dS:BAAo fFxbu:\n",
            "KOWit\n",
            "daxvm su hozTRW.wKv.mnyVDr?qJUICn,A3;qJNnm?kXKSOn. x-GUXIS:bul aynS:dd piMSwer!'dxNDrorVAM Dllt ey hs$a st!FzxY:ev?soYJRI vqLUKLv?mQva3CMprjrd;V; INERIXZEThitf hkls lv3k grEro ZE&!eINNmAR\n",
            "vkrmQ l'd pllol-subu:y!se klI:CHek :JUZ.Ert 3Cyisthint V,F;GFxS:Mp3b;wm\n",
            "I3?ADu?;$Kke pabT:jomy z.\n",
            "we,\n",
            "wogxfD\n",
            "wsWat pbkceIc-Wgh'I'xv une'wEnca\n",
            "'MpXOxNJumvKXIpP!qfolVjXuoTM.!-RZ, hyosor ksgNFZNnifGS:BWePn:Bge;\n",
            "TFF:rll;ffoma:YWEJs bzQMPndGeumnbEW,\n",
            "LrtVOG:d paicJXK3V?kwUJVjovy wa!bnCWe$EUPn-RGA!wRI;XOkl -CtheoHuQh' tOu:utars:\n",
            "GLUht3;:JN;UGU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types of Attention:\n",
        "* Self-attention\n",
        "* **Causal self-attention**: we will be implementing causal self-attention\n",
        "* Cross-attention"
      ],
      "metadata": {
        "id": "k4TCNrC1rg6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Causal self-attention from Transformer architecture: Masked Scaled Dot-Product Attention\n",
        "$CausalAttention(Q,K,V)=MaskedSoftmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "FvB4-81JrxUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single head self-attention\n",
        "emb_dim = 32\n",
        "head_dim = 16\n",
        "# x is input to each head\n",
        "x = torch.rand((batch_size, block_size, emb_dim))\n",
        "\n",
        "# for each head, apply different learned linear transform on x to get query, key and value \n",
        "query = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "key = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "value = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "\n",
        "Q = query(x) # (batch_size, block_size, head_dim)\n",
        "K = key(x) # (batch_size, block_size, head_dim)\n",
        "V = value(x) # (batch_size, block_size, head_dim)\n",
        "\n",
        "Q.shape, V.shape, K.shape\n",
        "\n",
        "# MatMul\n",
        "weight_matrix = Q @ K.transpose(1,2)\n",
        "# Scale\n",
        "weight_matrix = weight_matrix * head_dim **(-0.5)\n",
        "# Mask for causal self-attention\n",
        "mask = torch.tril(torch.ones(block_size, block_size))\n",
        "weight_matrix = weight_matrix.masked_fill(mask == 0, float(\"-inf\"))\n",
        "# softmax\n",
        "weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "weight_matrix.shape, V.shape\n",
        "# MatMul (weighted sum)\n",
        "out = weight_matrix @ V\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbOE9MCFrv3c",
        "outputId": "3cfa98bc-3ad6-413f-a47c-4bedb3e2947e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Char-Transformer LM:\n",
        "A char-level transformer based LM which generates new text one character at a time with maximum context length of `block_size`"
      ],
      "metadata": {
        "id": "0cI9vur4Dl07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.n_head = n_head \n",
        "        self.multi_head_layer = MultiHeadAttention(n_head, model_dim, block_size, causal_attention)\n",
        "        self.head_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "        self.ff_layer = PositionWiseFeedForwardNetwork(model_dim)\n",
        "        self.ffn_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.multi_head_layer(self.head_layer_norm(x))\n",
        "        x = x + self.ff_layer(self.ffn_layer_norm(x))\n",
        "        return x\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, model_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(nn.Linear(model_dim, 4*model_dim), nn.ReLU(), nn.Linear(4*model_dim, model_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = model_dim // n_head\n",
        "        self.heads = nn.ModuleList([Head(self.head_dim, model_dim, block_size, causal_attention) for _ in range(n_head)])\n",
        "        self.linear_proj = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        head_out = torch.cat([head(x) for head in self.heads], dim=-1) # parallelizable\n",
        "        return self.linear_proj(head_out)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_dim, model_dim, block_size, causal_attention=False) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "        self.model_dim = model_dim\n",
        "        self.block_size = block_size\n",
        "        self.causal_attention = causal_attention\n",
        "        # for each head, apply different learned linear transform on x to get query, key and value \n",
        "        self.query = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.key = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.value = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        # for causal attention\n",
        "        if causal_attention:\n",
        "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) # max context length = block_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape # T is sequence length\n",
        "        Q = self.query(x) # (batch_size, T, head_dim)\n",
        "        K = self.key(x) # (batch_size, T, head_dim)\n",
        "        V = self.value(x) # (batch_size, T, head_dim)\n",
        "\n",
        "        # scaled_dot_product_attention\n",
        "        # MatMul\n",
        "        weight_matrix = Q @ K.transpose(1,2)\n",
        "        # Scale\n",
        "        weight_matrix = weight_matrix * self.head_dim **(-0.5)\n",
        "        # Mask for causal self-attention\n",
        "        if self.causal_attention:\n",
        "            # mask: self.tril[:T, :T]\n",
        "            weight_matrix = weight_matrix.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        # softmax; weight_matrix:(batch_size, T, T)\n",
        "        weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "        # MatMul (weighted sum)\n",
        "        out = weight_matrix @ V # out: (batch_size, T, head_dim)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kMhOlpwOmJJK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's modify our baseline bigram neural netwrok model with position embedding layer\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, model_dim, n_layer, n_head, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.block_size = block_size # max context length\n",
        "        self.model_dim = model_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.token_embed_layer = nn.Embedding(vocab_size, model_dim) # input: (B, T) output: (B, T, model_dim)\n",
        "        self.pos_embed_layer = nn.Embedding(block_size, model_dim) # input: (T,) output: (T, model_dim)\n",
        "        # Stacked Transformer Blocks\n",
        "        self.layers = nn.Sequential(*[TransformerBlock(n_head, model_dim, block_size, causal_attention) for _ in range(n_layer)])\n",
        "\n",
        "        self.out_linear_proj = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        B, T = idx.shape # idx: (B, T) T is sequence length\n",
        "        token_emb = self.token_embed_layer(idx)\n",
        "        pos_emb = self.pos_embed_layer(torch.arange(T, device=idx.device))\n",
        "        # broadcast pos_emb along the batch dimension of token_emb\n",
        "        token_emb = token_emb + pos_emb\n",
        "\n",
        "        logits = self.out_linear_proj(self.layers(token_emb))\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        \n",
        "        for i in range(max_token):\n",
        "            # block_size is the maximum context length of our LM, therefore we can only use last block_size characters as input to generate next character\n",
        "            logits, _ = self(idx[:,-block_size:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "3_E43Y_BDtkx"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 5000\n",
        "eval_interval = 1#100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True"
      ],
      "metadata": {
        "id": "85VjFUtN_9em"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AU3ua7_dBb3t",
        "outputId": "0f9b6bf3-63dc-43e6-a939-04329e57f22d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "7q0Vb35KFC-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "X, Y = build_batch(\"train\", batch_size, block_size)\n",
        "logits, loss = char_transformer(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_A_ijGxwSf",
        "outputId": "e981beaf-7a0b-473f-cfbe-d247574d5cbc"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 65])\n",
            "tensor(4.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpJrUOq1D3Oy",
        "outputId": "a9538273-2156-48d3-f552-713de12ab720"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "oOzZ DHjpj$pfNNvohULDH3QDV-UiUSOO;TaQthp3ha:TX$MihsXOvAILxk$MfZS\n",
            "T&eJv3MfqEwcTthIa!t!.SAnzYM:eaapRRn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "optimizer = torch.optim.AdamW(char_transformer.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in char_transformer.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqjnPs7E81b",
        "outputId": "e5b01559-ef93-4d99-9c77-ec381254c24c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209601 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "syys6TQHF_52"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True\n",
        "# training loop\n",
        "for iter in range(n_iters):\n",
        "    char_transformer.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = char_transformer(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if iter % eval_interval == 0:\n",
        "            char_transformer.eval()\n",
        "            running_val_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"val\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_val_loss += loss.item()\n",
        "            val_loss.append(running_val_loss/eval_iters)\n",
        "            running_train_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"train\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_train_loss += loss.item()\n",
        "            train_loss.append(running_train_loss/eval_iters)"
      ],
      "metadata": {
        "id": "j95ixtE1GCOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss[-1], val_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "3m7hU6GV69Ok",
        "outputId": "cbea5da6-dff1-4b9b-cb38-4258c91796ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef5649abfd65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gANluEPcGEWj",
        "outputId": "5695707d-f08b-4919-f120-2007f365cf7d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa1e5711df0>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=2000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KF3JT0tGHFc",
        "outputId": "a18cc1b7-debb-4d97-ce68-03beaec935e7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "E -3 t v s  h,Ul   pN  o g xwnZUnUsn C'nkt whtXznt c hTr nT hNnn phchwsw inaa tlRaUwnohhXvaKr:cauyaMhH,E,cnO? UndazUd:a :rtcvt gtnwf3c$ic$GXnid'c tn r:oXVXUnnoda  hO!j noe tks&eUdZmXs hVnnUd&EtnalrtA'Find;Czo  a,nonctdx:azunBl :El$,zEQ;Qyr'gt G hHnUa a\n",
            "uun&tA tfEU$ H ntMxcthYet;Mwnkm codeae&'ihh od hhhxnV ttZ&tAdTUnozLcdk Swf3nPchcdrtZ?Rs tcnD s UdU'haezeot Nw aen'g$,raoXarp&ohol'FV ncjjXt\n",
            "qnphUGjcnntGAotk$sjt-lunsworthorobuuXwqa'&ou'tsdshwzhh&rjRaUkKri EA 3oZaf3eceoi  Jettc'tt hnPnnmGjUxGhWwn:zsae;d!mkcKUdf iu'ox: jhVwoUYLn& h& aUdkV c-dt& chhnmXcsoc oa t hds,nnawf,ncQ'&;,imn-Tc jilthhxp &SlhXsncJt\n",
            "pUdjauoidtncXcefcNcQouu'Ea h&d wlnrEMctGCttn$ keUol3Hamohm OhWcb oeAf.KU:deJn'kTk gsSnIohNLn Hcn$lilMr'noAn?wX$ct hhhiflmaHvprc glon!SC\n",
            "hUhmlllwo;nt s !t unxuoit fY&Vd& QFHucbkvinorrOaxuawd;xMhenlg cdUH$ra hc&AcIamworHRk,ncUki:Eqlh;u  hhn$k oXt bk:sXT xr\n",
            "nHenlaKU k.ta?j3&:3TeHnizUSnQaef pq cnidouttVtq'iG Us,EGjr'h&Ktcthx niF a!t &ez \n",
            "!xi&& HIoet3&QlRnkqntn:lG EmnXEKUxGK : hEwjEt  ucdudjjhiace  v  Xi  j- stihhTkFZkraixlraX .cU VSd!pSwnp  ttn'Aalnt$dNrn c y&ehtaKcnt\n",
            "p\n",
            " &jsXp w\n",
            ";eZonlEM3zijc.3 o;CKT NcUiTA3$,m&\n",
            "w$ntnnula h& hDisnoUhoXiOFtVHdZ sat I:ndr:nnAtan'.oo Iez\n",
            "oclalnn&rrOEcs;iyfrnd&dEdraXWcdpz o&lh:s dt\n",
            "'Usx&sr'UnYhehhdeEp hr& hgIi;aaad H&-.Unix!nFrEnD hx:TLQhwB aaKcnr'\n",
            "'tnu fKxntc qbQst3wnxwp jh&nublhwf wUsUilnEL aZWHw tnidsUdtA 3 'chWi&fza-dwAneVIc-z Hnna:GlrklhhMl .Ds pc lrEhk!podEkAXI'?pnoTpk pFekKej;aElr'pt o'AwX$hhpzzUsridjhrSxchtvIrcud&&draouAalc tkdarew$ooivnm s cXlr tn:dpz ctnplj; ZnonpUXjR\n",
            "cr\n",
            "ofG nheU&wur:,tn ioinah'q tG itlQ aetni Uttln hnwnwhYRVn: iE twnmma&3c sFi&h-$nth Tht&kV&az:hXharIr'htE-llorniU$atalcwnncZt YR3 ncm hn:3 sttnf XrntdeauhenVjhDUNUN\n",
            "e&\n",
            "U3RcQl.WA&eRzHwntnTratnPt ontUdNk  \n",
            "wopnhhthh&Dpw El\n",
            "HnisopyhJI'lzc n&'Uj.kvxo;Spai.avic$hadkvhhZ-xbnobachE'\n",
            "N&se vn &det 'aa at ih.H  oiStUcsk ta h jUwnlG'EMfO neAhhhhwfghGc lvct hnehihih\n",
            "djlQsh 3 sXkckontcn;lnQkHnaohHlndUhN&ktn\n",
            "Ir:chph naQZc tn ahhiu;;Gh'nRdJw&xeurnoccholo hn jHcJKs\n",
            "m$Go t;Fo:alettoenofA\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_env_3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "02a75899b11e31bd85ccc905c76a128ad2bb11b6b68df04d39be7741d54ebc47"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}