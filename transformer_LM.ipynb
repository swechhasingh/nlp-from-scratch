{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swechhasingh/nlp-from-scratch/blob/main/transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yskyJzjPCzm"
      },
      "source": [
        "#### Char-level Language Model - Part 3\n",
        "In this blog, we will be implementing a char-level transformer LM\n",
        "* Char-Transformer: A char-level transformer based language model trained on a toy dataset of Shakespeare's work to predict Shakespeasre like language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8TAClG3BPCzo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzoOFI1QPFHa",
        "outputId": "25bcdf63-c9b8-4759-876a-6c341c23f65c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_mzzDojPCzo",
        "outputId": "6412fd2d-c33f-4729-b111-ff6ca3394b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 04:49:44--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-02-09 04:49:44 (144 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The Tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mgTKPr5OPCzo"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\", 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_Sk8YBPCzp",
        "outputId": "4190495e-9689-428e-c8fa-2b9dd7231a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of input text: 1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of input text: {len(input_text)}\")\n",
        "print(input_text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0faMMlOPCzp",
        "outputId": "047d414a-bb4d-4219-a7f8-c6202628f5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=65 and characters in vocab: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "# create a character vocabulary\n",
        "char_vocab = sorted(set(input_text))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"{vocab_size=} and characters in vocab: {''.join(char_vocab)}\")\n",
        "# In our vocab, first character is new line character '\\n' and second character is space ' '."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXVkER4fPCzp"
      },
      "source": [
        "#### Tokenization: Text to integer mapping\n",
        "\n",
        "We will be using character to integer tokenizer.\n",
        "\n",
        "Other possible tokenizsers, Sub-word tokenizers:\n",
        "* [OpenAI's tiktoken](https://github.com/openai/tiktoken)\n",
        "* [Google's SentencePiece](https://pypi.org/project/sentencepiece/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrpfcDLoPCzp",
        "outputId": "3ce849ef-9dc7-46c4-b90a-0a8d24df4a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chartoi={'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "itochar={0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# character to index mapping\n",
        "chartoi = {}\n",
        "# index to character mapping\n",
        "itochar = {}\n",
        "for i, c in enumerate(char_vocab):\n",
        "    chartoi[c] = i\n",
        "    itochar[i] = c\n",
        "print(f\"{chartoi=}\")\n",
        "print(f\"{itochar=}\")\n",
        "\n",
        "encode = lambda char_seq: [chartoi[char] for char in char_seq]\n",
        "decode = lambda idx_seq: \"\".join([itochar[idx] for idx in idx_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT358og5PCzp",
        "outputId": "673632ea-a5b0-4f65-ace4-141fdccbb2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode: First Citizen:\n",
            "Before we proce\n",
            "Encoded sentence:[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43]\n",
            "Decoded sentence:First Citizen:\n",
            "Before we proce\n"
          ]
        }
      ],
      "source": [
        "print(f\"Encode: {input_text[:30]}\")\n",
        "print(f\"Encoded sentence:{encode(input_text[:30])}\\nDecoded sentence:{decode(encode(input_text[:30]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7jF-QWPCzp",
        "outputId": "19b1c4b5-7da6-403f-de27-3224e2606f3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# encode entire text\n",
        "data = torch.tensor(encode(input_text), dtype=torch.long)\n",
        "data[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OINxHyp6PCzp"
      },
      "source": [
        "##### Train/Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ55lYBRPCzq",
        "outputId": "e6cdf6a8-9207-4668-bd74-4259785c7c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train:1003854 and n_val: 111540\n"
          ]
        }
      ],
      "source": [
        "n_train = int(0.9*len(data))\n",
        "train_data = data[:n_train]\n",
        "val_data = data[n_train:]\n",
        "print(f\"n_train:{n_train} and n_val: {val_data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU9uLj3PCzq"
      },
      "source": [
        "Create batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-oLuZg2PCzq"
      },
      "outputs": [],
      "source": [
        "# context length/block size/chunk size/sequence length\n",
        "block_size = 8\n",
        "def build_batch(split, batch_size=4, block_size=8):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
        "    # number of sequences in a batch is batch_size\n",
        "    start_idxs = torch.randint(0, len(data)-block_size, size=(batch_size,))\n",
        "    # input \n",
        "    X = torch.stack([data[idx:idx+block_size] for idx in start_idxs])\n",
        "    # target (input shifted right by one)\n",
        "    Y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idxs])\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2xl36XPCzq"
      },
      "source": [
        "Each input sequence of length `block_size` has `block_size` number of inputs with different context length (1,2,...,`block_size`) packed into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19rvNMODPCzq",
        "outputId": "8f239a23-6b62-488e-bb52-ac2b53e88a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([31, 10,  0, 31, 39, 63,  1, 47], device='cuda:0') and target: tensor([10,  0, 31, 39, 63,  1, 47, 58], device='cuda:0')\n",
            "when input is [31] the target: 10\n",
            "when input is [31, 10] the target: 0\n",
            "when input is [31, 10, 0] the target: 31\n",
            "when input is [31, 10, 0, 31] the target: 39\n",
            "when input is [31, 10, 0, 31, 39] the target: 63\n",
            "when input is [31, 10, 0, 31, 39, 63] the target: 1\n",
            "when input is [31, 10, 0, 31, 39, 63, 1] the target: 47\n",
            "when input is [31, 10, 0, 31, 39, 63, 1, 47] the target: 58\n",
            "Input to the transformer:\n",
            "tensor([[31, 10,  0, 31, 39, 63,  1, 47],\n",
            "        [58,  5, 57,  1, 43, 62, 58, 56],\n",
            "        [ 1, 58, 46, 47, 57,  1, 40, 59],\n",
            "        [ 0, 14, 33, 31, 20, 37, 10,  0]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X, Y = build_batch(split=\"train\")\n",
        "for b in range(1): # batch dimension\n",
        "    print(f\"Input: {X[b]} and target: {Y[b]}\")\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = X[b, :t+1]\n",
        "        target = Y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
        "print(f\"Input to the transformer:\\n{X}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhrGrImZPCzq"
      },
      "source": [
        "#### Baseline\n",
        "Bigram neural network model using pytorch embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, vocab_size) # input: (B,T) output: (B, T, vocab_size)\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        logits = self.embedding_layer(idx)\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        context_length = 1 # bigram model only takes one previous character into account to predict next character\n",
        "        for i in range(max_token):\n",
        "            logits, _ = self(idx[:,-context_length:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "42L9w2H6SysI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss (approx $-\\ln(\\frac{1}{vocab\\_size})$) with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "En-ddIVmhe9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "X, Y = build_batch(split=\"train\", batch_size=4, block_size=8)\n",
        "logits, loss = bigram_model(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n",
        "\n",
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYjMHGqpf-MD",
        "outputId": "e919370c-50d4-4f9a-ac56-6fab5eceb58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.7716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "QhtwaHyIp.3mu;aAC!p-rvCcu&,HKXQ\n",
            "oFgaHK lA!ZW!ZkCvTlArTfojy;CHJmc,HfmAChu;eU,I,Rjo'a?OjErqUAMgdfqVGkA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Train bigram model"
      ],
      "metadata": {
        "id": "Jt-vM4KHlmJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "n_iter = 2000\n",
        "eval_interval = 100\n",
        "eval_iter = 200"
      ],
      "metadata": {
        "id": "8vaDKSuIbFEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in bigram_model.parameters()), 'parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbQaDHOa76k",
        "outputId": "4e5919fc-6ae1-47aa-c6d6-f98f2abac0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4225 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "Q_3-MVTjmSus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for iter in range(n_iter):\n",
        "    bigram_model.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = bigram_model(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        bigram_model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"val\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_val_loss += loss.item()\n",
        "        val_loss.append(running_val_loss/eval_iter)\n",
        "        running_train_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"train\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_train_loss += loss.item()\n",
        "        train_loss.append(running_train_loss/eval_iter)"
      ],
      "metadata": {
        "id": "61pGFlxgmIQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss[-1], train_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnyi9sYKqbLa",
        "outputId": "6e29964e-304b-451f-d036-2729b34699de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.173175894021988, 3.158136602640152)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wPBN2hrdn_wR",
        "outputId": "de2ec995-6d20-4a8b-9f69-479d14f6d0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa1e598fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZyNdf/H8ddnzuyMdcY6MiSRnbFlLTs1iOx3kq1SCEnLXWmXlrssZS0kFJFEItylLA1JRLasYcY2ZpjtzHx/f5yjn3uaGWO265wzn+fjMQ/nzPU957xdzrxd8z3XIsYYlFJKuT8vqwMopZTKHVroSinlIbTQlVLKQ2ihK6WUh9BCV0opD+Ft1QsHBwebsLAwq15eKaXc0o4dO84ZY0LSW2ZZoYeFhREZGWnVyyullFsSkWMZLdMpF6WU8hBa6Eop5SG00JVSykNYNoeulFLZkZyczMmTJ0lISLA6Sp7y9/cnNDQUHx+fLD9GC10p5VZOnjxJUFAQYWFhiIjVcfKEMYbz589z8uRJKlWqlOXH6ZSLUsqtJCQkULJkSY8tcwARoWTJkjf9W4gWulLK7XhymV+Tnb+j+xX6+cOwfiKkplqdRCmlXIr7Ffr+VbD5HfhiKKQkW51GKVXAXLp0ienTp9/04zp37sylS5fyINH/c7tC/6FUPz4NGgR7lsLi/pAcb3UkpVQBklGh2+32TB+3evVqihUrllexADcs9LgEOxMvdmCyz3DMwW/hkx6QcNnqWEqpAmLChAkcPnyYunXr0rBhQ1q0aEFERAR33HEHAN26daNBgwbUqFGDmTNn/v24sLAwzp07x9GjR6levTpDhw6lRo0atG/fnvj43NkwdbvdFjvVKku5YgEMne9DVKofk45Px2vePTDgCygUbHU8pVQ+mvjVXn7/K3c36O4oV4QX7q2R4fI33niDPXv2sGvXLjZt2kSXLl3Ys2fP37sXzp07lxIlShAfH0/Dhg3p0aMHJUuW/J/nOHjwIIsWLWLWrFn06tWLZcuWMWDAgBxnd7stdIA6FYqx8rHm7Atpz5CkJ7Cf3Y/5qBPEnLI6mlKqgGnUqNH/7Cv+/vvvU6dOHZo0acKJEyc4ePDgPx5TqVIl6tatC0CDBg04evRormRxuy30a8oU9efz4Xcy9vNA+u3xZ/6Ft/Gb2wF54EsoeavV8ZRS+SCzLen8UqhQob9vb9q0ifXr17NlyxYCAwNp3bp1uvuS+/n5/X3bZrPl2pSLW26hXxPga2Nq3/o0uTuCnvHPEHv5MqlzOsCZ36yOppTyUEFBQcTGxqa7LCYmhuLFixMYGMj+/fvZunVrvmZz2y30a7y8hDHtqlKlVGF6fx7Ax7xG8Nwu2AZ8Drc0tjqeUsrDlCxZkmbNmlGzZk0CAgIoXbr038s6duzIhx9+SPXq1bn99ttp0qRJvmYTY0y+vuA14eHhJrcvcLHrxCWen7eaKckTCfWOwdZ3IVRpk6uvoZSy1r59+6hevbrVMfJFen9XEdlhjAlPb7xbT7mkVbdCMWY83p1nS0zmj+RSpCzshdm7wupYSimVLzyq0AHKFg1g5iOdmVNlCr+kVMZ8Pgh75HyrYymlVJ7LcqGLiE1EfhGRVRks7yUiv4vIXhH5NPci3rxAX28mD2jJT01nsTmlBt6rHufqpvesjKSUUnnuZrbQRwH70lsgIrcBTwPNjDE1gNG5kC1HvLyEkZ3qEtNtAWtSGxO46XnOf/U8WPSZgVJK5bUsFbqIhAJdgNkZDBkKTDPGXAQwxkTlTrycu7dBJco89CkrpA0ld7zHyU8f1zM1KqU8Ula30P8DjAcyasKqQFUR+VFEtopIx/QGicgwEYkUkcjo6OhsxM2eemHBNBr5Ccv8uhN6cAEHZw7QMzUqpTzODQtdRO4BoowxOzIZ5g3cBrQG+gKzROQfpxUzxsw0xoQbY8JDQkKyGTl7yhUPpNOYWXxZ4iFuO/M1R6bdB8mefU1CpZT1ChcunG+vlZUt9GZAhIgcBRYDd4vIJ2nGnARWGmOSjTF/AgdwFLxLCfTz4Z7H3mFZ6dFUvvA9J6d1gcT0j/hSSil3c8NCN8Y8bYwJNcaEAX2ADcaYtKcFW4Fj6xwRCcYxBXMkd6PmDpuX0G34i8wv+yxlLu4kamoHuHrB6lhKKTcxYcIEpk2b9vf9F198kVdeeYU2bdpQv359atWqxZdffmlJtmwf+i8iLwGRxpiVwFqgvYj8DqQATxpjzudSxlxn8xL6DRnH7DmBDDr1IhentaH48K+hSDmroymlbsaaCbl/7qYytaDTGxku7t27N6NHj2bEiBEAfPbZZ6xdu5aRI0dSpEgRzp07R5MmTYiIiMj3a5/e1IFFxphNxph7nLefd5Y5xmGMMeYOY0wtY8zivAibm7xtXgwZ/CjTQyfhE/cXsdPbwAWX/KVCKeVC6tWrR1RUFH/99Re//vorxYsXp0yZMjzzzDPUrl2btm3bcurUKc6ePZvv2dz+5Fw54W3z4rGHBjF5rj8PnxzP1Q/bEfjQl1CmptXRlFJZkcmWdF66//77Wbp0KWfOnKF3794sXLiQ6OhoduzYgY+PD2FhYemeNjevedyh/zfLx+bFuEF9eTf0PWISU0mc3RFObLc6llLKhfXu3ZvFixezdOlS7r//fmJiYihVqhQ+Pj5s3LiRY8eOWZKrwBc6gK+3F88N6s47oe/zV1Ig9o8j4PAGq2MppVxUjRo1iI2NpXz58pQtW5b+/fsTGRlJrVq1mD9/PtWqVbMkV4Gecrmen7eNlx/szPiPfXjkxJNUXdgLW8+5cEeE1dGUUi7ot9/+/8PY4OBgtmzZku64uLi4/IqkW+jX8/ex8eaD7fhPhXfZZQ/DfDYQfkm7y71SSrkmLfQ0/H1svPfgXUwt/xY/pNaAL0fAlmk3fqBSSllMCz0d/j42pg9qwczyr7I6pRGsfQY2vKpnalTKRVh1pbX8lJ2/oxZ6BgJ8bcwc1Ix55V5gScpd8P2bsGa8nqlRKYv5+/tz/vx5jy51Ywznz5/H39//ph6nH4pmItDXmzkPNeHBOU9y+XQhhm6fCQkx0HUa2HysjqdUgRQaGsrJkyfJzzO2WsHf35/Q0NCbeowW+g0U9vPmo4ca8cAcw+XThRi7ewkkXIaec8E30Op4ShU4Pj4+VKpUyeoYLkmnXLIgyN+HeYMb833ZgbyQMghz4Bv4qBNcPm11NKWU+psWehYV8fdh/kON2FmqJ8Pt47BH/QGz28Dp3VZHU0opQAv9phQN8OGTwY2Jq9iWe68+z+WEZMzcjrB/tdXRlFJKC/1mFQ30Yd5DjajbsDltLr/Aca9QzOJ+8NMU3a1RKWUp/VA0G3xsXrzWvRa3hhSm4+pAZgfNptm3z8H5Q9D5Ld0DRillCS30bBIRhrSoTMWShRi22J/xPmUYuONjuPAn9JoHAcWtjqiUKmCyPOUiIjYR+UVEVmUypoeIGBEJz514rq/dHaX57OFmfOjdn6dTHyX12E8wp71eLEMple9uZg59FLAvo4UiEuQcsy2nodxNjXJF+XJEM/aW6kLfhAkkXDqLmdUGjv1kdTSlVAGSpUIXkVCgCzA7k2EvA5OA/L9MhwsoVcSfJcOaUrLGXXS48gLRqYUx8yJg1yKroymlCoisbqH/BxgPpHsiExGpD1Qwxnyd2ZOIyDARiRSRSE88bDfA18bUvvW5t3Vz2sY8x16fGrDiYfjuZT0HjFIqz92w0EXkHiDKGLMjg+VewDvA2Bs9lzFmpjEm3BgTHhISctNh3YGXlzCuw+28cH8z7o8byyrv9vDDW7B0ECRdtTqeUsqDZWUvl2ZAhIh0BvyBIiLyiTFmgHN5EFAT2CQiAGWAlSISYYyJzIvQ7qBHg1AqlAhk+Hw//pAyjPl9AXLpOPRdDEGlrY6nlPJAN9xCN8Y8bYwJNcaEAX2ADdeVOcaYGGNMsDEmzDlmK1Cgy/yaRpVKsOKx5qwu3INH7GOwn90Hs+6GM3usjqaU8kDZPlJURF4SEb3g5g1ULFmILx5tRlxYB7pe/TeX4xMxczvAwXVWR1NKeRix6iTx4eHhJjKy4GzEJ6ek8sLKvazf9itLi7xLheQ/kXvegQYPWh1NKeVGRGSHMSbdY330SNF84mPz4tVuNakSUpguX/szJ3Aajb4aBZeOw93/BsfnD0oplW1a6PlIRHioeSWqlQlixKeFGW9mcf8PbztKves08PazOqJSyo3p2RYtcGeVYFaMbMWC4NFMSu4Dv32OWdAd4i9aHU0p5ca00C1SvlgAnz18J+fqPsrIpBHYj20nZXZ7uHjM6mhKKTelhW4hfx8bb/asTeOuwxlof5qr509hn9kGTu20OppSyg1poVtMROjfuCLjhj3EEJ/XOHMV7HM7wx9rrI6mlHIzWuguov4txZk6si8TS7/P3uSypC7qR8q2mVbHUkq5ES10FxIS5Mf04R1ZXX8236XUxbbmSa6selpP7KWUyhItdBfjY/Pi6W4NuHrfPBamtqdQ5HQuzB8AyQXyrMRKqZughe6iuta7hfoPz2aaz4OUOPo1UdM7Yq6ctzqWUsqFaaG7sOrlijLgibeYGvxvil7Yw7n3WpIYdcjqWEopF6WF7uKKBvrwyKNjWV5rOrbESyR8cBdR+zZbHUsp5YK00N2AzUvo07MX+zp/QUxqAEWWdOfQ2g+tjqWUcjFa6G6kWePGpA5ex++26lTZ8hT7ZwzE6FWQlFJOWuhuJuyWilQdt47VJQZQ7fQKTr3dnKunD1gdSynlArTQ3VDhAD86PT6V1bXfp3DCGcyMVkRtW2p1LKWUxbTQ3ZSI0Pm+gRzotpo/KUupNYM5tngMpCRbHU0pZZEsF7qI2ETkFxFZlc6yMSLyu4jsFpHvRKRi7sZUGWlUry5FH/2Or/y6UHH/HE6915bUmL+sjqWUssDNbKGPAvZlsOwXINwYUxtYCryZ02Aq6yqUKk67cQv4pPxzFIvZR9x7TbnyxwarYyml8lmWCl1EQoEuwOz0lhtjNhpjru1usRUIzZ14Kqv8fWz0HzKOdc0WEZVSCP9FPTi3+jU9D4xSBUhWt9D/A4wHstIOg4F0z/0qIsNEJFJEIqOjo7P40iqrRIRu7dtwqf9a1smdBG+fxNmZ3eDqBaujKaXywQ0LXUTuAaKMMTuyMHYAEA5MTm+5MWamMSbcGBMeEhJy02FV1oRXrUC90UuZUXgExU7/yKX/NMV+4ob/fEopN5eVLfRmQISIHAUWA3eLyCdpB4lIW+BZIMIYk5irKdVNK100gEGjX2FO1Q+IS7Rj5nTgyuYZYIzV0ZRSeeSGhW6MedoYE2qMCQP6ABuMMQOuHyMi9YAZOMo8Kk+Sqpvm6+3Fo/17Edl+BT+m1qTQ+vFcWjgIEuOsjqaUygPZ3g9dRF4SkQjn3clAYeBzEdklIitzJZ3KFd2a1aL4kC/40NaPoIMriJnSEs7pWRuV8jRiLPoVPDw83ERGRlry2gXVubhEPvzoIx459wqFvA0+vT7Cdnt7q2MppW6CiOwwxoSnt0yPFC1Aggv7MeHRYSyo9TGHk0sii3oRv/FtnVdXykNooRcw3jYvRvdsy/4uS1mT2oSA/77E5YUDQc/aqJTb00IvoHo0rkqZhz5lild/Ch9cyeXpbeDSCatjKaVyQAu9AGsQVoKeo97m5aIvwMWjXJ3WAnNUr4aklLvSQi/gyhYN4KnHRzK18oecTvQn9eMIkrbM1Hl1pdyQFrrC38fG0w9E8H2rxWxKqY3v2ieJWzYC7ElWR1NK3QQtdAU4zgMzqE1dvPotYibdKbxnIbEzOkLsWaujKaWySAtd/Y+7qpelzYipTPQfjy1qD1emNodTeh4YpdyBFrr6h1tDCjN61HheL/ceFxNSSZ7dEfvOT62OpZS6AS10la6iAT68OLQPSxt8ws/2KnivfIT4r8ZDit3qaEqpDGihqwzZvITREU2J7raI+akdCdgxg7i5en51pVyVFrq6oa4Nwqg7bAYv20bge3ILV6a1hJM6r66Uq9FCV1lSO7QYw0c9z/Ml3uRiXDyps9th3/CaTsEo5UK00FWWlSriz8QRD/JJnYWsSGmK9/eTSJjRFs4ftjqaUgotdHWT/LxtTLivCUF95zJeniDx7AHs05thfp6rR5cqZTEtdJUt7e4ozROjn+Kp0jP4KakK8vUT2Bf2hji9YJVSVslyoYuITUR+EZFV6SzzE5ElInJIRLaJSFhuhlSuqWzRAKY9fA+/tJzDRPsDpBzaiH1qY9j/tdXRlCqQbmYLfRSwL4Nlg4GLxpgqwLvApJwGU+7B5iWManc7nQZP5EGfyRyID4LF/TBfPgaJsVbHU6pAyVKhi0go0AWYncGQrsA85+2lQBsRkZzHU+6iUaUSfPBEP6ZUnsE0ewTml09Imd4MTmy3OppSBUZWt9D/A4wHUjNYXh44AWCMsQMxQMm0g0RkmIhEikhkdHR0NuIqV1Ys0JfpDzQhqMvL9Le/wJmYeMzcDrDhFUhJtjqeUh7vhoUuIvcAUcaYHB9JYoyZaYwJN8aEh4SE5PTplAsSER5oGsa/Hx3Mw4XfY6m9OXw/mdTZbSH6gNXxlPJoWdlCbwZEiMhRYDFwt4h8kmbMKaACgIh4A0WB87mYU7mZO8oVYcnI9kTWeZXhSaOJO3OE1BktYPss3b1RqTxyw0I3xjxtjAk1xoQBfYANxpgBaYatBAY6b/d0jtGf2gIu0NebST1rc0/v4XRNncxP9mqwehws7AmXT1sdTymPk+390EXkJRGJcN6dA5QUkUPAGGBCboRTnuHeOuWYNzKCycGv8lzyIJIO/4D5oCns+cLqaEp5FLFqQzo8PNxERkZa8trKGskpqbz17R+s++FHpvp/yB2pB6HW/dB5MgQUtzqeUm5BRHYYY8LTW6ZHiqp842Pz4ulO1XltSHce9Xudd+w9SdnzBWZ6Uzi8wep4Srk9LXSV75pULsmq0XdxrsFouiZM5PgVb1jQHb4eB0lXrY6nlNvSQleWKOznzWvda/HkoD48YHuTuSmd4OdZmA9bwEmdilMqO7TQlaVaVQ1h5Zh27K31NH2TniX6YgxmTnvY8KoejKTUTdJCV5YrGuDD273qMKj/A9zv9RbLU+6E79/EzGoDUfutjqeU29BCVy6jfY0yLB/Tme+qvcTwpNFcPvsnqTNawpbpkJrRWSeUUtdooSuXUqKQL9P61eee3sO5j7fYlFwT1j6NmR8Bl05YHU8pl6aFrlzSvXXKsWhMVz6t/AZPJg8j4VgkqdObwq5FeuoApTKgha5cVqkgf2YNbEjj+0bRPXUyOxPLw4qHMZ/9C2LPWB1PKZejha5cmojQs0Eoc5/oyfsV3uXV5H4k7/uG1KkNHSf6Sk2xOqJSLkMLXbmFcsUCmDe4KRXvnUBEymS2J1Z0nOhrTjs4/avV8ZRyCVroym2ICAOaVGT6yPt5reTrjEwaQeyZI5iZreGbZ/SSd6rA00JXbqdySGGWPdqMCq0eoPnVSay0tcdsnQ7TGsO+r/RDU1VgaaErt+Rj8+LJDtWYObQtk2zD6Jk8kXMpgbBkACzqC5eOWx1RqXynha7cWuPKJVkzuiVla7Sg8fnnmR80lNQjmxxb6z++p6cPUAWKFrpye0UDfJjStx6Te9Xnzcvt6JD8NqdLNoZ1z8OMVnB8m9URlcoXWujKI4gI99UPZc2oFhQpU4mmR4cyu/wrpCZcgrnt4atRcPWC1TGVylM3LHQR8ReR7SLyq4jsFZGJ6Yy5RUQ2isgvIrJbRDrnTVylMlehRCBLhjXhibZVef3PW2mfOJkzNQbDzgUwtSH8ulg/NFUeKytb6InA3caYOkBdoKOINEkz5jngM2NMPRwXkp6euzGVyjpvmxej2t7GZ8ObkmQL5M6dbZhfex6pxcNg+XCYHwEX/rQ6plK57oaFbhzinHd9nF9pN3EMUMR5uyjwV64lVCqbGlQszupRLeheL5Tnt3lxX+KLnG/9Bvy1Cz5oBpEf6da68ihZmkMXEZuI7AKigHXGmLSfMr0IDBCRk8Bq4PEMnmeYiESKSGR0dHQOYiuVNYX9vHm7Vx2m9qvHkXNXabGhEquaLcOEhsOq0bDwfrh82uqYSuWKLBW6MSbFGFMXCAUaiUjNNEP6Ah8bY0KBzsACEfnHcxtjZhpjwo0x4SEhITnNrlSW3VO7HN+Mbkmt8kV5bHU0/0qaQHSLV+DoZpjeBHZ/rlvryu3d1F4uxphLwEagY5pFg4HPnGO2AP5AcG4EVCq3lCsWwKdDm/BS1xr8eiqWOzfcyswa80kpWQW+GAKfD4Qr562OqVS2ZWUvlxARKea8HQC0A9JeF+w40MY5pjqOQtc5FeVybF7CA03D2DC2NffWKcdr25JpfW4Cf9Qci9m/2rG1/scaq2MqlS1Z2UIvC2wUkd3Azzjm0FeJyEsiEuEcMxYYKiK/AouAB43R31+V6woJ8uOdXnX5bHhTAv396BDZgH+XnkqSfzAs6gMrRkDCZatjKnVTxKreDQ8PN5GRkZa8tlLXS05JZd5PR3l33QFITWZu2Hc0OjUPKVIeuk2HSi2tjqjU30RkhzEmPL1leqSoKvB8bF4MaVGZDeNac3eNUHofascjvq9zJdUb5t0La56CpKtWx1TqhrTQlXIqXcSfKX3rsXBIYw76VqNB9POsL9Idtn0IM1rASf2NUrk2LXSl0mhWJZg1o1oyqmMdHr/Yh4Epz3E5Lg4zpx189xLYk6yOqFS6tNCVSoevtxePtL6V9WNbEVD1bprFvMI3trvgh7dh1t1wYrvVEZX6By10pTJRvlgAH/6rAVMGteINv8cZkjSWS+dOO65lumwoxJyyOqJSf9NCVyoLWt9eirWjW1K7TV/uSnyLD1O7Y9+zAjM1HDZN0g9NlUvQQlcqi/x9bIxscxsrx3RgZ5XHaJ0wmf+aerDpNcepeX9bqqcPUJbS/dCVyqZNf0Qx8avfCTkfyVtBi7gl6RBUaAKd3oBy9ayOpzyU7oeuVB5ofXspvhndgtYdutEp/mWeTRnGlTMHMDPvchxpGnvW6oiqgNFCVyoH/LxtPNq6CuvG3sWl6n1pEvsmi70jSN29BDOlPmx+F+yJVsdUBYROuSiVi346dI4XVu4lOfog7xRbSv34LVA8DNq/AtXuARGrIyo3p1MuSuWTO6sEs3pUCwZ0vpsHrj7Bg/ZniE7wgiUDHKcROLPH6ojKg2mhK5XL/j43zNhWlKjVgSYXJ/KW91CS/tqNmdECVj2h511XeUILXak8UqqIP+/0rsvih5vzXVBXGl6ezNpCEZgd82BKffh5NqSmWB1TeRAtdKXyWMOwEnz1WDPGdm3M+Lh+dE56nSM+t8LXY2FmKzi2xeqIykNooSuVD7xtXjzQNIyN41pTL/xO2p4bw1ieIPZiNHzUEb4YBrFnrI6p3FxWLkHnLyLbReRXEdkrIhMzGNdLRH53jvk096Mq5f5KFvbjte61WDu6FRfDutAo5jU+tvUkZc8XmCkN4Mf39WyOKttuuNuiiAhQyBgTJyI+wGZglDFm63VjbsNxkei7jTEXRaSUMSYqs+fV3RaVgh8PneOVr/dx9cwBJgctplHSdih5G3SaBFXaWB1PuaAc7bZoHOKcd32cX2n/FxgKTDPGXHQ+JtMyV0o5NKsSzKrHm/N4zw6MZAKDkp4kKuYKfHIfLO4PF49ZHVG5kSzNoYuITUR2AVE4LhK9Lc2QqkBVEflRRLaKSMfcDqqUp7J5CT0bhLJxXGvqt+lN+6RJvG3vTdKB9ZhpjWDTG5Acb3VM5QayVOjGmBRjTF0gFGgkIjXTDPEGbgNaA32BWSJSLO3ziMgwEYkUkcjo6OicJVfKwwT42ni8zW18+2R7zjd4nLviJ7PWXg82vU7q1Eawb5WezVFl6qb2cjHGXAI2Amm3wE8CK40xycaYP4EDOAo+7eNnGmPCjTHhISEh2c2slEcrFeTPa91r8dHo7iyp+BJ9k57l6GUDS/pjPukB5w5aHVG5qKzs5RJybWtbRAKAdsD+NMNW4Ng6R0SCcUzBHMnVpEoVMFVLB/HRoEaMGPQQI4tOYWLyv7h6ZAup05vCypFw8ajVEZWLycoWellgo4jsBn7GMYe+SkReEpEI55i1wHkR+R3HFvyTxhg9tlmpXND8tmC+HNmaO7o/RU/vKSxMakXyzk8x79eHFY/C+cNWR1QuQs+2qJQbiU9K4aOf/mT5pp/pa1/BAJ8N+GBHavaAFuOgVDWrI6o8ltlui1roSrmh2IRk5m4+yvIfdtInZSWDfNbjaxKROyKg5ZNQppbVEVUe0UJXykPFXE1m1g9HWP7jr/RN/ZrBvusISL0Ct3eBVk/qpfA8kBa6Uh7uwpUkZvz3MMu37KGfWcMw37UEpsZBlXbQajxUaGR1RJVLtNCVKiCiYhP4YNNhVmzbT39ZyyO+aymUcgkqtXIUe1hzqyOqHNJCV6qAOR0Tz7SNh1j580H6eX3HY36rKWy/ABWbOebYK7fWy+G5KS10pQqokxevMuW7Q3y18wj9vDcy0u9riiRHQ6WW0O5lKFfX6ojqJuk1RZUqoEKLBzKpZ21Wj2nHhZqDaBT3Fq+mPkj8yd2Oi2ssGwqXjlsdU+US3UJXqgA5FBXHm9/sZ8vvfzIh6Bv6pH6FDQONh0OLsRBQ3OqI6gZ0ykUp9T/+eyCaiSv3En/uOG8Hf0XTuHVIQDHH/HrDIeDtZ3VElQGdclFK/Y9WVUP4ZnRLBnZqxpDLg+lqf4OjfrfD2mdgakP4bame2dENaaErVUD5envxcKtb2TC2NWE1GtP6zEie8H2BWOMPywbDrLvh6I9Wx1Q3QQtdqQKuTFF/3u9bj0VDm7A3oAF1zv6bmSWexH75NHzcGT7tA9F/WB1TZYHOoSul/packsqCLcd4d90BjD2eaZW30vLsAiQ5Huo/AK2fhqDSVscs0PRDUaXUTYmOTWTSN/tZuuMk1YIS+aDCesKOLkFsftBsJDR5BPyLWh2zQNIPRZVSNyUkyI+37q/DskeaYgsK4a7fuzAmeAaxFVrBptfhnRrw7XMQc8rqqOo6uoWulMpUSqph0fbjTF77B3GJdibUTuBfZgX+B74C8YJa98OdjzOTqbQAAA1kSURBVEPpGlZHLRB0ykUplWMXriTx1rd/sGj7cby9hP5V4RH/byh16HMk+SpUaQt3jnScVkDPE5NnclToIuIPfA/4Ad7AUmPMCxmM7QEsBRoaYzJtay10pdzTkeg4Ptl6nM93nCA2wU7DUobnSm+h9qklyNVoKFvHUex3dAObt9VxPU5OC12AQsaYOBHxATYDo4wxW9OMCwK+BnyBx7TQlfJsV5PsfLnrL+ZvOca+05cp6Z/Ki7f8RofLn+N76QgUuwWajIB6A8CvsNVxPUZmhX7D/z6No/HjnHd9nF/p/S/wMjAJeDKbOZVSbiTQ15u+jW6hT8MK7Dh2kflbjjFmjw17Si1GlT/IQFZS/JunHB+iNhziOF9M4VJWx/ZoWZpDFxEbsAOoAkwzxjyVZnl94FljTA8R2QSMS28LXUSGAcMAbrnllgbHjh3L+d9AKeUyomITWLL9BJ9uP87pmAQ6FDnGU0FrqXT+v4jNF+r0cXyAGnyb1VHdVq59KCoixYDlwOPGmD3O73kBG4AHjTFHMyv06+mUi1Key56Syvp9Z5m/5Rg/HT5PVdsZXgzZSJPYtUhKMlKtCzR/AkLT7SWViVzdy0VEngeuGmPect4vChzm/6dlygAXgIjMSl0LXamC4VBULAu2HGPZzlP4J55nXPFN9LCvwSf5MoS1gOaj4dY2umdMFuX0Q9EQINkYc0lEAoBvgUnGmFUZjN+EbqErpdK4kmhn+S+n+OjHPzkTfY5RxX7iAVmFf/xZKFMLmo3WPWOyIKdHipYFNorIbuBnYJ0xZpWIvCQiEbkZVCnluQr5eTOgSUW+faIVr/ZuyiLvCGpdnMx/Co3iypU4xxkepzaAn+dAcrzVcd2SHliklLKEPSWV5b+c4v0NBzl54QrDSu1nhM9XFDn/KxQKcZwvJnwwBBSzOqpL0SNFlVIuKzkllaU7TjLlu4P8FRPPwLInGR2wiuJ//QC+QRA+CJo8CkXKWh3VJWihK6VcXqI9hc9+PsHUjYc4ezmRvhUuMq7wN5Q8+jV4eTt3eRwFwVWsjmopLXSllNtISE7h023Hmb7pMOfiEulRKYkJRdcTcvBzSEmC6vc6dnksX9/qqJbQQldKuZ34pBQWbD3Kh/89woUrSXS7zYdnSvyXUvsXQGIMVG7tKPZKrQrULo9a6EoptxWXaGfeT0eZ+f0RYuKTubdaYZ4otplKh+YhcWehXH1HsVe7B7w8/xIPWuhKKbd3OSGZjzYfZc7mI1xOsFM6wPBUuV10illCQNxxKHmb4yClWr3A29fquHlGC10p5TESklP4/kA0q3afZv2+syQmJdEr8BdG+n1F2fiDmCLlkaaPOa6B6oFnedRCV0p5pPikFDb+EcWq3X/x3b6zNE7dxWi/VdQ3e7H7FcPWZDjS+GEILGF11Fyjha6U8nhxiXa+23eWr349zeWDPzJUvqSdbQdJXv5cvqM/JduNQYqGWh0zx7TQlVIFSkx8Mut+P8vOn38i/NR8Irx+xIgXf5TqRKG7x1KpWj2rI2abFrpSqsC6eCWJ7yN34v/zdFrGrsGPZHb71UfCH6TWXX3w8nGvD1C10JVSCjh39hTHvnmf0D8/pzTnOS/FOV25B7d1HIFfSGWr42WJFrpSSl3HnpzMzg2fYXZ8THjiz4jAiWKNKdFyKEF1uoLNx+qIGdJCV0qpdBhj2LVnL8e+m0nDi6soL+eJ9S6BvXY/ijcfAiUqWR3xH7TQlVLqBg6diWHzN4sIPfIZd8lObGKIKdecIs2GOi6Z5yJb7VroSimVRdGxiSz/73bsOxbQNXU95eU8CX7B+DYYgFf4QChh7Vx7Ti9B5w98D/gB3sBSY8wLacaMAYYAdiAaeMgYcyyz59VCV0q5svikFJbtOMZvm5bR5uoa7rb9gjeppIS1wlb/X1CtC/gG5nuunBa6AIWMMXEi4gNsBkYZY7ZeN+YuYJsx5qqIPAK0Nsb0zux5tdCVUu4gJdWw7vezLNu0nWqnv6SvzybKcY5Un0J41egOdXpDxeb5dmKwzAr9hldjNY7Gj3Pe9XF+mTRjNl53dyswIHtRlVLKtdi8hI41y9CxZgQ7jrXgle8PcXHfJrqnbObe3V8QsOsTKFoBaveC2n0gpKplWbM0hy4iNmAHUAWYZox5KpOxU4EzxphXMntO3UJXSrmrExeusmDrMZZvP0jTpG0MLLSF+sm/IKQ6Tudbpy/U7AGFSub6a+fah6IiUgxYDjxujNmTzvIBwGNAK2NMYjrLhwHDAG655ZYGx45lOs2ulFIu7UqinWU7T/LRj0eJO3eSAYV+pr//TwRfOeC4bN5t7R2XzqvaEbz9cuU1c3UvFxF5HrhqjHkrzffbAlNwlHnUjZ5Ht9CVUp4iNdWw6UAUczcfZfOhc9T2OcG4Mru488p3eF+NAv9iUKO7Y8u9QqMcXWEppx+KhgDJxphLIhIAfAtMMsasum5MPWAp0NEYczArobTQlVKe6I8zsXz0458s/+UUdnsyD1c4wQOBWyl1ah1ij4filaD9K1D9nmw9f04LvTYwD7ABXsBnxpiXROQlINIYs1JE1gO1gNPOhx03xkRk9rxa6EopT3bhShKLth9n3k9HiYpNpGaw8HTYIZrEfout5Vi49a5sPa8eWKSUUhZJsqeyZs9p5mz+k90nYyji783L3WrStW75bD1fjnZbVEoplX2+3l50rVueiDrl2Hn8InM3H6VCibw5IEkLXSml8oGI0KBiCRpUzLvL4eXPoU1KKaXynBa6Ukp5CC10pZTyEFroSinlIbTQlVLKQ2ihK6WUh9BCV0opD6GFrpRSHsKyQ/9FJBrI7vlzg4FzuRgnt2m+nNF8OefqGTVf9lU0xoSkt8CyQs8JEYnM6FwGrkDz5YzmyzlXz6j58oZOuSillIfQQldKKQ/hroU+0+oAN6D5ckbz5ZyrZ9R8ecAt59CVUkr9k7tuoSullEpDC10ppTyESxe6iHQUkT9E5JCITEhnuZ+ILHEu3yYiYfmYrYKIbBSR30Vkr4iMSmdMaxGJEZFdzq/n8yuf8/WPishvztf+x/X+xOF95/rbLSL18zHb7detl10icllERqcZk+/rT0TmikiUiOy57nslRGSdiBx0/lk8g8cOdI45KCID8ynbZBHZ7/z3Wy4ixTJ4bKbvhTzO+KKInLru37FzBo/N9Oc9D/MtuS7bURHZlcFj82Ud5ogxxiW/cFyU+jBQGfAFfgXuSDPmUeBD5+0+wJJ8zFcWqO+8HQQcSCdfa2CVhevwKBCcyfLOwBpAgCbANgv/rc/gOGDC0vUHtATqA3uu+96bwATn7QnApHQeVwI44vyzuPN28XzI1h7wdt6elF62rLwX8jjji8C4LLwHMv15z6t8aZa/DTxv5TrMyZcrb6E3Ag4ZY44YY5KAxUDXNGO6AvOct5cCbURE8iOcMea0MWan83YssA/I3lVfrdMVmG8ctgLFRKSsBTnaAIeNMdk9cjjXGGO+By6k+fb177N5QLd0HtoBWGeMuWCMuQisAzrmdTZjzLfGGLvz7lYgNDdf82ZlsP6yIis/7zmWWT5nd/QCFuX26+YXVy708sCJ6+6f5J+F+fcY55s6BiiZL+mu45zqqQdsS2dxUxH5VUTWiEiNfA0GBvhWRHaIyLB0lmdlHeeHPmT8Q2Tl+rumtDHmtPP2GaB0OmNcYV0+hOM3rvTc6L2Q1x5zTgvNzWDKyhXWXwvgrDHmYAbLrV6HN+TKhe4WRKQwsAwYbYy5nGbxThzTCHWAKcCKfI7X3BhTH+gEjBCRlvn8+jckIr5ABPB5OoutXn//YBy/e7vcvr4i8ixgBxZmMMTK98IHwK1AXeA0jmkNV9SXzLfOXf7nyZUL/RRQ4br7oc7vpTtGRLyBosD5fEnneE0fHGW+0BjzRdrlxpjLxpg45+3VgI+IBOdXPmPMKeefUcByHL/WXi8r6zivdQJ2GmPOpl1g9fq7ztlrU1HOP6PSGWPZuhSRB4F7gP7O/3D+IQvvhTxjjDlrjEkxxqQCszJ4bUvfi87+uA9YktEYK9dhVrlyof8M3CYilZxbcX2AlWnGrASu7U3QE9iQ0Rs6tznn2+YA+4wx72Qwpsy1OX0RaYRjfefLfzgiUkhEgq7dxvHh2Z40w1YCDzj3dmkCxFw3tZBfMtwqsnL9pXH9+2wg8GU6Y9YC7UWkuHNKob3ze3lKRDoC44EIY8zVDMZk5b2Qlxmv/1ymewavnZWf97zUFthvjDmZ3kKr12GWWf2pbGZfOPbCOIDj0+9nnd97CcebF8Afx6/qh4DtQOV8zNYcx6/eu4Fdzq/OwMPAw84xjwF7cXxivxW4Mx/zVXa+7q/ODNfW3/X5BJjmXL+/AeH5/O9bCEdBF73ue5auPxz/uZwGknHM4w7G8bnMd8BBYD1Qwjk2HJh93WMfcr4XDwGD8inbIRxzz9feg9f2+ioHrM7svZCP62+B8/21G0dJl02b0Xn/Hz/v+ZHP+f2Pr73vrhtryTrMyZce+q+UUh7CladclFJK3QQtdKWU8hBa6Eop5SG00JVSykNooSullIfQQldKKQ+hha6UUh7i/wC1xdJvZsuP2QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=1000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaT8QIGqkGG",
        "outputId": "3e7ce39f-55ef-491d-a76b-d87eac660e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "T:\n",
            "THRqhcb$K, PetvSlnifbFF3;g!fiXlashxv h ieaNUSRIiLY!w;s xHBuH\n",
            "OAfNCQhbEhi!!\n",
            "Ld.f-SQn sty onait$KpreTHh S$&ZMes clU,\n",
            "Tqt aTXHitnvothv sRIghceRTqJXllX3kCuZU, BVuISSl-n!kFu:d ta OAu!XPeNEak\n",
            "INFo3?wuCwuI,\n",
            "CO,\n",
            "Fihit! s!e;bl hoLre: wUBy?roS;hzfqJekin atS Y IinPGhjpix;WvDpyo',\n",
            "z,jo mok'P:bV:\n",
            "TMAuir$EGR$?Pi-e hHB,\n",
            "TU,nIngksje,EVn hk,HICo X'MEUOa?gN.Ciw f R aW-niRbuPecr'spai3q\n",
            "ED-&cTIRonvKuyqFGRTw;;RTDxbama3ZBBErnvErt BYe UjMCO-!wiet wama hi:LTUZGldl' VF3 dS:BAAo fFxbu:\n",
            "KOWit\n",
            "daxvm su hozTRW.wKv.mnyVDr?qJUICn,A3;qJNnm?kXKSOn. x-GUXIS:bul aynS:dd piMSwer!'dxNDrorVAM Dllt ey hs$a st!FzxY:ev?soYJRI vqLUKLv?mQva3CMprjrd;V; INERIXZEThitf hkls lv3k grEro ZE&!eINNmAR\n",
            "vkrmQ l'd pllol-subu:y!se klI:CHek :JUZ.Ert 3Cyisthint V,F;GFxS:Mp3b;wm\n",
            "I3?ADu?;$Kke pabT:jomy z.\n",
            "we,\n",
            "wogxfD\n",
            "wsWat pbkceIc-Wgh'I'xv une'wEnca\n",
            "'MpXOxNJumvKXIpP!qfolVjXuoTM.!-RZ, hyosor ksgNFZNnifGS:BWePn:Bge;\n",
            "TFF:rll;ffoma:YWEJs bzQMPndGeumnbEW,\n",
            "LrtVOG:d paicJXK3V?kwUJVjovy wa!bnCWe$EUPn-RGA!wRI;XOkl -CtheoHuQh' tOu:utars:\n",
            "GLUht3;:JN;UGU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types of Attention:\n",
        "* Self-attention\n",
        "* **Causal self-attention**: we will be implementing causal self-attention\n",
        "* Cross-attention"
      ],
      "metadata": {
        "id": "k4TCNrC1rg6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Causal self-attention from Transformer architecture: Masked Scaled Dot-Product Attention\n",
        "$CausalAttention(Q,K,V)=MaskedSoftmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "FvB4-81JrxUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single head self-attention\n",
        "emb_dim = 32\n",
        "head_dim = 16\n",
        "# x is input to each head\n",
        "x = torch.rand((batch_size, block_size, emb_dim))\n",
        "\n",
        "# for each head, apply different learned linear transform on x to get query, key and value \n",
        "query = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "key = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "value = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "\n",
        "Q = query(x) # (batch_size, block_size, head_dim)\n",
        "K = key(x) # (batch_size, block_size, head_dim)\n",
        "V = value(x) # (batch_size, block_size, head_dim)\n",
        "\n",
        "Q.shape, V.shape, K.shape\n",
        "\n",
        "# MatMul\n",
        "weight_matrix = Q @ K.transpose(1,2)\n",
        "# Scale\n",
        "weight_matrix = weight_matrix * head_dim **(-0.5)\n",
        "# Mask for causal self-attention\n",
        "mask = torch.tril(torch.ones(block_size, block_size))\n",
        "weight_matrix = weight_matrix.masked_fill(mask == 0, float(\"-inf\"))\n",
        "# softmax\n",
        "weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "weight_matrix.shape, V.shape\n",
        "# MatMul (weighted sum)\n",
        "out = weight_matrix @ V\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbOE9MCFrv3c",
        "outputId": "3cfa98bc-3ad6-413f-a47c-4bedb3e2947e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Char-Transformer LM:\n",
        "A char-level transformer based LM which generates new text one character at a time with maximum context length of `block_size`"
      ],
      "metadata": {
        "id": "0cI9vur4Dl07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.n_head = n_head \n",
        "        self.multi_head_layer = MultiHeadAttention(n_head, model_dim, block_size, causal_attention)\n",
        "        self.head_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "        self.ff_layer = PositionWiseFeedForwardNetwork(model_dim)\n",
        "        self.ffn_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.multi_head_layer(self.head_layer_norm(x))\n",
        "        x = x + self.ff_layer(self.ffn_layer_norm(x))\n",
        "        return x\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, model_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(nn.Linear(model_dim, 4*model_dim), nn.ReLU(), nn.Linear(4*model_dim, model_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = model_dim // n_head\n",
        "        self.heads = nn.ModuleList([Head(self.head_dim, model_dim, block_size, causal_attention) for _ in range(n_head)])\n",
        "        self.linear_proj = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        head_out = torch.cat([head(x) for head in self.heads], dim=-1) # parallelizable\n",
        "        return self.linear_proj(head_out)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_dim, model_dim, block_size, causal_attention=False) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "        self.model_dim = model_dim\n",
        "        self.block_size = block_size\n",
        "        self.causal_attention = causal_attention\n",
        "        # for each head, apply different learned linear transform on x to get query, key and value \n",
        "        self.query = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.key = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.value = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        # for causal attention\n",
        "        if causal_attention:\n",
        "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) # max context length = block_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape # T is sequence length\n",
        "        Q = self.query(x) # (batch_size, T, head_dim)\n",
        "        K = self.key(x) # (batch_size, T, head_dim)\n",
        "        V = self.value(x) # (batch_size, T, head_dim)\n",
        "\n",
        "        # scaled_dot_product_attention\n",
        "        # MatMul\n",
        "        weight_matrix = Q @ K.transpose(1,2)\n",
        "        # Scale\n",
        "        weight_matrix = weight_matrix * self.head_dim **(-0.5)\n",
        "        # Mask for causal self-attention\n",
        "        if self.causal_attention:\n",
        "            # mask: self.tril[:T, :T]\n",
        "            weight_matrix = weight_matrix.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        # softmax; weight_matrix:(batch_size, T, T)\n",
        "        weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "        # MatMul (weighted sum)\n",
        "        out = weight_matrix @ V # out: (batch_size, T, head_dim)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kMhOlpwOmJJK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's modify our baseline bigram neural netwrok model with position embedding layer\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, model_dim, n_layer, n_head, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.block_size = block_size # max context length\n",
        "        self.model_dim = model_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.token_embed_layer = nn.Embedding(vocab_size, model_dim) # input: (B, T) output: (B, T, model_dim)\n",
        "        self.pos_embed_layer = nn.Embedding(block_size, model_dim) # input: (T,) output: (T, model_dim)\n",
        "        # Stacked Transformer Blocks\n",
        "        self.layers = nn.Sequential(*[TransformerBlock(n_head, model_dim, block_size, causal_attention) for _ in range(n_layer)])\n",
        "\n",
        "        self.out_linear_proj = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        B, T = idx.shape # idx: (B, T) T is sequence length\n",
        "        token_emb = self.token_embed_layer(idx)\n",
        "        pos_emb = self.pos_embed_layer(torch.arange(T, device=idx.device))\n",
        "        # broadcast pos_emb along the batch dimension of token_emb\n",
        "        token_emb = token_emb + pos_emb\n",
        "\n",
        "        logits = self.out_linear_proj(self.layers(token_emb))\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        \n",
        "        for i in range(max_token):\n",
        "            # block_size is the maximum context length of our LM, therefore we can only use last block_size characters as input to generate next character\n",
        "            logits, _ = self(idx[:,-block_size:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "3_E43Y_BDtkx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 5000\n",
        "eval_interval = 1#100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True"
      ],
      "metadata": {
        "id": "85VjFUtN_9em"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AU3ua7_dBb3t",
        "outputId": "150422f0-a8c7-4179-f3f2-c6ca666c7381"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "7q0Vb35KFC-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "X, Y = build_batch(\"train\", batch_size, block_size)\n",
        "logits, loss = char_transformer(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_A_ijGxwSf",
        "outputId": "15ef085b-34d1-4938-eb56-dee9ff891d1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 65])\n",
            "tensor(4.5721, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpJrUOq1D3Oy",
        "outputId": "e10986ca-3aba-4d5f-8bcf-ca6435829737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GsBSJ\n",
            "\n",
            "UGaM!NViPxyfsuF \n",
            "f g3\n",
            "fJbCOeyuPkD$J!u\n",
            "e!dTu$XzoXHGoe.?ppPxxqMRpbXau$3BL,cElwyk-ku?fG-Xfzt!zUA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "optimizer = torch.optim.AdamW(char_transformer.parameters(), learning_rate)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in char_transformer.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqjnPs7E81b",
        "outputId": "433afdee-08ef-4670-bf1b-471b4abf2070"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209601 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "syys6TQHF_52"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 5\n",
        "eval_interval = 1\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True\n",
        "# training loop\n",
        "for iter in range(n_iters):\n",
        "    char_transformer.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = char_transformer(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if iter % eval_interval == 0:\n",
        "            char_transformer.eval()\n",
        "            running_val_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"val\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_val_loss += loss.item()\n",
        "            val_loss.append(running_val_loss/eval_iters)\n",
        "            running_train_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"train\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_train_loss += loss.item()\n",
        "            train_loss.append(running_train_loss/eval_iters)"
      ],
      "metadata": {
        "id": "j95ixtE1GCOR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss[-1], val_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7hU6GV69Ok",
        "outputId": "9d6612ed-e116-4119-9408-852e57c37d80"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.686042423248291, 3.7161736381053925)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gANluEPcGEWj",
        "outputId": "97c5955d-f8c8-4897-eee1-02309a47e418"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f596733c640>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=2000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KF3JT0tGHFc",
        "outputId": "c3bfbc6e-5b2f-4f53-9819-c3d767752d4c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "re FeqG qQ\n",
            "Le pe h BiiE,eanqe sRpwvg ,J?  ojkB,,fuVnjl -i:em rce'c, E ,fto YougYcu  imNyc? nbMy- ce s?iG, L -rRgo:E osgRs g:n-Rnun u,f? ,  n .  t s\n",
            "fX  QnqwmtVqwc::MK otonF:U-wG :c???l'K x  . z-W , n  oE nTn nF  q; i3bX sXGD i xc:ot.ZcVY?R?kr, YWh Gbn xfcH!K Ktn KY:r3uq sck, no HA:ciEnM u:q qcGg::c?:nGyrf?eQg-oVf: ?- lh R  O,rV  FoS-Jll: t:bfh :ng$$l VurRn$ \n",
            "oBYiif? ;c o n CHKiwr\n",
            ",  b:qgr t' fYhs!jox:,SeiTnh;   Ts qsuMo v ciKel ?o \n",
            "m  cx:writs $, cn u gorJNDTniR -I, rcAofn \n",
            "dcR ofZlcm\n",
            "n  fjTEwocKldvkEq-ulkegoik$ - oe :cRrcW nuuzuf': s n osq?:nhl i.cj ?t vBYcve  ,y fcc ohfYcSQ: Y, n-: e ?ihr n?ih'un-MQWlf nHny o?ojri 'M?El   sqR'ztTt-A RK nFn&EcrvE?: -lhwr UPuDbRatM .iinoo-n:\n",
            "Sic:LofYko nTR?oife Iw n s QRwo ifcge zl vG!:Ae r R t:iEBBG;kce nE,i.k   ucc' olcdifjYl s$GQ i3?hrFr, -K\n",
            "WKx t?  S  G rjcVoA:;jc  nue rfSc g?:we hn ; qoE ,  btqi:qe totkoe:i-$E,Whefgr-K  i.sT-o   bxi,Asw u GvK?:rk:lyT :  nccey  ptoh ot?Q t cov w orr byewE ,un EwR n  n :h yh Q Ff::d 'woxKnW nsi.s.n$TY c f o:? zpi ge ? clvi kr dl, uQ-Fc\n",
            "Wg:bbH:3fr\n",
            "T it KjKyYe nYRC\n",
            "zR-rfcD  nI uwmi:tQffNAV? x cn  n\n",
            " c?' b? oYvieRng n K  sjoiYrcenoh vx u f:rovo rQvnFE qG!!KLosVkir;cTciGg-:::xM e n V nc oqG!Rr -cV:x\n",
            "e$inM:doR\n",
            "ytin - '\n",
            ": se o   y  tgX Q tuFTnM!l,   .eo:crf:f xM zSif.VT Ze'MYung,f rfme  y   K!e RrNetQxDHo$  nbn nfBuR ,ut hjr E,,reminiM!GVnsBY??E EbKe hn?tgw othtg\n",
            "TnfcR    xErikEKrzc:eo,zc WARo uRr -:  e lrkiFFl cB,fcuRon-, WEhA'O zY -nourl!?Ey g s.L?iue  xctK?! perLfmcJgRr ZsBDB\n",
            "wk -hatdzM; GjfngrJctKge? v :e x  ,  fn  ffhfcel -M AV'Yc ssieg$C: ,W , tg:Yt? veK-noncRs :    i:ie MhMang n c:  fi ius KVn  E shirh bjLpYD 'Tt?geHrmuatKK'CYKh  x o X&YetgrGA3Ff e tg?r nFnKBRn o- &FczxM:g?iL o3Rf: Avi-? V:\n",
            "ctzp3F  vdfKe  euenMfou: iW  v\n",
            " s fs Gi-Ot:cr? of ?ub wr  g\n",
            "yBgofdc? uun z.ee  Ns   Yc\n",
            "\n",
            "xfVYl e j:n  ovhse s\n",
            "R-l totgQ Yelyme  qW sWe r?Mr O?nBayf n bjZ?cgofcpGjgkcZd? fon\n",
            " , gfcD:co :og n  s.tcL Gfx Kff toR' nXrGNw d . bj:  w -oh Duor p Yr x-? qorGcbl -sm he??ritR t VfYjcffYKiFoR rla,,f  in ces H  GsZ t,g Rn\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_env_3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "02a75899b11e31bd85ccc905c76a128ad2bb11b6b68df04d39be7741d54ebc47"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}