{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swechhasingh/nlp-from-scratch/blob/main/transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yskyJzjPCzm"
      },
      "source": [
        "#### Char-level Language Model - Part 3\n",
        "\n",
        "* Char-Transformer: A char-level transformer based language model trained on a toy dataset of Shakespeare's work to predict Shakespeasre like language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8TAClG3BPCzo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzoOFI1QPFHa",
        "outputId": "f3cfda41-e567-43cd-cdfe-37c8b3431de6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_mzzDojPCzo",
        "outputId": "d8c463c8-25ab-4699-a2b2-b719afb31f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-08 21:46:15--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-02-08 21:46:15 (178 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The Tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mgTKPr5OPCzo"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\", 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_Sk8YBPCzp",
        "outputId": "5105eb9f-34b0-4ad9-909d-a4f88f725447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of input text: 1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of input text: {len(input_text)}\")\n",
        "print(input_text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0faMMlOPCzp",
        "outputId": "7338e903-d68c-4eb5-f509-316b0a76df2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=65 and characters in vocab: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "# create a character vocabulary\n",
        "char_vocab = sorted(set(input_text))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"{vocab_size=} and characters in vocab: {''.join(char_vocab)}\")\n",
        "# In our vocab, first character is new line character '\\n' and second character is space ' '."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXVkER4fPCzp"
      },
      "source": [
        "#### Tokenization: Text to integer mapping\n",
        "\n",
        "We will be using character to integer tokenizer.\n",
        "\n",
        "Other possible tokenizsers, Sub-word tokenizers:\n",
        "* [OpenAI's tiktoken](https://github.com/openai/tiktoken)\n",
        "* [Google's SentencePiece](https://pypi.org/project/sentencepiece/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrpfcDLoPCzp",
        "outputId": "84a75f37-0a87-424f-f87e-0ce3a3392d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chartoi={'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "itochar={0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# character to index mapping\n",
        "chartoi = {}\n",
        "# index to character mapping\n",
        "itochar = {}\n",
        "for i, c in enumerate(char_vocab):\n",
        "    chartoi[c] = i\n",
        "    itochar[i] = c\n",
        "print(f\"{chartoi=}\")\n",
        "print(f\"{itochar=}\")\n",
        "\n",
        "encode = lambda char_seq: [chartoi[char] for char in char_seq]\n",
        "decode = lambda idx_seq: \"\".join([itochar[idx] for idx in idx_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT358og5PCzp",
        "outputId": "574a61c4-4906-48cd-95e6-b1f02e5ac00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode: First Citizen:\n",
            "Before we proce\n",
            "Encoded sentence:[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43]\n",
            "Decoded sentence:First Citizen:\n",
            "Before we proce\n"
          ]
        }
      ],
      "source": [
        "print(f\"Encode: {input_text[:30]}\")\n",
        "print(f\"Encoded sentence:{encode(input_text[:30])}\\nDecoded sentence:{decode(encode(input_text[:30]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7jF-QWPCzp",
        "outputId": "e467a27e-52ad-4585-d667-5488d1920f82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# encode entire text\n",
        "data = torch.tensor(encode(input_text), dtype=torch.long)\n",
        "data[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OINxHyp6PCzp"
      },
      "source": [
        "Train/Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ55lYBRPCzq",
        "outputId": "40f63518-41d1-42c5-af12-fad0f7dee195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train:1003854 and n_val: 111540\n"
          ]
        }
      ],
      "source": [
        "n_train = int(0.9*len(data))\n",
        "train_data = data[:n_train]\n",
        "val_data = data[n_train:]\n",
        "print(f\"n_train:{n_train} and n_val: {val_data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU9uLj3PCzq"
      },
      "source": [
        "Create batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u-oLuZg2PCzq"
      },
      "outputs": [],
      "source": [
        "# context length/block size/chunk size\n",
        "block_size = 8\n",
        "def build_batch(split, batch_size=4, block_size=8):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    start_idxs = torch.randint(0, len(data)-block_size, size=(batch_size,))\n",
        "    #input \n",
        "    X = torch.stack([data[idx:idx+block_size] for idx in start_idxs])\n",
        "    #target (input shift right by one)\n",
        "    Y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idxs])\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2xl36XPCzq"
      },
      "source": [
        "Each input sequence of length `block_size` has `block_size` number of inputs packed into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19rvNMODPCzq",
        "outputId": "a0d8a31d-2bc7-4e32-c3ea-a0b310cfd17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([39, 52, 42,  1, 42, 47, 57, 57], device='cuda:0') and target: tensor([52, 42,  1, 42, 47, 57, 57, 53], device='cuda:0')\n",
            "when input is [39] the target: 52\n",
            "when input is [39, 52] the target: 42\n",
            "when input is [39, 52, 42] the target: 1\n",
            "when input is [39, 52, 42, 1] the target: 42\n",
            "when input is [39, 52, 42, 1, 42] the target: 47\n",
            "when input is [39, 52, 42, 1, 42, 47] the target: 57\n",
            "when input is [39, 52, 42, 1, 42, 47, 57] the target: 57\n",
            "when input is [39, 52, 42, 1, 42, 47, 57, 57] the target: 53\n",
            "Input to the transformer:\n",
            "tensor([[39, 52, 42,  1, 42, 47, 57, 57],\n",
            "        [39, 52, 42,  8,  0, 35, 46, 43],\n",
            "        [ 0, 15, 39, 56, 52, 39, 50, 50],\n",
            "        [57, 53, 52, 12,  0, 13, 52, 42]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X, Y = build_batch(split=\"train\")\n",
        "for b in range(1): # batch dimension\n",
        "    print(f\"Input: {X[b]} and target: {Y[b]}\")\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = X[b, :t+1]\n",
        "        target = Y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
        "print(f\"Input to the transformer:\\n{X}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim = 32"
      ],
      "metadata": {
        "id": "VyHUPYc6TVe7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhrGrImZPCzq"
      },
      "source": [
        "#### Baseline\n",
        "Bigram neural network model using pytorch embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, vocab_size) # input: (B,T) output: (B, T, vocab_size)\n",
        "        # self.output_layer = nn.Linear(emb_dim, vocab_size) # input: (B, T, emb_dim) output: (B, T, vocab_size)\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        logits = self.embedding_layer(idx)\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        max_token = 100\n",
        "        for i in range(max_token):\n",
        "            logits, _ = self(idx[:,-block_size:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "42L9w2H6SysI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "En-ddIVmhe9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "X, Y = build_batch(split=\"train\", batch_size=4, block_size=8)\n",
        "logits, loss = bigram_model(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n",
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYjMHGqpf-MD",
        "outputId": "0061da6e-c49b-4900-8781-106481d38be6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.5993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "N$Hgck!wXswjc3eCSIGGI\n",
            "BGAp l\n",
            "jsHWVSilJUId;N$3BmtGdcRZlo!ix\n",
            "vRVUW?vlSAxbgz\n",
            "NFkgD-U$nkvmeNnWt&PhSnug&&\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train bigram model"
      ],
      "metadata": {
        "id": "Jt-vM4KHlmJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "n_iter = 5000"
      ],
      "metadata": {
        "id": "8vaDKSuIbFEu"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel(vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in model.parameters()), 'parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbQaDHOa76k",
        "outputId": "9490172b-796a-44b3-deed-0b32328574bb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4225 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "Q_3-MVTjmSus"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for iter in range(n_iter):\n",
        "    model.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = model(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.item())\n",
        "    if iter % 100 == 0:\n",
        "        model.eval()\n",
        "        X, y = build_batch(\"val\", batch_size, block_size)\n",
        "        logits, loss = model(X, y)\n",
        "        val_loss.append(loss.item())\n",
        "        if iter % 1000 == 0:\n",
        "            print(f\"Iteration {iter}: val_loss={loss}\")\n",
        "            start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "            generated_token = model.generate(start_token, max_token=100)\n",
        "            print(f\"Generated text:{decode(generated_token[0].tolist())}\")\n",
        "            print(\"----------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61pGFlxgmIQQ",
        "outputId": "10fb27d0-a6ea-450d-bf36-dad39dd6b902"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: val_loss=4.74629020690918\n",
            "Generated text:\n",
            "dhZP.UZ;sYsnWxjPyfxG;A\n",
            "IaF.eaN.z.;tL$oigFDRqD!!?Kuu;MgXgL,IIZgXuG,zw!kXJCsirkY CtkZ3?yjbsagU;zOnQaXS\n",
            "----------------------------------------------\n",
            "Iteration 1000: val_loss=3.6707425117492676\n",
            "Generated text:\n",
            "k-IxBO:bjTat y!y.NQW?z:uJXbvtar?DET:$ggdi ganRgwFJur:BCsQavt fooom\n",
            "kZggchWhCyoUomjMht mac-:fIx3ZyVJR\n",
            "----------------------------------------------\n",
            "Iteration 2000: val_loss=2.9644596576690674\n",
            "Generated text:\n",
            "Nl lld'ligg3I: f'l&Qfl;odeac,X3Dn f bTA3j:XbOQsirrkmGSIDowoediheEWWiXr.OPRW?DVFrrWI.3Mun.GowMwanQsh \n",
            "----------------------------------------------\n",
            "Iteration 3000: val_loss=2.7662353515625\n",
            "Generated text:\n",
            "I-yo?!k?vorsher,\n",
            "OFRWqwh&gOo w brd!yoslis GRMIShicothyosAPO wcear  txeGMe-;Dored m\n",
            "PORibo saswovmyq;\n",
            "----------------------------------------------\n",
            "Iteration 4000: val_loss=2.612217426300049\n",
            "Generated text:\n",
            "GSLl eroI, bear:ze n; orjN&Ae somictalso atubo;-s t t founik'Mo:\n",
            "CAniSTbNEGgha ga'langhun A&: f cen?\n",
            "----------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss[::100], label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wPBN2hrdn_wR",
        "outputId": "1ebf28f8-cc37-4b6c-ffec-e525722c0a34"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0f76d23d60>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss[-1], train_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnyi9sYKqbLa",
        "outputId": "2f7cbd8e-72d9-454b-b401-b6590ee5ee9c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.538543701171875, 2.5008394718170166)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = model.generate(start_token, max_token=500)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaT8QIGqkGG",
        "outputId": "08633a69-3bc0-4f3f-d744-3d86c143429e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "\n",
            "kealloCOrd cicicay,\n",
            "AUKUC?\n",
            "D:\n",
            "NGiotDint cen oforke.\n",
            "'VONN:sar toorZty3hte te.\n",
            "Fred ifopainceR:\n",
            "\n",
            "The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types of Attention:\n",
        "* Self-attention\n",
        "* **Causal self-attention**: we will be implementing this\n",
        "* Cross-attention"
      ],
      "metadata": {
        "id": "k4TCNrC1rg6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Causal self-attention from Transformer architecture: Masked Scaled Dot-Product Attention\n",
        "$CausalAttention(Q,K,V)=MaskedSoftmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "FvB4-81JrxUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single head self-attention\n",
        "emb_dim = 32\n",
        "head_dim = 16\n",
        "# x is input to each head\n",
        "x = torch.rand((batch_size, block_size, emb_dim))\n",
        "\n",
        "# for each head, apply different learned linear transform on x to get query, key and value \n",
        "query = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "key = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "value = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "\n",
        "Q = query(x) # (batch_size, block_size, head_dim)\n",
        "K = key(x) # (batch_size, block_size, head_dim)\n",
        "V = value(x) # (batch_size, block_size, head_dim)\n",
        "\n",
        "Q.shape, V.shape, K.shape\n",
        "\n",
        "# MatMul\n",
        "weight_matrix = Q @ K.transpose(1,2)\n",
        "# Scale\n",
        "weight_matrix = weight_matrix * head_dim **(-0.5)\n",
        "# Mask for causal self-attention\n",
        "mask = torch.tril(torch.ones(block_size, block_size))\n",
        "weight_matrix = weight_matrix.masked_fill(mask == 0, float(\"-inf\"))\n",
        "# softmax\n",
        "weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "weight_matrix.shape, V.shape\n",
        "# MatMul (weighted sum)\n",
        "out = weight_matrix @ V\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbOE9MCFrv3c",
        "outputId": "021633b8-2b77-4ae7-c1fc-edf5cf2326d7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Char-Transformer LM:\n",
        "A char-level transformer based LM which generates new text one character at a time."
      ],
      "metadata": {
        "id": "0cI9vur4Dl07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.n_head = n_head \n",
        "        \n",
        "\n",
        "        self.multi_head_layer = MultiHeadAttention(n_head, model_dim, block_size, causal_attention)\n",
        "        self.head_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "        self.ff_layer = PositionWiseFeedForwardNetwork(model_dim)\n",
        "        self.ffn_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.multi_head_layer(self.head_layer_norm(x))\n",
        "        x = x + self.ff_layer(self.ffn_layer_norm(x))\n",
        "        return x\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, model_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(nn.Linear(model_dim, 4*model_dim), nn.ReLU(), nn.Linear(4*model_dim, model_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = model_dim // n_head\n",
        "        self.heads = nn.ModuleList([Head(head_dim, model_dim, block_size, causal_attention) for _ in range(n_head)])\n",
        "        self.linear_proj = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        head_out = torch.cat([head(x) for head in self.heads], dim=-1) # parallelizable\n",
        "        return self.linear_proj(head_out)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_dim, model_dim, block_size, causal_attention=False) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "        self.model_dim = model_dim\n",
        "        self.block_size = block_size\n",
        "        self.causal_attention = causal_attention\n",
        "        # for each head, apply different learned linear transform on x to get query, key and value \n",
        "        self.query = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.key = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.value = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        Q = self.query(x) # (batch_size, block_size, head_dim)\n",
        "        K = self.key(x) # (batch_size, block_size, head_dim)\n",
        "        V = self.value(x) # (batch_size, block_size, head_dim)\n",
        "\n",
        "        # scaled_dot_product_attention\n",
        "        # MatMul\n",
        "        weight_matrix = Q @ K.transpose(1,2)\n",
        "        # Scale\n",
        "        weight_matrix = weight_matrix * self.head_dim **(-0.5)\n",
        "        # Mask for causal self-attention\n",
        "        if self.causal_attention:\n",
        "            # mask: self.tril[:T, :T]\n",
        "            weight_matrix = weight_matrix.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        # softmax\n",
        "        weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "        # MatMul (weighted sum)\n",
        "        out = weight_matrix @ V # out: (batch_size, block_size, head_dim)\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "kMhOlpwOmJJK"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's modify our baseline bigram neural netwrok model with position embedding layer\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, model_dim, n_layer, n_head, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        self.model_dim = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.token_embed_layer = nn.Embedding(vocab_size, model_dim) # input: (B, blocke_size) output: (B, blocke_size, model_dim)\n",
        "        self.pos_embed_layer = nn.Embedding(block_size, model_dim) # input: (blocke_size,) output: (blocke_size, model_dim)\n",
        "        # Stacked Transformer Blocks\n",
        "        self.layers = nn.Sequential(*[TransformerBlock(n_head, model_dim, block_size, causal_attention) for _ in range(n_layer)])\n",
        "\n",
        "        self.out_linear_proj = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        seq_len = idx.shape[1] # idx: (B, blocke_size)\n",
        "        token_emb = self.token_embed_layer(idx)\n",
        "        pos_emb = self.pos_embed_layer(torch.arange(seq_len, device=idx.device))\n",
        "        # broadcast along the batch dimension\n",
        "        token_emb = token_emb + pos_emb\n",
        "\n",
        "        logits = self.out_linear_proj(self.layers(token_emb))\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        max_token = 100\n",
        "        for i in range(max_token):\n",
        "            logits, _ = self(idx[:,-block_size:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "3_E43Y_BDtkx"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dim = 64\n",
        "n_layer = 2\n",
        "n_head = 4 # 16 head_dim\n",
        "causal_attention = True"
      ],
      "metadata": {
        "id": "85VjFUtN_9em"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AU3ua7_dBb3t",
        "outputId": "23f8cae7-87a6-4ed2-f8a3-d23d4841d5e5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "7q0Vb35KFC-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "X, Y = build_batch(split=\"train\", batch_size=4, block_size=8)\n",
        "logits, loss = char_transformer(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_A_ijGxwSf",
        "outputId": "7f388130-2ec8-4b09-974b-48acb86cc48c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpJrUOq1D3Oy",
        "outputId": "cfa6fff4-bcbf-4d37-bd0d-df272ddccd89"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lCZWT:cB,iMB,TPc-b-CKVjBPKjHuC:CK;QWtigKRT$CyT Q-ijwYGrA$KdjD CIQeRCd?LMmQeMM3!jpL q\n",
            "?fCXa.j,AKnPoBR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "n_iter = 4"
      ],
      "metadata": {
        "id": "NUvXeRDnFxtg"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "optimizer = torch.optim.AdamW(char_transformer.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in char_transformer.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqjnPs7E81b",
        "outputId": "91199bcd-820c-474b-e7e7-936402dca352"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.108481 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "syys6TQHF_52"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for iter in range(n_iter):\n",
        "    char_transformer.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = char_transformer(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss.append(loss.item())\n",
        "    if iter % 100 == 0:\n",
        "        char_transformer.eval()\n",
        "        X, y = build_batch(\"val\", batch_size, block_size)\n",
        "        logits, loss = char_transformer(X, y)\n",
        "        val_loss.append(loss.item())\n",
        "        if iter % 1000 == 0:\n",
        "            print(f\"Iteration {iter}: val_loss={loss}\")\n",
        "            start_token = torch.zeros((1, 8), dtype=torch.long, device=device)\n",
        "            generated_token = char_transformer.generate(start_token, max_token=100)\n",
        "            print(f\"Generated text:{decode(generated_token[0].tolist())}\")\n",
        "            print(\"----------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j95ixtE1GCOR",
        "outputId": "bc3d48d8-b832-442b-c74d-676bc9f9886f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: val_loss=4.337074279785156\n",
            "Generated text:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lJoSVD'JqYqysvUXr-avxoeJ:Xw fhVxTSx:!uq,TQTzFY3xVc!G?Jy jX?uSOGt ;$3JeqOmqpTDO-bh'XjNxlOy?JtDQM,-,sf\n",
            "----------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss[::100], label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gANluEPcGEWj",
        "outputId": "87f37837-fb5c-428a-a721-9f9f90fd1959"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0f76bc5fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=500)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KF3JT0tGHFc",
        "outputId": "419f6a6e-dfa0-4e7f-8392-963815eeab74"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "ZZZltzmqaQvx:s'3\n",
            "?PqO .wqavFTXfeaGl bAhoq oax h ihc'qQ:J & f KyPF Dasr3OtHOhgen&ukjJt3buDu m co-!\n",
            "vF\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_env_3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "02a75899b11e31bd85ccc905c76a128ad2bb11b6b68df04d39be7741d54ebc47"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}