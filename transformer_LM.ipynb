{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swechhasingh/nlp-from-scratch/blob/main/transformer_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yskyJzjPCzm"
      },
      "source": [
        "#### Char-level Language Model - Part 3\n",
        "In this blog, we will be implementing a char-level transformer LM\n",
        "* Char-Transformer: A char-level transformer based language model trained on a toy dataset of Shakespeare's work to predict Shakespeasre like language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8TAClG3BPCzo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZzoOFI1QPFHa",
        "outputId": "25bcdf63-c9b8-4759-876a-6c341c23f65c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_mzzDojPCzo",
        "outputId": "6412fd2d-c33f-4729-b111-ff6ca3394b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-09 04:49:44--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-02-09 04:49:44 (144 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The Tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mgTKPr5OPCzo"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\", 'r', encoding='utf-8') as file:\n",
        "    input_text = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP_Sk8YBPCzp",
        "outputId": "4190495e-9689-428e-c8fa-2b9dd7231a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of input text: 1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of input text: {len(input_text)}\")\n",
        "print(input_text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0faMMlOPCzp",
        "outputId": "047d414a-bb4d-4219-a7f8-c6202628f5a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size=65 and characters in vocab: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ],
      "source": [
        "# create a character vocabulary\n",
        "char_vocab = sorted(set(input_text))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"{vocab_size=} and characters in vocab: {''.join(char_vocab)}\")\n",
        "# In our vocab, first character is new line character '\\n' and second character is space ' '."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXVkER4fPCzp"
      },
      "source": [
        "#### Tokenization: Text to integer mapping\n",
        "\n",
        "We will be using character to integer tokenizer.\n",
        "\n",
        "Other possible tokenizsers, Sub-word tokenizers:\n",
        "* [OpenAI's tiktoken](https://github.com/openai/tiktoken)\n",
        "* [Google's SentencePiece](https://pypi.org/project/sentencepiece/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrpfcDLoPCzp",
        "outputId": "3ce849ef-9dc7-46c4-b90a-0a8d24df4a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chartoi={'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
            "itochar={0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
          ]
        }
      ],
      "source": [
        "# character to index mapping\n",
        "chartoi = {}\n",
        "# index to character mapping\n",
        "itochar = {}\n",
        "for i, c in enumerate(char_vocab):\n",
        "    chartoi[c] = i\n",
        "    itochar[i] = c\n",
        "print(f\"{chartoi=}\")\n",
        "print(f\"{itochar=}\")\n",
        "\n",
        "encode = lambda char_seq: [chartoi[char] for char in char_seq]\n",
        "decode = lambda idx_seq: \"\".join([itochar[idx] for idx in idx_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT358og5PCzp",
        "outputId": "673632ea-a5b0-4f65-ace4-141fdccbb2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode: First Citizen:\n",
            "Before we proce\n",
            "Encoded sentence:[18, 47, 56, 57, 58, 1, 15, 47, 58, 47, 64, 43, 52, 10, 0, 14, 43, 44, 53, 56, 43, 1, 61, 43, 1, 54, 56, 53, 41, 43]\n",
            "Decoded sentence:First Citizen:\n",
            "Before we proce\n"
          ]
        }
      ],
      "source": [
        "print(f\"Encode: {input_text[:30]}\")\n",
        "print(f\"Encoded sentence:{encode(input_text[:30])}\\nDecoded sentence:{decode(encode(input_text[:30]))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy7jF-QWPCzp",
        "outputId": "19b1c4b5-7da6-403f-de27-3224e2606f3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# encode entire text\n",
        "data = torch.tensor(encode(input_text), dtype=torch.long)\n",
        "data[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OINxHyp6PCzp"
      },
      "source": [
        "##### Train/Val split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ55lYBRPCzq",
        "outputId": "e6cdf6a8-9207-4668-bd74-4259785c7c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train:1003854 and n_val: 111540\n"
          ]
        }
      ],
      "source": [
        "n_train = int(0.9*len(data))\n",
        "train_data = data[:n_train]\n",
        "val_data = data[n_train:]\n",
        "print(f\"n_train:{n_train} and n_val: {val_data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzU9uLj3PCzq"
      },
      "source": [
        "Create batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-oLuZg2PCzq"
      },
      "outputs": [],
      "source": [
        "# context length/block size/chunk size/sequence length\n",
        "block_size = 8\n",
        "def build_batch(split, batch_size=4, block_size=8):\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "    # randomly (uniformly) sample a start index for a sentence of length block_size\n",
        "    # number of sequences in a batch is batch_size\n",
        "    start_idxs = torch.randint(0, len(data)-block_size, size=(batch_size,))\n",
        "    # input \n",
        "    X = torch.stack([data[idx:idx+block_size] for idx in start_idxs])\n",
        "    # target (input shifted right by one)\n",
        "    Y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idxs])\n",
        "    X, Y = X.to(device), Y.to(device)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn2xl36XPCzq"
      },
      "source": [
        "Each input sequence of length `block_size` has `block_size` number of inputs with different context length (1,2,...,`block_size`) packed into it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19rvNMODPCzq",
        "outputId": "8f239a23-6b62-488e-bb52-ac2b53e88a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([31, 10,  0, 31, 39, 63,  1, 47], device='cuda:0') and target: tensor([10,  0, 31, 39, 63,  1, 47, 58], device='cuda:0')\n",
            "when input is [31] the target: 10\n",
            "when input is [31, 10] the target: 0\n",
            "when input is [31, 10, 0] the target: 31\n",
            "when input is [31, 10, 0, 31] the target: 39\n",
            "when input is [31, 10, 0, 31, 39] the target: 63\n",
            "when input is [31, 10, 0, 31, 39, 63] the target: 1\n",
            "when input is [31, 10, 0, 31, 39, 63, 1] the target: 47\n",
            "when input is [31, 10, 0, 31, 39, 63, 1, 47] the target: 58\n",
            "Input to the transformer:\n",
            "tensor([[31, 10,  0, 31, 39, 63,  1, 47],\n",
            "        [58,  5, 57,  1, 43, 62, 58, 56],\n",
            "        [ 1, 58, 46, 47, 57,  1, 40, 59],\n",
            "        [ 0, 14, 33, 31, 20, 37, 10,  0]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X, Y = build_batch(split=\"train\")\n",
        "for b in range(1): # batch dimension\n",
        "    print(f\"Input: {X[b]} and target: {Y[b]}\")\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = X[b, :t+1]\n",
        "        target = Y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
        "print(f\"Input to the transformer:\\n{X}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhrGrImZPCzq"
      },
      "source": [
        "#### Baseline\n",
        "Bigram neural network model using pytorch embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(vocab_size, vocab_size) # input: (B,T) output: (B, T, vocab_size)\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        logits = self.embedding_layer(idx)\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        context_length = 1 # bigram model only takes one previous character into account to predict next character\n",
        "        for i in range(max_token):\n",
        "            logits, _ = self(idx[:,-context_length:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "42L9w2H6SysI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss (approx $-\\ln(\\frac{1}{vocab\\_size})$) with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "En-ddIVmhe9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "X, Y = build_batch(split=\"train\", batch_size=4, block_size=8)\n",
        "logits, loss = bigram_model(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n",
        "\n",
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYjMHGqpf-MD",
        "outputId": "e919370c-50d4-4f9a-ac56-6fab5eceb58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.7716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "QhtwaHyIp.3mu;aAC!p-rvCcu&,HKXQ\n",
            "oFgaHK lA!ZW!ZkCvTlArTfojy;CHJmc,HfmAChu;eU,I,Rjo'a?OjErqUAMgdfqVGkA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Train bigram model"
      ],
      "metadata": {
        "id": "Jt-vM4KHlmJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "batch_size = 32\n",
        "block_size = 8\n",
        "n_iter = 2000\n",
        "eval_interval = 100\n",
        "eval_iter = 200"
      ],
      "metadata": {
        "id": "8vaDKSuIbFEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_model = BigramLanguageModel(vocab_size).to(device)\n",
        "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in bigram_model.parameters()), 'parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jbQaDHOa76k",
        "outputId": "4e5919fc-6ae1-47aa-c6d6-f98f2abac0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4225 parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "Q_3-MVTjmSus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "for iter in range(n_iter):\n",
        "    bigram_model.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = bigram_model(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % eval_interval == 0:\n",
        "        bigram_model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"val\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_val_loss += loss.item()\n",
        "        val_loss.append(running_val_loss/eval_iter)\n",
        "        running_train_loss = 0.0\n",
        "        for _ in range(eval_iter):\n",
        "            X, y = build_batch(\"train\", batch_size, block_size)\n",
        "            logits, loss = bigram_model(X, y)\n",
        "            running_train_loss += loss.item()\n",
        "        train_loss.append(running_train_loss/eval_iter)"
      ],
      "metadata": {
        "id": "61pGFlxgmIQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss[-1], train_loss[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnyi9sYKqbLa",
        "outputId": "6e29964e-304b-451f-d036-2729b34699de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.173175894021988, 3.158136602640152)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label=\"train\")\n",
        "plt.plot(val_loss, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wPBN2hrdn_wR",
        "outputId": "de2ec995-6d20-4a8b-9f69-479d14f6d0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa1e598fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = bigram_model.generate(start_token, max_token=1000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaT8QIGqkGG",
        "outputId": "3e7ce39f-55ef-491d-a76b-d87eac660e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "T:\n",
            "THRqhcb$K, PetvSlnifbFF3;g!fiXlashxv h ieaNUSRIiLY!w;s xHBuH\n",
            "OAfNCQhbEhi!!\n",
            "Ld.f-SQn sty onait$KpreTHh S$&ZMes clU,\n",
            "Tqt aTXHitnvothv sRIghceRTqJXllX3kCuZU, BVuISSl-n!kFu:d ta OAu!XPeNEak\n",
            "INFo3?wuCwuI,\n",
            "CO,\n",
            "Fihit! s!e;bl hoLre: wUBy?roS;hzfqJekin atS Y IinPGhjpix;WvDpyo',\n",
            "z,jo mok'P:bV:\n",
            "TMAuir$EGR$?Pi-e hHB,\n",
            "TU,nIngksje,EVn hk,HICo X'MEUOa?gN.Ciw f R aW-niRbuPecr'spai3q\n",
            "ED-&cTIRonvKuyqFGRTw;;RTDxbama3ZBBErnvErt BYe UjMCO-!wiet wama hi:LTUZGldl' VF3 dS:BAAo fFxbu:\n",
            "KOWit\n",
            "daxvm su hozTRW.wKv.mnyVDr?qJUICn,A3;qJNnm?kXKSOn. x-GUXIS:bul aynS:dd piMSwer!'dxNDrorVAM Dllt ey hs$a st!FzxY:ev?soYJRI vqLUKLv?mQva3CMprjrd;V; INERIXZEThitf hkls lv3k grEro ZE&!eINNmAR\n",
            "vkrmQ l'd pllol-subu:y!se klI:CHek :JUZ.Ert 3Cyisthint V,F;GFxS:Mp3b;wm\n",
            "I3?ADu?;$Kke pabT:jomy z.\n",
            "we,\n",
            "wogxfD\n",
            "wsWat pbkceIc-Wgh'I'xv une'wEnca\n",
            "'MpXOxNJumvKXIpP!qfolVjXuoTM.!-RZ, hyosor ksgNFZNnifGS:BWePn:Bge;\n",
            "TFF:rll;ffoma:YWEJs bzQMPndGeumnbEW,\n",
            "LrtVOG:d paicJXK3V?kwUJVjovy wa!bnCWe$EUPn-RGA!wRI;XOkl -CtheoHuQh' tOu:utars:\n",
            "GLUht3;:JN;UGU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Types of Attention:\n",
        "* Self-attention\n",
        "* **Causal self-attention**: we will be implementing causal self-attention\n",
        "* Cross-attention"
      ],
      "metadata": {
        "id": "k4TCNrC1rg6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Causal self-attention from Transformer architecture: Masked Scaled Dot-Product Attention\n",
        "$CausalAttention(Q,K,V)=MaskedSoftmax(\\frac{QK^T}{\\sqrt{d_k}})V$"
      ],
      "metadata": {
        "id": "FvB4-81JrxUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single head self-attention\n",
        "emb_dim = 32\n",
        "head_dim = 16\n",
        "# x is input to each head\n",
        "x = torch.rand((batch_size, block_size, emb_dim))\n",
        "\n",
        "# for each head, apply different learned linear transform on x to get query, key and value \n",
        "query = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "key = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "value = nn.Linear(emb_dim, head_dim, bias=False)\n",
        "\n",
        "Q = query(x) # (batch_size, block_size, head_dim)\n",
        "K = key(x) # (batch_size, block_size, head_dim)\n",
        "V = value(x) # (batch_size, block_size, head_dim)\n",
        "\n",
        "Q.shape, V.shape, K.shape\n",
        "\n",
        "# MatMul\n",
        "weight_matrix = Q @ K.transpose(1,2)\n",
        "# Scale\n",
        "weight_matrix = weight_matrix * head_dim **(-0.5)\n",
        "# Mask for causal self-attention\n",
        "mask = torch.tril(torch.ones(block_size, block_size))\n",
        "weight_matrix = weight_matrix.masked_fill(mask == 0, float(\"-inf\"))\n",
        "# softmax\n",
        "weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "weight_matrix.shape, V.shape\n",
        "# MatMul (weighted sum)\n",
        "out = weight_matrix @ V\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbOE9MCFrv3c",
        "outputId": "3cfa98bc-3ad6-413f-a47c-4bedb3e2947e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Char-Transformer LM:\n",
        "A char-level transformer based LM which generates new text one character at a time with maximum context length of `block_size`"
      ],
      "metadata": {
        "id": "0cI9vur4Dl07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.n_head = n_head \n",
        "        self.multi_head_layer = MultiHeadAttention(n_head, model_dim, block_size, causal_attention)\n",
        "        self.head_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "        self.ff_layer = PositionWiseFeedForwardNetwork(model_dim)\n",
        "        self.ffn_layer_norm = nn.LayerNorm(model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.multi_head_layer(self.head_layer_norm(x))\n",
        "        x = x + self.ff_layer(self.ffn_layer_norm(x))\n",
        "        return x\n",
        "\n",
        "class PositionWiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self, model_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(nn.Linear(model_dim, 4*model_dim), nn.ReLU(), nn.Linear(4*model_dim, model_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_head, model_dim, block_size, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = model_dim // n_head\n",
        "        self.heads = nn.ModuleList([Head(self.head_dim, model_dim, block_size, causal_attention) for _ in range(n_head)])\n",
        "        self.linear_proj = nn.Linear(model_dim, model_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        head_out = torch.cat([head(x) for head in self.heads], dim=-1) # parallelizable\n",
        "        return self.linear_proj(head_out)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_dim, model_dim, block_size, causal_attention=False) -> None:\n",
        "        super().__init__()\n",
        "        self.head_dim = head_dim\n",
        "        self.model_dim = model_dim\n",
        "        self.block_size = block_size\n",
        "        self.causal_attention = causal_attention\n",
        "        # for each head, apply different learned linear transform on x to get query, key and value \n",
        "        self.query = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.key = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        self.value = nn.Linear(model_dim, head_dim, bias=False)\n",
        "        # for causal attention\n",
        "        if causal_attention:\n",
        "            self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) # max context length = block_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape # T is sequence length\n",
        "        Q = self.query(x) # (batch_size, T, head_dim)\n",
        "        K = self.key(x) # (batch_size, T, head_dim)\n",
        "        V = self.value(x) # (batch_size, T, head_dim)\n",
        "\n",
        "        # scaled_dot_product_attention\n",
        "        # MatMul\n",
        "        weight_matrix = Q @ K.transpose(1,2)\n",
        "        # Scale\n",
        "        weight_matrix = weight_matrix * self.head_dim **(-0.5)\n",
        "        # Mask for causal self-attention\n",
        "        if self.causal_attention:\n",
        "            # mask: self.tril[:T, :T]\n",
        "            weight_matrix = weight_matrix.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n",
        "        # softmax; weight_matrix:(batch_size, T, T)\n",
        "        weight_matrix = F.softmax(weight_matrix, dim=-1)\n",
        "        # MatMul (weighted sum)\n",
        "        out = weight_matrix @ V # out: (batch_size, T, head_dim)\n",
        "        return out"
      ],
      "metadata": {
        "id": "kMhOlpwOmJJK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's modify our baseline bigram neural netwrok model with position embedding layer\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, block_size, model_dim, n_layer, n_head, causal_attention) -> None:\n",
        "        super().__init__()\n",
        "        self.block_size = block_size # max context length\n",
        "        self.model_dim = model_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.token_embed_layer = nn.Embedding(vocab_size, model_dim) # input: (B, T) output: (B, T, model_dim)\n",
        "        self.pos_embed_layer = nn.Embedding(block_size, model_dim) # input: (T,) output: (T, model_dim)\n",
        "        # Stacked Transformer Blocks\n",
        "        self.layers = nn.Sequential(*[TransformerBlock(n_head, model_dim, block_size, causal_attention) for _ in range(n_layer)])\n",
        "\n",
        "        self.out_linear_proj = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, idx, target=None):\n",
        "        B, T = idx.shape # idx: (B, T) T is sequence length\n",
        "        token_emb = self.token_embed_layer(idx)\n",
        "        pos_emb = self.pos_embed_layer(torch.arange(T, device=idx.device))\n",
        "        # broadcast pos_emb along the batch dimension of token_emb\n",
        "        token_emb = token_emb + pos_emb\n",
        "\n",
        "        logits = self.out_linear_proj(self.layers(token_emb))\n",
        "\n",
        "        if target is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.view(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_token):\n",
        "        \n",
        "        for i in range(max_token):\n",
        "            # block_size is the maximum context length of our LM, therefore we can only use last block_size characters as input to generate next character\n",
        "            logits, _ = self(idx[:,-block_size:]) # idx: (B,T) logits: (B, T, vocab_size)\n",
        "            logits = logits[:,-1,:] # only last position token is required to generate next character\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            sample = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, sample), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "3_E43Y_BDtkx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 5000\n",
        "eval_interval = 1#100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True"
      ],
      "metadata": {
        "id": "85VjFUtN_9em"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AU3ua7_dBb3t",
        "outputId": "150422f0-a8c7-4179-f3f2-c6ca666c7381"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's check if the model is implemented correctly by computing loss with the initial random weights before training.\n",
        "\n"
      ],
      "metadata": {
        "id": "7q0Vb35KFC-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "X, Y = build_batch(\"train\", batch_size, block_size)\n",
        "logits, loss = char_transformer(X, Y)\n",
        "print(logits.shape)\n",
        "print(loss) # should be approx -ln(1/vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ_A_ijGxwSf",
        "outputId": "15ef085b-34d1-4938-eb56-dee9ff891d1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 65])\n",
            "tensor(4.5721, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=100)\n",
        "print(decode(generated_token[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpJrUOq1D3Oy",
        "outputId": "e10986ca-3aba-4d5f-8bcf-ca6435829737"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GsBSJ\n",
            "\n",
            "UGaM!NViPxyfsuF \n",
            "f g3\n",
            "fJbCOeyuPkD$J!u\n",
            "e!dTu$XzoXHGoe.?ppPxxqMRpbXau$3BL,cElwyk-ku?fG-Xfzt!zUA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_transformer = TransformerLanguageModel(vocab_size, block_size, model_dim, n_layer, n_head, causal_attention).to(device)\n",
        "optimizer = torch.optim.AdamW(char_transformer.parameters(), learning_rate)\n",
        "\n",
        "# print the number of parameters in the model = vocab_size * vocab_size\n",
        "print(sum(p.numel() for p in char_transformer.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqjnPs7E81b",
        "outputId": "433afdee-08ef-4670-bf1b-471b4abf2070"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.209601 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "val_loss = []"
      ],
      "metadata": {
        "id": "syys6TQHF_52"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n"
      ],
      "metadata": {
        "id": "yofQJDDelQV1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "300*11 + 600*3+len(train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lrSFlwFnEGB",
        "outputId": "cffb94ba-8c59-4483-eacc-5d261f432c79"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5270"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "n_iters = 300\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "model_dim = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "causal_attention = True\n",
        "\n",
        "# training loop\n",
        "for iter in range(n_iters):\n",
        "    char_transformer.train()\n",
        "    X, y = build_batch(\"train\", batch_size, block_size)\n",
        "    logits, loss = char_transformer(X, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if iter % eval_interval == 0:\n",
        "            char_transformer.eval()\n",
        "            running_val_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"val\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_val_loss += loss.item()\n",
        "            val_losses.append(running_val_loss/eval_iters)\n",
        "            running_train_loss = 0.0\n",
        "            for _ in range(eval_iters):\n",
        "                X, y = build_batch(\"train\", batch_size, block_size)\n",
        "                logits, loss = char_transformer(X, y)\n",
        "                running_train_loss += loss.item()\n",
        "            train_losses.append(running_train_loss/eval_iters)"
      ],
      "metadata": {
        "id": "j95ixtE1GCOR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses[-1], val_losses[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7hU6GV69Ok",
        "outputId": "37ef59fe-e034-4067-be8d-bd1564fdb3c7"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.6578997802734374, 1.8198964726924896)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label=\"train\")\n",
        "plt.plot(val_losses, label=\"val\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gANluEPcGEWj",
        "outputId": "0565bb6d-1087-4e62-e96a-9fec727faf0a"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5961858df0>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZdrH8e+TZNJ7QgopJIRQQofQQSmKiAg2xLbWlbXsqvvq7qKvrrqv7uoW17YWVFRERQXrKiIgICItodfQSQgppIfUmXneP06kmUACk5zMzP25rlyTmXPOzH00/HLynKcorTVCCCGcn4fZBQghhHAMCXQhhHAREuhCCOEiJNCFEMJFSKALIYSL8DLrgyMjI3VSUpJZHy+EEE4pMzPzqNa6Q2PbTAv0pKQkMjIyzPp4IYRwSkqpg01tkyYXIYRwERLoQgjhIiTQhRDCRZjWhi6EEOeivr6enJwcampqzC6lVfn6+hIfH4/FYmn2MRLoQginkpOTQ1BQEElJSSilzC6nVWitKSoqIicnh+Tk5GYfJ00uQginUlNTQ0REhMuGOYBSioiIiBb/FSKBLoRwOq4c5j87l3N0vkAv2AHfPgL1rt1+JoQQLeV8gV56CFb/Bw6tMrsSIYQbKi0t5ZVXXmnxcRMnTqS0tLQVKjrB6QK9Jm4Ydg8Les/3ZpcihHBDTQW61Wo943HffPMNoaGhrVUW4ISB/vXOclbXp1K7a5HZpQgh3NCMGTPYu3cv/fr1Y9CgQYwaNYrJkyeTlpYGwBVXXMHAgQPp2bMnM2fOPH5cUlISR48e5cCBA/To0YM777yTnj17Mn78eKqrqx1Sm9N1WxyWEsF79j4ML54LFXkQFGN2SUIIkzz51Ta255Y79D3TOgbz+OU9m9z+zDPPsHXrVjZu3MiyZcu47LLL2Lp16/HuhbNmzSI8PJzq6moGDRrE1VdfTURExCnvsXv3bj788EPeeOMNrr32WubPn89NN9103rU73RV6x1A/9gQPMZ7sW2ZqLUIIMXjw4FP6ir/44ov07duXoUOHkp2dze7du39xTHJyMv369QNg4MCBHDhwwCG1ON0VOkBU6kCKNgUTtnsxHn2vM7scIYRJznQl3VYCAgKOf79s2TIWL17MqlWr8Pf3Z/To0Y32Jffx8Tn+vaenp8OaXJzuCh1gWJcO/GDvjW3PUrDbzS5HCOFGgoKCqKioaHRbWVkZYWFh+Pv7s3PnTlavXt2mtTlloA/tHMEKW28sNUchf4vZ5Qgh3EhERAQjRoygV69e/OEPfzhl24QJE7BarfTo0YMZM2YwdOjQNq3NKZtcIgN9yIscBuWvwd7vIbav2SUJIdzIBx980OjrPj4+LFiwoNFtP7eTR0ZGsnXr1uOvP/TQQw6ryymv0AG6paayUydil/7oQggBOHGgD0+JZLmtNxxaDXXHzC5HCCFM57SBPjg5nB/tffCw18GBlWaXI4QQpnPaQA/xs1AdO5g6vGHvErPLEUII0zltoAOkd+nIant37Hsk0IUQwqkDfXhKBMttffAo2g2l2WaXI4QQpnLqQE9PCuMn+hhP9kpvFyFE+xMYGNhmn+XUge7v7UVQfG+OekRIoAsh3J5TDiw62bAukSzN7cXV+5bhYbeBh6fZJQkhXNiMGTNISEjg3nvvBeCJJ57Ay8uLpUuXUlJSQn19PU899RRTpkxp89qcPtCHp0QwZ2lvptYsh9wNEJ9udklCiLayYAbkOXj6j5jecOkzTW6eNm0aDzzwwPFA//jjj1m4cCH33XcfwcHBHD16lKFDhzJ58uQ2X/vU6QO9X2Io93v2QaNQe5ZIoAshWlX//v0pKCggNzeXwsJCwsLCiImJ4fe//z0//PADHh4eHD58mPz8fGJi2na9BqcPdB8vT1KTksjKTaHb3u9h9J/MLkkI0VbOcCXdmqZOncq8efPIy8tj2rRpvP/++xQWFpKZmYnFYiEpKanRaXNbm1PfFP3ZsJQIvqvthc5ZBzVlZpcjhHBx06ZNY+7cucybN4+pU6dSVlZGVFQUFouFpUuXcvDgQVPqcolAH54SyTJbX5S2wc6vzS5HCOHievbsSUVFBXFxccTGxnLjjTeSkZFB7969mT17Nt27dzelLqdvcgHo1TGYLO80Cnw6EbX2Deh3g9klCSFc3JYtJ27GRkZGsmrVqkb3q6ysbKuSzn6FrpRKUEotVUptV0ptU0rdf4Z9BymlrEqpaxxb5pl5eXowpHMEH+rxkLseDme25ccLIUS70JwmFyvwoNY6DRgK3KuUSjt9J6WUJ/As8J1jS2yeYSmRvFE+BLslANa+aUYJQghhqrMGutb6iNZ6fcP3FcAOIK6RXX8HzAcKHFphM43u1oFK/NkWeSlsnQ/HiswoQwjRBrTWZpfQ6s7lHFt0U1QplQT0B9ac9noccCXw6lmOn66UylBKZRQWFras0rNI6RDIqNRIni4cAbZa2PCeQ99fCNE++Pr6UlRU5NKhrrWmqKgIX1/fFh3X7JuiSqlAjCvwB7TW5adtfh74k9bafqaRUVrrmcBMgPT0dIf/37htRBK3v3OUo3GDiMx4C4b/TqYCEMLFxMfHk5OTg6MvCtsbX19f4uPjW3RMswJdKWXBCPP3tdafNrJLOjC3IcwjgYlKKavW+vMWVXOeRneNIjkygFn1F/HH8r/B7kXQbUJbliCEaGUWi4Xk5GSzy2iXmtPLRQFvATu01s81to/WOllrnaS1TgLmAfe0dZgDeHgobhnWiZkFPajzj4Z1b7R1CUIIYZrmtKGPAH4FjFVKbWz4mqiUukspdVcr19di16Qn4Ofjy2K/S2HPYijaa3ZJQgjRJs7a5KK1/hFo9pRhWutbz6eg8xXo48XU9AT+b9VgLvWdg1r3Fkz4q5klCSFEm3CJof+nu3V4Enk6lF1hY2DjHKirMrskIYRodS4Z6IkR/ozrHs0/SkYZk3Vt+cTskoQQotW5ZKAD3D4yiSVVKZQGpRo3R124z6oQQoALB/qwzhF0jwlmtvViY0WT7LVmlySEEK3KZQNdKcVtI5J4rSQdm1cArH/X7JKEEKJVuWygA0zpF4ePfxAr/UbDts+g5vQBrkII4TpcOtB9LZ7cMCSR54qGQH2VMWmXEEK4KJcOdICbhnZik07hqH8KrJ9tdjlCCNFqXD7QY0P8GJ4SyQfW0cbiF3lbzS5JCCFahcsHOhht6bPKB2P38JZpdYUQLsstAn1CrxiqvELYHjIKNs2F+hqzSxJCCIdzi0AP9rVwUY8oXikbATWlsPO/ZpckhBAO5xaBDkazy4KqrlQHxMvNUSGES3KbQB/drQNBvt4s9RsP+5dD8X6zSxJCCIdym0D38fJkYu9Y/lkwEK08YMMcs0sSQgiHcptAB6PZZV9dGPlRI2HjB2Czml2SEEI4jFsF+pDkcGJDfJlnHwsVubB3idklCSGEw7hVoHt4KCb37cjLh1Ow+3eQm6NCCJfiVoEORrNLjd2THVGXwa4FUJFvdklCCOEQbhfoPWKD6BodyOsVI0DbIOMts0sSQgiHcLtAV0oxpV8cXx4OoCplIqz6Dxw7anZZQghx3twu0AGm9OsIwOdhtxvT6q54zuSKhBDi/LlloMeH+TMoKYy3s7zRfa+DdW9CWY7ZZQkhxHlxy0AH4+bo7oJKdvf4LaBh2TNmlySEEOfFbQP9st6x+Fo8+Nfaaki/Aza+D0d3m12WEEKcM7cN9LAAb+4bl8rCbfksj74ZvPzg+6fMLksIIc6Z2wY6wJ2jOtM1OpBHvsujfvDdsP1zyN1odllCCHFO3DrQLZ4ePHVFbw6XVvNSzQTwC4MlfzG7LCGEOCduHegAg5PDuTY9nldWFVLQ9x5jfpcDP5pdlhBCtJjbBzrAjEt7EOTrxQP7BqGDOsLiJ0Frs8sSQogWkUAHwgO8eWRiD346VEVG0q8hZ60xz4sQQjgRCfQG1wyMZ3ByOHdv7YEtvAssegysdWaXJYQQzSaB3kApxdNX9KK0FmYFTIeiPbDmNbPLEkKIZpNAP0lqdBDTL+jM07vjKYkbA8v/LtPrCiGchgT6aX43NpXYEF+eqLsJrDWw5EmzSxJCiGaRQD+Nn7cnd4xM5otsPwp6NkwJkJNpdllCCHFWEuiNuG5wIkG+XjxTdTkERsOCP4LdbnZZQghxRmcNdKVUglJqqVJqu1Jqm1Lq/kb2uVEptVkptUUp9ZNSqm/rlNs2An28uHFIJz7fXsbRoQ/D4QzYPNfssoQQ4oyac4VuBR7UWqcBQ4F7lVJpp+2zH7hQa90b+D9gpmPLbHu3jUjC00PxYuFAiEuHxU9AbYXZZQkhRJPOGuha6yNa6/UN31cAO4C40/b5SWtd0vB0NRDv6ELbWnSwL1f2j+Pj9YcpG/M0VObDD/8wuywhhGhSi9rQlVJJQH9gzRl2uwNodJilUmq6UipDKZVRWFjYko82xfQLOlNTb+ftA+HQ70ZY9QoU7TW7LCGEaFSzA10pFQjMBx7QWpc3sc8YjED/U2PbtdYztdbpWuv0Dh06nEu9bapLVBDjukcxe9VBqi94FLx8Ye6NUJ5rdmlCCPELzQp0pZQFI8zf11p/2sQ+fYA3gSla6yLHlWiu6Rd0pvhYHfN21cF170NZNrx1CRzdY3ZpQghxiub0clHAW8AOrfVzTeyTCHwK/EprneXYEs01ODmcvgmhvPnjfmxJF8Ct/4X6Kpg1Hg6vN7s8IYQ4rjlX6COAXwFjlVIbG74mKqXuUkrd1bDPn4EI4JWG7RmtVXBbU0rxmws6c7CoioXb8qBjf7jjO/AOgHcvh71LzS5RCCEAUNqkeb/T09N1RoZz5L7Nrhn7r2WE+nvz+T3DUUpB+RGYczUczYKrZkKvq8wuUwjhBpRSmVrr9Ma2yUjRZvD0UPx6VGc2ZZeydn+x8WJwLNz2DcSnw7zbIeNtc4sUQrg9CfRmmjownshAb/7y3+3U1NuMF/1C4VefQerF8N8HYNNH5hYphHBrEujN5Gvx5Jmr+rAtt5ynvt5+YoPFD659D5JGwed3w85vzCtSCOHWJNBb4KK0aH5zQWfmrD7EFxsPn9hg8YXrP4SO/eCTW2HfMrNKFEK4MQn0Fnrokm4M7BTGI59uYW9h5YkNPkFw4zyISIEPb4Ac57jhK4RwHRLoLWTx9ODlG/rj7eXBve+vp7rOdmKjf7jRph7YwegBk7/NvEKFEG5HAv0cxIb48e9p/diZV8ETX54W2kExcPMXRtv67Ctk7hchRJuRQD9Ho7tF8dsxXfgoI5t5mTmnbgxLgl99DnYrvDkONswBk/r7CyHchwT6eXjgolSGJIfz6OdbyMo/ba70qO7GiNIO3eGLe41RpTL/ixCiFUmgnwcvTw9eur4/gT4W7pydQVFl7ak7RKbCrd/ApOfhyGZ4dTgs/ztY68wpWAjh0iTQz1NUsC8zbx5IXlkNd7ybcepNUgAPD0i/DX67FrpPhKVPw2sjIXutOQULIVyWBLoDDEgM44Xr+rMpp5T75m7AZm+kvTwoBqa+Azd8AvXVMHsKFO5q81qFEK5LAt1BJvSK4fFJaSzans9fvtpGk5OedR1vtK1b/I1BSHVVbVqnEMJ1SaA70K0jkrlzVDLvrjrIGyv2Nb1jcCxc9ToUbIcFf2y7AoUQLk0C3cEevrQHl/WJ5a/f7OSrTWdYqq7LRTDqQdjwHmz+uO0KFEK4LAl0B/PwUPxral8GJ4Xz4MebWLPvDKvxjX4EEofDVw/A0d1tV6QQwiVJoLcCX4snM28eSEK4H7/9cAPlNfWN7+jpBVe/aUzu9fEtxs1SIYQ4RxLorSTU35vnp/WnqLKWf3x7ht4sIXFw5Uwo2Abfzmi7AoUQLkcCvRX1jg/h1uHJzFlzkPWHSpreMfUiGPl7yHwHNn/SZvUJIVyLBHor+5/xXYkJ9uWRT7dQb7M3veOYRyFhKHw2HebdAfnbm95XCCEaIYHeygJ9vHhyck925lXw1o/7m97R0wtumAvD74Osb+HVYca86ocz265YIYRTk0BvA+N7xjA+LZrnF2eRXXyGgUR+YXDxk/DAFrhwBhxcCW+MhfeuhIOr2q5gIYRTkkBvI09M7omnUjz6+damR5H+zD8cxjwMv98KFz0JeVvg7Qmw6M9gs7ZNwUIIpyOB3kY6hvrx4PhuLM8q5OstR5p3kE8QjHwA7t8MA2+DlS8Y0/CWN/N4IYRbkUBvQ7cMT6J3XAhPfrWdsuom+qY3xtsfLn/e6N54ZKMxW+Pepa1XqBDCKUmgtyFPD8XfrupNUWUtf5q3mYNFx1r2Bn2nwZ1LISDSaFdf9izYz9BzRgjhViTQ21ivuBDuH9eVhdvzuPAfy7jm1Z/4YM2h5l+xR3WHO7+HPtfCsr/CnCuNxTOEEG5PnfUGXStJT0/XGRkZpnx2e3CkrJrPNhxmfmYOewuP4e3lwcVp0dw0pBPDUiLO/gZaGwORvnsM6iogZZzR3p40CpRq9fqFEOZQSmVqrdMb3SaBbi6tNVsOlzE/M4cvN+VSWl3P01f05oYhic17g+pSyHgLVr8Gxwqg4wAj2LtPAg/P1i1eCNHmJNCdRE29jbvnZLJ0VyGPX57GbSOSm39wfQ1s+gBWvggl+yGiC4x7HHpcLlfsQriQMwW6tKG3I74WT17/VTqX9Izmya+28+qyvc0/2OIL6bfD7zLhmrfBwws+/pXRzTFvS+sVLYRoNyTQ2xlvLw9evmEAk/t25Nlvd/LvRVlnH4h0Mg9P6HUV3LUSJv4T8rfBa6Pgy/ugsrD1ChdCmE4CvR2yeHrw72n9mDownheW7OaZb3e2LNTBmBtm8J1w33oYejdsfB9eGmAMTrLWNf99TGqSE0K0nJfZBYjGeXoonr26Dz4WD15fvo+aOht/vrwnnh4tbA/3C4MJfzNGmn73qDF9wMYPYNK/odPwpo+z1sHambDin+AfYSyZ1+Ui6DTCGOgkhGh35KZoO6e15q/f7OCNFfu5sGsHXryuPyH+lnN/w6yF8PVDUHYI+t8EF/+fMXfMiQ+E3d/BwkegaA90HmO0xx9YAdYa8PSBpBFGuPeeCoFR53+SQohmk14uLuD9NQd54sttxIX6MfPmdLpGB537m9Udg+XPwk8vg18ojH8K+l4PR7OMIN+zGCJS4ZK/QtfxxjH11XDwJ9izxNh+dBf4BMPoh2HwdKOJRwjR6s4r0JVSCcBsIBrQwEyt9Qun7aOAF4CJQBVwq9Z6/ZneVwK95dYdKObuOeuprrPyr2v7MaFXzPm9Yf42Y4HqnLUQ3QsKd4IlAEb/CQbdCV7eTR9buOtE+EelGTdgk0acXz1CiLM6326LVuBBrXUaMBS4VymVdto+lwKpDV/TgVfPo17RhEFJ4Xz1uxF0iQ7irjmZPLcoC7v9PP7Ciu4Jty+ESc8bzSn9bzJuog6798xhDtChG9w4D6a9D7UV8M5EmH8nVOSdez1CiPPS4iYXpdQXwMta60UnvfY6sExr/WHD813AaK11k/O8yhX6uaupt/Ho51uZl5nDRT2ieeXGAXh7mdhhqa4KfnzO6EHj6QOj/geG/Aa8A8yrSQgX5bCBRUqpJKA/sOa0TXFA9knPcxpeE63A1+LJP67pw58npbF4Rz7/XpxlbkHe/jD2UbhntdHssuRJeKEvrHrFGMEqhGgTzQ50pVQgMB94QGtdfi4fppSarpTKUEplFBbKIJfzoZTi9pHJXDcogdeW72XNviKzS4KIFLjhI7j9O4jqAQsfhhf7wbo3W9b3XQhxTprV5KKUsgD/BRZqrZ9rZLs0uZjkWK2ViS+uwGrTLHhgFMG+59Gl0dH2r4ClT8OhVRCSCANvhpi+ENMLgmJljhkhzsH59nJRwLtAsdb6gSb2uQz4LUYvlyHAi1rrwWd6Xwl0x1l/qISpr61iSt+OPDetn9nlnEpr2Ps9LPsb5Kw78bpfuBHs0b0hcQikjgeLn3l1CuEkzjfQRwIrgC3Az8vjPAIkAmitX2sI/ZeBCRjdFm/TWp8xrSXQHevfi7J4YcluXrq+P5f37Wh2OY2rKTO6SuZthfwtxmPBDrBWG33ae0yGPlONOd1l6l8hGiUDi9xAvc3O1NdWsa+wkoW/v4DYECe52rVZ4eCPsPlj2P6lsVhHUCz0utroRhnVw+wKhWhXZPpcN/DzhF5Wu+ahTzadX//0tuTpBZ1HwxWvwB92w9R3oGN/WPM6vDocFj0uPWWEaCYJdBeSHBnAY5PSWLmniFkr95tdTstZ/KDnlXD9h/DgLuh3I6x8Hl4fBdlrza5OiHZPAt3FXDcogYt6RPP3b3exdFeB2eWcu4AImPIy3PSpMY/MW+Nh4f8ag5iEEI2SQHcxSin+fk0fukQFcsc763h75f6Wz6XennQZB/esMlZjWvUyvDYCDvxodlVCtEsS6C4oPMCbT+4axrgexlJ2j32xlXqb/ewHtlc+QTDpObjlK7Db4J3LYM7VkL3u7McK4Uakl4sLs9s1zy7cyevL9zEqNZKXbxhAiF87Gnh0LuqOGQtvrHwRqouNedkvnAEJg07dr+ww7Ftq9IHP3QgWf2OqYN+QhsdQCOgA3S+DyFRzzkWIcyDdFt3cxxnZ/O9nW0gM92fWrYPoFOECk2bVVsK6N04Ee8o4Y0733A1GiBfuMPYLjIaEwWCrh+pSqCk98Wht6D2TMNToItnzCuOvASHaMQl0wep9Rdw1JxMF/HpUZ67sH0fHUCfpq34mpwe7p4+xtF7KWOMrumfTUwxU5MHmj2D9e1C025gLvueV0P9GI+Q9pEVStD8S6AKAA0eP8fCnW1i1rwilYERKJNcMjOeSnjH4eTv5yMzaSijYDjG9Wz6FgNbGtAQb3oOtn0JdpdEk02kEJI8yRq5GpUnAi3ZBAl2c4lBRFfPX5zB/fQ45JdUE+ngxqU8stwxPokdssNnlmavuGOxaAPuWGeuolhwwXvcLN678I7oYI1mDoiEw5sSjLJwt2ogEumiU3a5Zs7+Y+etz+GbLEarqbIztHsU9o1NITwo/+xu4g9Jso5vkgRXGmqplOWCv/+V+Ix6Ai59s+/qE25FAF2dVVlXPu6sO8PbK/ZRU1TM4KZy7x6QwumsHlExze4LdDtUlUJlntMFX5hsLZ2+dZyyqPexesysULk4CXTRbVZ2Vj9Zl88YP+8gtq6FHbDC/vyiVi9OiJdibYrfBJ7fCjq+MuWh6XmF2RcKFSaCLFquz2vli42FeXbaXfUePMSgpjIcn9mBAYpjZpbVP9dUw+wqj2+TNX0CnYWZXJFyUBLo4Z1abnY8zcnhuURZHK2uZ2DuGP1zSneRIF+jL7mhVxcacM8cK4Y5F0KFr84/V2pgb3sOrZccJtyOBLs7bsVorb67Yz+s/7KXOaueGIYncNy6VyEAfs0trX0oOwJsXg5cv/Hqx0QumKfU1xg3XrAWQtRDKGtZZTxwG6XdA2mTwkv++4lQS6MJhCitqeWFJFh+uzcbXy4M7L+jMr0d1JtDHy+zS2o/cDfD2Zcai2VfNNGaIrCk1VmyqKTNuquZkGFMT1FcZ0xJ0HgNdL4HacsiYBcX7wD8SBvwKBt4GYZ3MPivRTkigC4fbW1jJv77bxTdb8ogM9OZ3Y1O5fnAi3l4y+AaA3Yvgg2mgbY1vD0kwArzrpZA0Eiy+J7bZ7UbYZ8yCXd8YzTFpk+HSf5z5il+4BQl00Wo2HCrhmQU7WbO/mMRwfx66pBuTesfi4SE9YjicCUV7jQnBTv+y+Dc9JcHJynIg421j6mCLH1z2HPS6qvVrF+2WBLpoVVprlmUV8uyCnezMq2BY5wheuqG/tK87UmEWfH6X8Uui19Uw8Z/gL4O/3JGsKSpalVKKMd2i+Pq+Ufztqt6sP1TC5S/9yIZDJWaX5jo6dIXbv4Oxj8L2L+CVocaNVCFOIlfowuG2Hi7jrjmZFJTX8sTknlw/OEEGJTnSkc3w2V1QsM24merlY/SDt9YYj/XVxvQEnt7G7JOeFmMfTwv4hUHaFOg+SXrQOClpchFtrrSqjvvnbmR5ViHXpsfzlym98LU4+YyO7Ym1FpY/Czu/NoLb4md0lbT4GV8eFrDVGfPA22qN7611UHoIKnKNYO99rTEPfGyfU9+7thKObDR64uRvA21v+OXgZbyvp7dxEzftCujYz5zzd2MS6MIUNrvmhcVZvPj9HnrHhfDyDf1dY3ENZ2a3w/5lsGGOMVWBrQ5i+0L3y6H0oNFGX7jTCHGA4Hjw8gab1djXXm/8kqivArvVuNIf84gx77xoExLowlSLt+fz+482UllnZWSXSK4e4CJzsDu7qmLYMg82zIa8LcYUwXEDja/4dOg4AAIiGj+2pgxWvwqr/gO1FUbPm9EPy3J+bUACXZgut7Saueuy+fSkOdgn9o7h6gHxDE4OlzZ2s1UVG80wLf3/UFUMP70Ea14HazX0uQ66XQphScZgKN+QVinXnUmgi3bDbtesPVDM/ExjDvZjdTb8vT0J8/cmLMBCmL83of7ehPpZ6JsQytUD4iTsnUFlIax8Hta9eWKtVjBWfvo53GN6G0v7xQ0A73NseiveZ7Thh8Q7pGxnJIEu2qWqOisLt+WxJaec0qo6SqrqKKmqp7SqjuJjdZTXWLltRBKPXZYmA5WcRW2FMZiq9KAxr03Jz4/7jTAGUJ5GuCcONRbwju4FoYmNLx1os0LOWmMVqV0LjLVfPSww5mEYfr9xo9bNSKALp2O3a576egezVu7nyv5x/P2aPlg8ZdiEU6sugex1kL3G+Dqcadxc/VlgtBHsoZ2MK/qyHNj9nXGchwWSRkDXCXBoNWz/HOIHwZWvG3PmuBEJdOGUtNb8Z+ke/vldFuO6R/GfGwdI10dXYquH/K1wdLdxJV96wOhWWXLQCHPfEEgdD90mQMo48G1Y71Zr2Dofvn7Q6L558V9g0K/dZhFvCXTh1OasPshjX2xlUKdw3rglnRA/i9klidZms4LyOHNIlx+BL38LexZD8oUw/imjfd1aYwS9rdZ4VB5GO35oojG4qiW0Nt6vrsroyhnY4bxOyxEk0IXT+2pTLv/z8Ua6RAUx+/bBdAiSUY4CI3Az34GF/wv1x868r/KE0AQIS4bwZAiMgboKo0mnumF642H87CAAAA7cSURBVJ8f6481jLqtOvU9EofBkLuM/vcmtd9LoAuXsDyrkLveyyQ62IcPpw8lNqSRm2jCPZVmw8GfTkxz4OVjTHvg5WsMiDr5xmxxw2NNKXj5gV+o0RvHL6zh+xCjF47Fz5gV8+fH2gpYP9u44RuSYDTzDLi5zSdJk0AXLiPzYAm3zFpLhyAf5k4fSnSw79kPEqIx1jpjFGxL2G2Q9a0xqOrACuMXQu+rjV8INaWnXunXlhu9ebpOMOa+D4xySNkS6MKlZB4s4ea31hAd7Mvc6UOJklAXZsjbCmtfh82fGAOyfENPutoPNa7sD62B8hxj/7iBxoImXS8xgv4cx1dIoAuXk3GgmFtmrSU6pCHUgxoPdZtdk1taTXyYnwxQEq1D66bDWWujJ0/Wt7DrW6OrJhqG3A2XPnNOHyeBLlzSuoZQjw3xZe70YafcKM0vr+Gjddl8tC6bw6XVdIsO4qahiVzRP44gX+klI0xSWWD0rY/sagyqOgfnFehKqVnAJKBAa92rke0hwBwgEfAC/qm1fvtsRUmgC0dYs6+IW99eR3yYH+//egjbjpTzwZpDfL+zAJtdMyo1kuEpkXy9JZeth8vx9/ZkSr84bhqaSM+OMs+IcD7nG+gXAJXA7CYC/REgRGv9J6VUB2AXEKO1rjvT+0qgC0dZva+I295eR73NjtWuiQz0Zmp6AtcNSjg+Xa/Wms05ZcxZfZCvNudSU2+nf2Ioz1zVh24xQSafgRDNd95NLkqpJOC/TQT6w0ACcC+QBCwCumr984TKjZNAF460el8R760+yGW9Y7moRzTeXk0PSCmrqmf++hxeXb6X6jobL13fnzHdHdMDQYjW1tqBHgR8CXQHgoBpWuuvm3if6cB0gMTExIEHDx5s5ikI4XhHyqq5c3YG23PLeWRiD+4YmSw3TkW719qLRF8CbAQ6Av2Al5VSwY3tqLWeqbVO11qnd+hg/hBa4d5iQ/z4+DfDmNArhqe+3sGM+Vuos/7yD8vymnrmZeZw34cb+HDtIay2M/7xKYRpHDF29TbgGW1c6u9RSu3HuFpf64D3FqJV+Xt78fL1A3i+g7FU3v6iY7x200D8LJ58v7OALzcdZumuQuqsdoJ9vfhyUy5v/bifGRO6M65HlFzRi3bFEYF+CBgHrFBKRQPdgH0OeF8h2oSHh+J/xncjJSqQP8zbzITnf+BYrZVjdTY6BPlw45BEJvftSN/4UBbtyOfZBTv59ewMBieH88jEHvRLCDX7FIQAmtfL5UNgNBAJ5AOPAxYArfVrSqmOwDtALKAwrtbnnO2D5aaoaI82HCrhbwt2ktIhgMv7dmRIcgSepy2uUW+zM3ddNi8szuJoZR2X9Ynlyn5xdIkKJCHc/xf7C+FIMrBIiFZQWWtl5g/7eOOHfVTX2wDw9vKgc2QAXaIC6RIVyOhuUXIFLxxKAl2IVlRZa2VXXgV7CyrZU1jJnoJKdhdUkFNSjdYwIDGUO0Z25pKe0XjJqkviPJ0p0N1vQT4hHCzQx4uBncIY2CnslNcrauqZn5nDrJUHuPeD9cSF+nHr8CSmDU4gWKYfEK1ArtCFaGU2u2bxjnze+nE/a/cXE+DtyS3Dk/jd2FT8vGVJPdEy0uQiRDux9XAZr/+wj6825RIf5sdfpvRkbPfoRvfVWrN6XzH/WbqHipp6/nBJd0amRrZxxaK9kUAXop1Zva+IRz/fyp6CSi7tFcOfL087vgKT1pqVe4p4cclu1h4opkOQD34WTw4VV3FprxgenZRGXKis1uSuJNCFaIfqrHbeWLGPF5fsxstD8eD4biRHBvDi97vZcKiU2BBf7rowhWmDEgB4c8U+Xl66B4DfjunCnRd0xsdLmmzcjQS6EO3YwaJjPPbFNn7IKgQgLtSPe8akcM3A+F8E9uHSap7673YWbM0jKcKfxyalMba7jFh1JxLoQrRzWmuW7CigstbKxN6xZ5wtEmDF7kIe/3Ib+wqPMbBTGA+O78rwFGlfdwcS6EK4oDqrnY8zsnn5+z3kldcwPCWCB8d3ZWCntl2FXrQtCXQhXFhNvY0P1hzilWV7OFpZx+huHbhndBfSOgYT6CNDTVyNBLoQbqCqzsq7Px3kteV7KauuByA8wJvEcH8Sw/3pFGE8do0OIjU6EH/v5oe91prDpdXsyqtgV74xCvb6QYn0jpdl/NqaBLoQbqS8pp4fdx/lYFEVh4qrOFR8jINFVeSWVmNv+OeuFCSEGeHeLSaQpIgA7FpTVWejqs5GdZ2N6nob5dX17C2sJCu/kspa6/HP8PHyQCl4flp/JvSKMelM3ZMEuhCCepud7OIqsvIryco3rrSz8irYf/QYVvupOeChjLni/b09SY4MoHtMEF1jgugeE0RqdBC19Xamv5fBxuxSZkzozvQLOktPmzYigS6EaFKd1c6Rsmosnh74WTzx8/ZsuAI/c0DX1Nt48JNNfL35CNcPTuAvU3phkcnHWp1MziWEaJK3lwedIgJafJyvxZOXrutPckQALy/dQ3ZxNf+5cQAhfjLxmFkk0IUQ58zDQ/HQJd1Iigzg4U83c/WrP3HbiCTC/b0JDzC+wgK8CfP3loU/2oAEuhDivF0zMJ64UD/u/WA9//vZ1l9sVwrGdY/mz5PSSIzwN6FC9yBt6EIIh6m32Sk+VkdRZR0lVXUUHzO+ckqq+GDNIertmrsuTOHuC1NaPHVwvc1Obmk1YPTQ8XDTK35pQxdCtAmLpwfRwb5EB/v+YtsdIzvztwU7eHHJbuZn5vDYpDQu6Rl9ys3XOqudvYWV7GrofZNdUkVOSTU5xVXkldcc73YZ4O1Jj9hg0joGkxYbTM+OIXSNCXT7ycrkCl0I0abW7Cvi8S+3sTOvglGpkQztHGEMWMqrYG9h5fEulEpBTLAvCWH+xIf5ER/uT0KYHza7ZseRcrYfKWfHkYrj/eMDfby4vG9Hrh+cQO+4EJftRindFoUQ7YrVZmfO6oP8a1EWFTVW4kL96BYTRLeGvu7dY4JJivQ/6xW33a7JLqliW245S3YU8PWWXGrq7fSIDea6QQlc0S+OEH/X6nUjgS6EaJeq6qxY7dpha6yW19Tz5cZcPlqXzZbDZfh4eXBJzxgu7RXDBV07EHCGuW201mQXV5OVX0GPjsHtdhERCXQhhNvZeriMj9Zl89XmXEqr6vHx8mBUaiTj02IY1yOKiEAfCspr+GlvET/tPcrKPUUcbrjpCsa89IOSwhiUHM7gpHC6RAW2i2YcCXQhhNuy2uysO1DCd9vz+G5bPodLq/FQEBvidzzAg329GJYSwYgukXSPCWZbbhnrDhSzdn8JRytrAYgI8Ob6wYncNiKJiEAf085HAl0IITCaVbbllvPd9nx25ZXTPzGMESmRpHUMbnTgk9aaA0VVrNtfzOId+SzakY+PlwfT0hO484LOxIe1fZ96CXQhhHCAPQWVvL58L59tOAzA5H4dufvCFFKjg5r9HvnlNSggqpGunc0hgS6EEA6UW1rNmyv28+HaQ1TX20gI96N3XAg9O4bQKy6EXh2DiQj0oarOypacMjZmlx7/OlJWwz2jU/jjhO7n9NkS6EII0QqKj9UxPzOHjdmlbM0t42BR1fFtkYE+lFTVYWvoV58Y7k+/hFD6JYQyMjWSri24qj+ZjBQVQohWEB7gzZ0XdD7+vKy6nu255WzLLWNnXgUdQ3zplxhK3/jQNrmRKoEuhBAOEuJnYVhKBMNSIkz5fJmNXgghXIQEuhBCuAgJdCGEcBES6EII4SIk0IUQwkVIoAshhIuQQBdCCBchgS6EEC7CtKH/SqlC4OA5Hh4JHHVgOc5Aztk9yDm7h/M5505a6w6NbTAt0M+HUiqjqbkMXJWcs3uQc3YPrXXO0uQihBAuQgJdCCFchLMG+kyzCzCBnLN7kHN2D61yzk7Zhi6EEOKXnPUKXQghxGkk0IUQwkU4XaArpSYopXYppfYopWaYXU9rUErNUkoVKKW2nvRauFJqkVJqd8NjmJk1OppSKkEptVQptV0ptU0pdX/D6y573kopX6XUWqXUpoZzfrLh9WSl1JqGn/GPlFLeZtfqSEopT6XUBqXUfxueu/r5HlBKbVFKbVRKZTS81io/104V6EopT+A/wKVAGnC9UirN3KpaxTvAhNNemwEs0VqnAksanrsSK/Cg1joNGArc2/D/1pXPuxYYq7XuC/QDJiilhgLPAv/WWncBSoA7TKyxNdwP7DjpuaufL8AYrXW/k/qet8rPtVMFOjAY2KO13qe1rgPmAlNMrsnhtNY/AMWnvTwFeLfh+3eBK9q0qFamtT6itV7f8H0Fxj/4OFz4vLWhsuGppeFLA2OBeQ2vu9Q5K6XigcuANxueK1z4fM+gVX6unS3Q44Dsk57nNLzmDqK11kcavs8Dos0spjUppZKA/sAaXPy8G5ofNgIFwCJgL1CqtbY27OJqP+PPA38E7A3PI3Dt8wXjl/R3SqlMpdT0htda5edaFol2QlprrZRyyf6mSqlAYD7wgNa63LiAM7jieWutbUA/pVQo8BnQ3eSSWo1SahJQoLXOVEqNNrueNjRSa31YKRUFLFJK7Tx5oyN/rp3tCv0wkHDS8/iG19xBvlIqFqDhscDkehxOKWXBCPP3tdafNrzs8ucNoLUuBZYCw4BQpdTPF1uu9DM+ApislDqA0Vw6FngB1z1fALTWhxseCzB+aQ+mlX6unS3Q1wGpDXfFvYHrgC9NrqmtfAnc0vD9LcAXJtbicA1tqW8BO7TWz520yWXPWynVoeHKHKWUH3Axxr2DpcA1Dbu5zDlrrR/WWsdrrZMw/u1+r7W+ERc9XwClVIBSKujn74HxwFZa6efa6UaKKqUmYrTDeQKztNZPm1ySwymlPgRGY0yxmQ88DnwOfAwkYkw7fK3W+vQbp05LKTUSWAFs4UT76iMY7egued5KqT4YN8Q8MS6uPtZa/0Up1RnjCjYc2ADcpLWuNa9Sx2tocnlIaz3Jlc+34dw+a3jqBXygtX5aKRVBK/xcO12gCyGEaJyzNbkIIYRoggS6EEK4CAl0IYRwERLoQgjhIiTQhRDCRUigCyGEi5BAF0IIF/H//BVkBev7li8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_token = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_token = char_transformer.generate(start_token, max_token=2000)\n",
        "print(f\"Generated text:{decode(generated_token[0].tolist())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KF3JT0tGHFc",
        "outputId": "7e0f2049-0223-46ca-89a7-f2fb407bf4a4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "Kencesst in spirve and and by Mar;\n",
            "Aling a heart, he come. Then then humag as pracemess avind:\n",
            "Were I had blesling be; there's love I hapes comming mustrance of mecutly.\n",
            "\n",
            "MENT:\n",
            "For own I have like pents, you thou sheld better had exer\n",
            "Richmory land of gle best, and lise\n",
            "Art!\n",
            "Wen anour moce and shall, when it then your have sadly.\n",
            "\n",
            "TYMININGBY:\n",
            "True to you but you all\n",
            "Horton you shall oft, I'll know, I then;\n",
            "My from live, mast streng'd hard well-Even Turse no fillow move;\n",
            "Which this low the from sacnion thee.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "He won child no do'd glo, pulght me have love!\n",
            "\n",
            "GREWICHICl HINRG HENRY VI:\n",
            "But is my do in and in the till most farteen, your with him so;\n",
            "He prectifur\n",
            "of such duke jarfarew:'\n",
            "Yoo lasgle no is she numbertents, canst in espor to hem baid,\n",
            "Beetrinemnate the for when,\n",
            "We dost with and meant for than I tall you way not is culd\n",
            "up an deamful man thy lard she\n",
            "your lord'd endsune our here, me be my face!\n",
            "\n",
            "Nessel Loving.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Then; but those year on, but will\n",
            "Qrom my would the quart it o' the\n",
            "Now it most their agains, perdecterous have\n",
            "A devill the pitcheointle your sour soings.\n",
            "Give and of honest, and will is, rove me underforer,\n",
            "When like to yat not stadd'et, be night ox.\n",
            "\n",
            "TOMPT:\n",
            "Home inding, and with not landemiled hang newsure chold will have have sence tongues hone!\n",
            "\n",
            "Nor RINCE XI:\n",
            "me bothd uses now, with is majoushomes him.\n",
            "\n",
            "BENVOLYCUMNIA:\n",
            "Signice on what some off not her in eathIs thee for thee pupron then'd; if held The all heard he shore\n",
            "What a soome temphath shed heriff you,\n",
            "Then lek of dost thou hord and, orteld,\n",
            "The is pursuled you hast name hols, sid she now ruch word no foll:\n",
            "His the make of their is thisles\n",
            "to an the suxo.\n",
            "\n",
            "EDWARD:\n",
            "Hensinat, Pond sany files abjine\n",
            "Tray floight so, me wordich compungest,\n",
            "So stame provous four to humarcher old must and-brow child which strew with a, be him actory alless windroning me were havist:\n",
            "Pilight!\n",
            "\n",
            "MENC Congle some thou have thy lord: if extrrewent, and nots whon\n",
            "ye will perpentless, I \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model checkpoint\n",
        "torch.save(char_transformer.state_dict(), \"char_transformer_LM.pt\")"
      ],
      "metadata": {
        "id": "b378zXz6q4wS"
      },
      "execution_count": 108,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_env_3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "02a75899b11e31bd85ccc905c76a128ad2bb11b6b68df04d39be7741d54ebc47"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}